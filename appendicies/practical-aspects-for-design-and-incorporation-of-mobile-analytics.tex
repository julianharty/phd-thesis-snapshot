\chapter{Practical aspects for design and incorporation of-mobile-analytics}~\label{practical-aspects-appendix}
This appendix introduces various practical aspects of incorporation of mobile analytics that are not necessary to understand the overall approach. The intention is to help those who would be actively involved in the concepts and approach described in the core thesis.


\section{Evaluation criteria for Analytics Tools}
One of the considerations in terms of using analytics tools is to decide on evaluation criteria. These criteria may range from informal and implicit evaluations to more rigorous and formal approaches. Considerations also include a mix of technical and non-technical aspects such as popularity, brand, perceived ease of initial use, and so on.

This section includes four types of criteria and a rubric for evaluating analytics tools.

\subsubsection{Evidence-based criteria}

\subsubsection{Auditability}
The reliability of software where the outcomes of failure are material has been a subject of discussion and research for decades. As (\cite{dobbing1998reliability}) notes, where the reliability requirements are modest black box testing techniques may be sufficient, however \emph{``When reliability claims cannot be justified from test results alone, safety standards accept evidence from the design process"}. This paper focuses on smart instrumentation for the UK nuclear industry, nonetheless given the widespread use and implicit trust of analytics software, similar approaches to assess the reliability of this software could help in terms of auditing the behaviours of the analytics tools. Indeed two of the authors of (\cite{dobbing1998reliability}) collaborated with a third author and published a paper on the relevance and importance of software in measuring systems, where \emph{``Both users and suppliers of such systems must be aware of the risks involved and take appropriate precautions."} (~\cite{wichmann2007software}).

\subsubsection{Functional-aspects}

\subsubsection{Transparency}

\subsubsection{Veracity}

\subsubsection{Faults and failures}


\subsubsection{Verification and Validation criteria}
These two terms, verification and validation, are often used in tandem, particularly in software testing standards including the retired~\cite{BS_7925_1_1998} and the standard that superseded it~\cite{iso29119-1-2013}. The definitions from the ISO standard are:
\begin{itemize}
    \item ``Verification is confirmation, through the provision of objective evidence, that specified requirements have been fulfilled in a given work item."~\cite{iso29119-1-2013}
    \item ``Validation demonstrates that the work item can be used by the users for their specific tasks."~\cite{iso29119-1-2013}
\end{itemize}

In terms of analytics tools, verification would focus on evaluating whether the tool has been implemented correctly. Validation considers human aspects such as whether users can perform intended tasks using the analytics tool(s). (In this research context software developers of mobile apps are the main users).

As the requirements for analytics tools are often proprietary, verification using the product specified requirements may be impractical to assess rigorously unless and until one has access to these requirements. Nonetheless common-sense requirements can be established based on heuristics and experience, \emph{etc}. this is covered in the section titled: \href{rubric-for-evaluating-analytics-tools}{\nameref{rubric-for-evaluating-analytics-tools}}.

\subsubsection{Perceptions-based criteria}

\subsubsection{Qualitative/quality criteria}

\subsubsection{Functional correctness}

\subsubsection{Performance}

\subsubsection{Safety}
Freedom from harm or danger, safety in other words, may be an unlikely consideration initially especially in terms of using analytics tools. 

Safety in terms of reputation, ability to try something out, and so on, considers human aspects of using (or not-using) various analytics tools. Safety became an emerging consideration in terms of assessing various analytics tools. Safety in relationship to the researcher, the health of apps and projects related to the research, and in terms of protecting the safety of end users privacy, \emph{etc}.

\subsubsection{Security}

\subsubsection{Time-aspects}

\subsection{A rubric for evaluating analytics tools}~\label{rubric-for-evaluating-analytics-tools}
Bugs can be exposed with various qualities, a heuristic the author learned in many years of evaluating the performance of systems is zero, one, several, and many, where:
\begin{itemize}
    \item Zero: can represent a system before it is actively used and/or the quiescent state with no active users, where there were users previously.
    \item One: the first user, session, account, and so on. Unless there are stated reasons to the contrary, as the first activity starts the analytics should be able to correctly indicate and report on the activity.
    \item Several: As several activities occur in parallel and concurrently race conditions, queuing, latency, and reuse of dirty memory values can all emerge.
    \item Many: As volumes increase from several to many issues of scaling may emerge, and some of the issues that appeared to be minor with several users may increase nonlinearly. 
\end{itemize}

\subsection{Validating Analytics}

TODO TBC

\subsection{Some practical complications} 
Access may be restricted or not available to some of the steps introduced in this section. For instance, the data collection and reporting servers may be off-limits. If so, aspects of verifying the testing may be answered, at least partially, in later steps, for instance appearance of activity in an analytics report may be used to infer that the messages arrived and were processed adequately.





\section{Summary of the practical aspects appendix}
The development team has intrinsic choices on how much credibility and trust to place in the analytics tools they use. If they wish to investigate and establish evidence-based criteria the contents of this appendix is intended to help them do so. Feedback is welcome and may help improve the depth, breadth and credibility of this research! as per the approach described in~\cite{scaffidi2007developing} which was discussed earlier in this thesis.
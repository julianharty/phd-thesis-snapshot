
\chapter{Findings per case study}\label{chapter-findings-per-case-study}
This chapter holds various findings per case study. The contents were previously in the case studies overview chapter. They need to be compiled / analysed and the compiled version added to the respective findings chapter.


\section{GTAF}

The app-centric case study procedure was applied as follows:
{\small
\begin{enumerate}
    \itemsep0em
    \item \textit{Exploration and selection:} A fellow PhD researcher contributes voluntarily as a developer as part of the extended project team and introduced me to the core project team who agreed my research was of interest to them and something they were willing to support. The project had various popular Android apps in Google Play store. They were already using several mobile analytics services so were already familiar with the concepts presented in this research.
    \item \textit{Engagement:} the developers had had to address excessively-high crash rates, so they were interested in the research and willing to help. They were happy to provide read access to their Google Play Account for their apps, but they were cautious about providing access to additional analytics services or their source code, so we agreed that the research would start with Google Play Console with Android Vitals\index{Android Vitals} and access to their issue tracking system, which is public anyway.  There were no formal interventions.
    \item \textit{Action research:} the action research stage consisted of three elements: a discussion on their use of mobile analytics; ongoing read only access to their Google Play Console; and a report based on the analysis of the Google Play Console and Android Vitals reports and data for their top apps. Ill-health and some other complications effectively limited any additional action research and meant they did not provide access to their other mobile analytics services. 
    \item \textit{Post-hoc analysis:} as the research has ongoing access to Google Play Console, the analysis continues.\todo{Do some analysis of the issues database and summarise here. Ditto summarise findings from Google Play Console with Android Vitals.}
    \item \textit{Wrap-up:} Access to Google Play Console was withdrawn in Spring 2022, presumably as part of their housekeeping activities as they are no longer actively involved in the research.
\end{enumerate}
}

\subsection{GTAF: Experiences of using mobile analytics}
The development team checks Android Vitals\index{Android Vitals} approximately once a week, and Firebase more frequently as the team decided the crash reports in Firebase are more actionable. Perhaps unsurprisingly, they check more often after new releases of their apps looking for any new bugs arising in the new release as it rolls out across the user population.

They noticed differences in the Firebase reports compared to Android Vitals, however they were not overly concerned about the differences, as their focus was on the crashes reported in Firebase because they contain more contextual detail. The team seldom checked \acrshort{anr}s as they considered these had less impact on users and less frequent. % TODO ask for access to their Firebase stats?

At the time of the case study, the team's development priorities for the rest of 2020 and until April 2021 focused on bug-fixes which included fixing the causes of crashes being reported by mobile analytics for their apps. In March 2021, they published a blog post which confirms this focus and includes a chart of their average daily crashes for 2020 which shows their progress in addressing peaks in the crash rate~\sideparencite{gtafblog2021_gtaf_accomplishment_2020}. The chart does not provide any additional information \emph{e.g.} about the app(s) for which the chart was plotted or the source of the data. However, from the appearance of the chart, it can be inferred that the source is probably Firebase Analytics.

The same blog post~\sideparencite{gtafblog2021_gtaf_accomplishment_2020} explains one of their goals for 2021 was to ``integrate analytics features in our application'' to improve the user experience.

As the project did not provide access to Firebase or the other in-app analytics, it was not feasible to compare their outputs; similarly, the team did not provide access to the source code of their apps, so that could not be studied.

\subsection{GTAF: data collected and methods used for collection}
The data was collected from four primary sources:
{\small
\begin{enumerate}
    \itemsep0em
    \item an online, \textit{pre-study} interview, recorded in handwritten notes, 
    \item ongoing read access to Google Play Console with Android Vitals\index{Android Vitals}, both automated and interactive snapshots were captured, 
    \item 3) email correspondence, maintained in a GMail account, and 
    \item 4) the project's public issues database, which was searched interactively. 
\end{enumerate}
}

\subsection{GTAF: Outcomes for the organisation}
The organisation found mobile analytics helpful and addressed the crashes they believed were tractable and productive to fix in terms of improving the user experience. And, based on their experiences of using mobile analytics they committed to increasing their use in order to improve their understanding of their mobile apps~\sideparencite{gtafblog2021_gtaf_accomplishment_2020}.

\subsection{GTAF: misc}
\julian{There was scope to do ongoing analysis of the Google Play Console and Android Vitals reports for the project's 10+ Android apps. They help indicate some foibles in the Dashboard page for several apps - at least, where the combined \acrshort{anr} and crash rate report does not agree with the separate Crash and \acrshort{anr} reports from Android Vitals.}

\section{LocalHalo}
\subsection{Local Halo: Background - How the case study came about}
I was introduced to the CEO of Local Halo by one of their team who knew of my work in October 2019. An online call was followed by an in-person meeting with the CEO in November 2019 where he offered to be a case study for my research. After an online call in January 2020 with the \acrshort{cto}, he provided access to Google Play Console with Android Vitals\index{Android Vitals} for their Local Halo Android app~\footnote{The underlying app is cross-platform which generates both Android and iOS binaries.}, and to their Sentry~\footnote{\url{https://sentry.io/welcome/}}, which was used to track technical issues with their app and website. 


{\small
\begin{enumerate}
    \itemsep0em
    \item Exploration and selection: the project had a cross-platform app available in iOS and Android; it was written in React Native, the \nth{3} most popular framework in approximately 8\% of the top Android apps~\cite{appbrain2021_react_native_stats}, so very much of interest in terms of the research.
    \item Engagement: we agreed the research would have access to Google Play Console with Android Vitals and to Sentry as both were used to monitor technical aspects of the apps and service. We agreed the research would \textit{not} have access to the third analytics service, Mixpanel~\footnote{\url{https://mixpanel.com/}}, which they used for user behaviour and related analytics. This service included personally-identifiable information of their users and would not be useful for this research. We also agreed no access would be provided to the source code, as that was deemed sensitive. 
    \item The action research stage: the main connection was through the shared medium of mobile analytics outputs, together with analysis of these outputs and an email discussion of one issue in particular.
    \item \textit{Post-hoc} analysis: as the project team provided ongoing access to Sentry analytics there was ongoing analysis until late 2021 of these analytics. 
    \item Wrap-up: the project team appears to have stopped working on the app a few months after the active period and was not available, hence the wrap-up has been on the research side.
\end{enumerate}
}

\subsection{Local Halo: Data collected and methods used for collection}
This case study combines three immediate sources of data with automatically provided reports. The interactive sources are: 1) separate meetings with the founders, 2) email conversations with the founders, and 3) online access to two mobile analytics tools. The automatically provided reports include 100's of automated emails from Sentry's hosted mobile analytics service, and Vital Scraper was also used to collect reports and crash details from Google Play Console with Android Vitals\index{Android Vitals}.

\subsection{Local Halo: Experiences of using mobile analytics}
The development team used at least three distinct mobile analytics services: Mixpanel for behavioural analytics, Sentry for error analytics, and Google Play Console with Android Vitals\index{Android Vitals} (these were the ones discussed with the CTO). 

Local Halo incorporated two analytics libraries into their cross-platform mobile application: Sentry for crash reporting and Mixpanel for business-oriented usage analytics. For their Android app they also had access to Google Play Console. Interestingly, the Exodus Privacy project detects additional trackers and does not detect Sentry, as their report for Local Halo confirms: \url{https://reports.exodus-privacy.eu.org/en/reports/225323/}.

They seldom used Google Play Console with Android Vitals. According to the \acrshort{cto} it did not suit apps developed in React Native as the crashes did not actually crash the shell app which wraps the React Native app~\footnote{Note, other developers have asked about this behaviour, for instance on StackOverflow \href{https://stackoverflow.com/questions/66166824/native-crash-reporting-for-expo-deployed-to-android/}{Native crash reporting for Expo deployed to Android?}} 
(which is what appears to be monitored by Android). The shell app restarts the React Native app automatically.

The development team chose to use separate analytics services for user behaviour analytics (Mixpanel) and issues such as crashes and anomalies (Sentry). Presumably the respective SDKs were incorporated into the React Native source code~\footnote{Some of the errors reported by Sentry indicate the integration used TypeScript (which is supported in React Native, see \url{https://reactnative.dev/docs/typescript}. Mixpanel also provides an opensource wrapper that supports React Native \url{https://github.com/mixpanel/mixpanel-react-native}.}~\footnote{Note: Local Halo also incorporated Sentry into their website and provided access to Sentry for their website, however the website is out of scope for this research and will not be considered further here.}. Only two people have access to Sentry: the \acrshort{cto} and me; therefore any other members of the development team would have indirect access, for instance via screenshots and/or bug reports raised by the \acrshort{cto}. 

They saw value in using analytics to improve business results, for instance for App Store Optimisation to improve the ranking of their app in the app stores. The \acrshort{cto} made a key observation during the interview: \emph{``If you have lots of crashes you have zero chance of being promoted [by the app store].''}
%
In terms of user experience analytics the \acrshort{cto} also observed: \emph{``To improve user retention you need to do both: eliminate the bad stuff [and] improve the good stuff [to] increase value''}.

The overall impression was the team had decided to incorporate mobile analytics to help them provide a reliable and valuable service for their current and hoped-for users where the team would address errors on an \emph{ad-hoc} basis.


\subsection{Local Halo: Outcomes for the company}
The nature of the case study (being remote from the development team, with access limited to two of the mobile analytics services, and correspondence being occasional) meant the outcomes for the company are hard to ascertain. It is clear the founders saw the value in choosing two particular mobile analytics services to help them manage the business and the service their provided to their users. 

Their main focus was to try to grow the business. Ultimately that was not successful, a topic discussed briefly in the next paragraph. Nonetheless, the analytics tools continue to report on the app and the website and continue to provide some insights into the reliability of the app and usage of the app.

Note: The founders of local halo indicated, as of October 2020~\footnote{Via their respective LinkedIn profiles: \url{https://www.linkedin.com/in/jamesroutledge/} and \url{https://www.linkedin.com/in/andriymarin/}.}, they are no longer actively involved in this project. And there are confirming indications in sentry.io as the app has not been updated in over a year, in contrast to the many updates they made previously. So even though the app remains online and available, and the analytics continue to report, there is no one actively maintaining the app or dealing with the errors being reported in the analytics.


\section{Moodspace}

\subsection{Moodspace: Background - How the case study came about}
A practitioner recommended me and my research to the co-founder and \acrshort{cto} of Moodspace. He was willing to answer questions and also provide screenshots from Google Play Console and Android Vitals\index{Android Vitals}.

{\small
\begin{enumerate}
    \itemsep0em
    \item Exploration and selection: Moodspace was one of several Android apps developed by the \acrshort{cto} and in a new application domain of health. 
    \item Engagement: The \acrshort{cto} was happy to answer questions and send a subset of pertinent information, his business responsibilities meant he was cautious about providing direct access to the analytics or development artefacts. 
    \item The action research stage: limited to analysis of ObjectBox in addition to learning how the project used mobile analytics.
    \item \textit{Post-hoc} analysis: similarly constrained by the limited access to artefacts, there was some follow up on research into this app and similar apps in terms of their efficacy in terms of mental health.
    \item Wrap-up: followed up with the \acrshort{cto} in late 2019 who was actively focusing on fund-raising. There was nothing else to wrap-up.
\end{enumerate}
}

\subsection{Moodspace: App Design}
The CTO actively developed the app to be performant, and chose to use an in-memory ORM database, objectbox to ensure the app was responsive for end users. In his words: 

\begin{quote}
\emph{``The app doesn't use any API, so all the data's stored in very fast ORM databases like object-box (and uses memory caching). This enables the app to be mostly synchronous, which hugely cuts down on complexity of code. i.e. no need to handle loading, errors, or concurrency. This is a big benefit! And cuts down on errors significantly, with no real impact on performance for users. To illustrate that it has little impact on users, I use firebase performance to run a trace on some methods that call the ORM/cache - it's peak duration is 40ms while the majority of calls take 3-6 ms."} (email correspondence, lightly edited to fix typos and improve readability)\todo{Relocate this comment to the methodology chapter if I provide other edited extracts from emails.}.    
\end{quote}

\subsection{Moodspace: Data collected and methods used for collection}
The main source of data are emails from the \acrshort{cto}, these included extracts of screenshots from their Google Play Console with Android Vitals\index{Android Vitals}. These were supplemented with some additional research online using grey literature and grey data;

\subsection{Moodspace: Experiences of using mobile analytics}
The app included both Firebase Analytics and Firebase Crashlytics. The discussion covered Firebase Crashlytics and Google Play Console with Android Vitals\index{Android Vitals}, Firebase Analytics was not mentioned by the CTO. Details of their use are covered in the \nameref{chapter-analytics-in-use} chapter. They used Crashlytics in preference to Android Vitals, however as part of the interview the \acrshort{cto}noticed Android Vitals had reported an \acrshort{anr} which he believed he should and could fix. He suggested several desirable improvements for Google Play Console with Android Vitals, these will be discussed in the \nameref{chapter-tools-and-their-artefacts} Chapter.

The current privacy policy for the Moodspace app confirms they actively use mobile analytics in the app: 

{\small
``To make the app work well at all we collect the following anonymous data:
    \begin{itemize}
        \itemsep0em
        \item Crash reports: If you've never seen the app crashing, it's because as soon as one happens, we get a crash report. A little red light flashes in our office, a loud siren blares, and we release a fix right away. It's quite annoying actually.
        \item Analytics: We assume you're going to use the app a certain way. We're almost always wrong, and you often surprise us. Analytics lets us see how people like you actually use the app, so we can make improvements to the right places. Analytics can use the Google Advertising ID to identify you. This doesn't tell us anything about you (it's just some numbers and letters), but if you really want to trick us you can reset your Google Advertising ID at any time. Go to your device Settings > Google > Ads."
    \end{itemize}~\sideparencite{moodspace2021_privacy_policy}
}

\subsection{Moodspace: Outcomes for the company}
The startup was subsequently able to raise a round of funding and grow to six people. The project later returned to be a side-project which is maintained and updated~\sideparencite{alexander2021_linkedin_profile}. % Some details of the funding also available on twitter ``Thank you for so much support on our @Crowdcube campaign! More than 50 investors and £46k raised. You can still invest here: " https://twitter.com/MoodSpaceApp/status/1237753829174710272?s=20 http://crowdcube.com/boundlesslabs (protected behind an intrusive account creation process which I abandoned).
The app has a strong positive User Experience rating of 4.18/5.00~\footnote{\url{https://onemindpsyberguide.org/apps/moodspace/}}.

% The app was made free of charge on 17 March 2020 https://twitter.com/MoodSpaceApp/status/1239942338434215941 and https://www.healthfoundry.org/covid-19-response 


\section{Moonpig}

\subsection{Moonpig: Background - How the case study came about}
One of the developers of the Android app learned about this research and offered to provide their insights into their use of mobile analytics for their Android app. Both the head of engineering and communication manager approved him doing so and gave permission for the material to be used.

{\small
\begin{enumerate}
    \itemsep0em
    \item Exploration and selection: A highly popular Android app for a profitable e-commerce business that was developed by a team passionate about delivering an excellent quality app and service made the case study compelling. They also used Firebase Analytics actively and extensively. 
    \item Engagement: Clearance was obtained from senior management for the research and they gave permission to use the outputs and findings. Their developer had permission to discuss and share their use of mobile analytics. 
    \item The action research stage: various in-person discussions about their use of mobile analytics and how they handled sporadic peaks in failures.
    \item \textit{Post-hoc} analysis: this case study set the high-watermark among the app-centric case studies in terms of the reliability of complex Android apps and how the development team actively addressed the sporadic issues. 
    \item Wrap-up: Permission was sought for some additional updates but declined for business reasons at the time and post IPO.
\end{enumerate}
}

\subsection{Moonpig: Data collected and methods used for collection}
The data was collected though a mix of in-person and online working sessions together with various email conversations. Screenshots and other materials were emailed by the developer to the researcher. 
%
The developer also ran Vitals Scraper\todo{Add cross-reference once I've relocated the content on Vitals Scraper.} to help evaluate whether it worked beyond the local use as part of various case studies. They sent the JSON results containing the crash clusters collected by Vitals Scraper. 

\subsection{Moonpig: Experiences of using mobile analytics}
The development team use Firebase Crashlytics and Google Analytics for diagnostics in addition to the information available in Android Vitals; and estimated they used Android Vitals\index{Android Vitals} approximately 30\% of their time to identify flaws and issues related to their Android app.
%
They also incorporated in-app analytics by using Firebase Analytics which recorded analytics related to how the users use the mobile apps and whether errors or other problems occurred while the app was being used. 

Their Android app had one of the highest stability scores, details are in the \nameref{chapter-analytics-in-use} chapter.\todo{Add forward link once I've incorporated the material into that chapter.}

\subsection{Moonpig: Outcomes for the company}
For over two years since the case study started, in June 2019, the Android app has been highly rated by end users in Google Play. According to AppBrain it is in the top 1\% of apps by rating, and in the top 5\% in both ratings (46,000) and downloads (estimated at 3,000,000)~\sideparencite{appbrain_moonpig}.

The company was able to `go public' in February 2021 by listing on the London Stock Exchange.  Their success online through their website and their mobile apps were cited in their IPO~\footnote{Initial Public Offering - listing a company on a stock market.} Prospectus~\sideparencite[p.92]{moonpig2021_ipo_prospectus}.


\section{SmartNavi}

\subsection{Smartnavi: Background - How the case study came about}
The app was one of the opensource codebases investigated as part of my collaborative research on logging using Google Firebase Analytics. I noticed an issue which I reported to the project's developer and I submitted a pull request to address this issue~\footnote{\url{https://github.com/Phantast/smartnavi/pull/25}} which he accepted and merged. He agreed to be interviewed for this research.

{\small
\begin{enumerate}
    \itemsep0em
    \item Exploration and selection: this case study came via research into how developers of opensource Android apps use Firebase Analytics; then I discovered an oddity I thought the developer might be interested in.
    \item Engagement: the developer appreciated my interest and was happy to discuss their use of mobile analytics.
    \item The action research stage:  a discussion on their use of mobile analytics historically, submitting and having a minor Pull Request accepted.
    \item \textit{Post-hoc} analysis: analysis actually preceded the engagement.
    \item Wrap-up: not applicable as the project is opensource and the information freely provided.
\end{enumerate}
}


\subsection{Smartnavi: Data collected and methods used for collection}
Source code on GitHub analysed before and during the case study. Contemporaneous notes and email discussion.

\subsection{Smartnavi: Experiences of using mobile analytics}
Mobile Analytics are used for several purposes including A/B experiments using Firebase Analytics and Crashlytics for crash reporting. Several years ago (probably 2016) the developer spent a lot of time where he actively focused on fixing crashes being reported in Fabric Crashlytics (since superseded by Firebase Crashlytics). The few crashes that remain are ones either too impractical to investigate (e.g. on a few unbranded low-end Android devices he has no access to) or in a third-party library that only occurs again on a few unusual devices.


\subsection{Smartnavi: Outcomes for the company}
Bugs found by mobile analytics were fixed in the app including at least one raised by an Android user who wrote a 1-star review. The usability of the app was improved through the use of Firebase Analytics. 

% Extra feedback on the app https://www.kiledjian.com/main/2020/10/16/navigate-to-your-destination-without-using-gps

\section{Kiwix}
\subsection{Kiwix: Background - How the case study came about}
The reliability of the Android app, as reported by Android Vitals\index{Android Vitals}, had been a concern for the core project leaders and by early 2019 was a major concern yet the active developers for the Android app had not been able to materially improve the reliability. We agreed it would be worth trying to focus on improving the reliability and that the planned project wide hackathon in Stockholm would be a great opportunity to do so. In parallel the project had funding to pay for an experienced Android lead developer several days a week and one of his objectives would be to improve the reliability of the app. 

{\small
\begin{enumerate}
    \itemsep0em
    \item Exploration and selection: work with Kiwix started in 2014, predating this case study by many years. 
    \item Engagement: we were already `engaged'; the scope was agreed to use a planned hackathon as an impetus to focus on improving the crash rate for the main Kiwix app.
    \item The action research stage: started around six months before the hackathon~\footnote{Many of the expenses were covered by the Kiwix organisation, the researcher covered their own expenses.} and continued for around six further months.
    \item \textit{Post-hoc} analysis: the analysis was ongoing during the action research stage and continues to date.
    \item Wrap-up: not applicable as the project is ongoing.
\end{enumerate}
}

\subsection{Kiwix: Data collected and methods used for collection}
The development artefacts including the codebase \href{https://github.com/kiwix/kiwix-android}{github.com/kiwix/kiwix-android} and the issues \href{https://github.com/kiwix/kiwix-android/issues}{github.com/kiwix/kiwix-android/issues} are both public and freely available. They include the history of the source code and of issues raised pertaining to the case study. The analytics artefacts were collected interactively and by using vitals-scraper. Various contemporaneous notes were made during the case study.  

\subsection{Kiwix: Experiences of using mobile analytics}
The project leaders have consistently chosen \emph{not} to incorporate any analytics in their applications in order to protect the users of Kiwix software. Nonetheless they were willing to use analytics provided by Google Play which are collected by Android rather than by the app. The expectation is that users who are willing to let Android collect this data are unlikely to be at risk from using Kiwix.

\subsection{Kiwix: Outcomes for the project}
The project was able to significantly reduce the measured crash rates~\footnote{Some of the apps do not have many users and the crashes were too few for Google Play to report on them. This topic is discussed in the \nameref{chapter-tools-and-their-artefacts} chapter.}\todo{Add link to the relevant section.} for all the shipping Android apps despite some additional complications related to Android app bundles. 


\section{Catrobat}

\subsection{Catrobat: Background - How the case study came about}
A PhD student who was part of the Catrobat project discovered my research at the MobileSOFT 2019 conference. Their flagship Pocket Code app had a persistently high, chronic crash rate and my early research for the Kiwix project seemed worth evaluating in case it could help them reduce the high crash rate. 

{\small
\begin{enumerate}
    \itemsep0em
    \item Exploration and selection: like Kiwix, the case study includes an open and opensource project with several Android apps, which makes it relatively easy to work with and open to collaboration. It also had an app with a high crash rate so one that offered lots of scope for improvement. Furthermore the Pocket Code app included Fabric Crashlytics and thereby provided the scope to understand Crashlytics and compare the results of the two mobile analytics tools. 
    \item Engagement: was simple given the open nature of the project and the development team, access was given to both their mobile analytics services and to create issues in JIRA. We agreed on the hackathon to kickstart the action research~\footnote{Many of the expenses were covered by the Catrobat organisation.}. A second workshop was planned for \nth{28} Feb 2020 which did not go as envisaged because of the outbreak of Covid-19 that weekend in parts of Europe.
    \item The action research stage: effectively started with planning the hackathon and finished just over three months later (with the mass outbreak of Covid-19).
    \item \textit{Post-hoc} analysis: the progress by the development team for the 20 issues raised during the hackathon have been reviewed, in tandem the improvements to the crash rate were assessed for the two releases post hackathon.
    \item Wrap-up: the case study transitioned into a quiescent state for various reasons. Given the open nature of the project and the engagement additional action research is expected in 2022.
\end{enumerate}
}

\subsection{Catrobat: Data collected and methods used for collection}
The project team provided access to Google Play Console for all their Android apps and also to their Fabric Crashlytics account. They also provided access to their JIRA and Jenkins systems (read access to both system is public). Their codebases are all public and available as opensource. The majority of the data for this case study is public, in JIRA tickets and in the codebase for Pocket Code. Outputs from the two mobile analytics tools were captured interactively and using vitals scraper for Google Play Console with Android Vitals\index{Android Vitals}. There are some email communications and similarly various handwritten field notes in notebooks.

\subsection{Catrobat: Experiences of using mobile analytics}
The project had already incorporated Fabric Crashlytics into the Pocket Code Android app. %TODO confirm when and revise accordingly.
For their apps in Google Play they also had Google Play Console with Android Vitals\index{Android Vitals}. They did not appear to use either source of mobile analytics materially in their software development practices, however they were aware of the ongoing high crash rate for the Pocket Code app. %TODO check through their JIRA history for signs of them using either mobile analytics tool as a source of issues that they wanted to address.

\subsection{Catrobat: Outcomes for the project}
A group of six members of the Catrobat development team were able to usefully address various causes of the most prevalent failures of the Pocket Code app in production. 

\section{C1}

\subsection{C1: Experiences of using mobile analytics}
The project included multiple mobile analytics services integrated into their apps, including the Android app. However the development teams seldom appeared to use them proactively. 

\subsection{C1: App-centric case study procedure}
{\small
\begin{enumerate}
    \itemsep0em
    \item Exploration and selection: the company engaged me to jointly improve one of the critical Android apps as part of a wider brief. At the time the Android app had millions of users.
    \item Engagement: details of the project and the work are confidential. Access was provided to source code and other development and analytics artefacts.
    \item The action research stage: direct, remote engagement working-from-home using commercially available collaboration tools.
    \item \textit{Post-hoc} analysis: access to the materials was available after the action research stage and evaluated both for the project team and for research purposes.
    \item Wrap-up: access to the systems and artefacts are no longer available. A summary of the findings and results were provided to senior management.
\end{enumerate}
}

\subsection{C1: Outcomes for the company}
Confidential.

\subsection{C1: Contributions to the research}
\textbf{TBD} \todo{Add forward links when the relevant material has been included.}.

\begin{enumerate}
    \item Excessive \acrshort{anr}s
    \item Excessive Crash Rate
    \item Gaps in understanding and gaps in testing of changes and generally of networking code increase crash rate several fold
    \item Problems could have ameliorated using Release Management reports
    \item Concerted focus to address native memory leaks that caused some of the crashes
    \item Code written to reproduce the networking errors that led to the crashes, followed by fixes to the underlying code covered adequately by automated tests, bring excessive crash rate under control.
    \item Majority of \acrshort{anr}s came from another project team's SDK, when the new SDK was integrated and a new release launched, the \acrshort{anr}s were materially improved. 
    \item Other crashes also addressed leading to further improvements.
    \item Automated build pipelines and implementation of code-quality analysis also help identify potential sources of failures (but signal to noise ratio was low).
\end{enumerate}

Discuss the success factors, what led to the material improvements, and also the sorts of things that led to unexpected increases in failures. Also discuss the utility of the release management reports and of taking action accordingly. Possibly also discuss the value in separating pre-release and post-release sources of data, versioning of the releases, etc.cd 

\section{Minor contributions to opensource analytics tools}
TODO The content needs to be relocated to the Tools chapter.

\section{Source code analysis}
TODO ditto, relocate the results.

\section{Crashlytics}

\subsection{Crashlytics: Experiences of using mobile analytics}
The action research came from observing, analysing, and using Crashlytics during the Catrobat case study. We used the legacy Fabric user interface for approximately six months and then transitioned to the Firebase Analytics user interface for the reporting. The app continued to use the Fabric version of the Crashlytics SDK for the duration of the case study. In preparation for the workshop in Poland, scheduled on \nth{28} February 2020, the project also chose to incorporate Firebase Analytics to both the Android and iOS Pocket Code apps. On discovering that Firebase included demographic data the project leadership decided \emph{not} to migrate to the Firebase Crashlytics SDK and not to further the use of Firebase Analytics in order to protect the end users' privacy. Many of the end users are minors who are school children and the project team was concerned that any use of in-app mobile analytics would need to be very carefully considered and weighed in terms of the impact.


\section{Firebase Analytics}

\subsection{Firebase Analytics: Experiences of using mobile analytics}
The experiences are as reported and/or demonstrated by developers interviewed in the case studies, and as observed in opensource repositories for Android apps.


\section{Google Play Console with Android Vitals}

\subsection{Google Play Console with Android Vitals: Experiences of using mobile analytics}
Working with Google Play Console and with Android Vitals permeates this research, the experiences include using it directly, working with copies of the outputs from the app-case studies and other Grey Data and Grey Literature sources, analysing source code for candidate elements of the tool, and discussions with the development team for this and other mobile analytics tools.

\section{Iteratively}

\subsection{Iteratively with Amplitude: Experiences of using mobile analytics}
Iteratively provided an online data design tool to define a schema for mobile analytics and another tool to configure the SDK to send the data to various third-party mobile analytics services via that service's respective SDK. They also provided software that developers can add to their build scripts in order to validate the app has the schema adequately implemented. The schema is versioned and changes to the schema automatically receive a higher version number.

Iteratively's tools were used to add mobile analytics reporting to a small Android app, called IDot developed as part of this research. The app is due to be opensourced and will be available at \url{https://github.com/commercetest/idot}. Iteratively was configured to use Amplitude as the destination mobile analytics service. We also developed a custom `crash' message using the schema tool and implemented the necessary code to trigger this in the Android app.

During the action research period Iteratively's tools were integrated into the Amplitude products and services where they also made other changes to these products and services. The research is, therefore, a snapshot of the services that were available at the time.

\section{Microsoft App Center}

\subsection{Microsoft App Center: Experiences of using mobile analytics}
Microsoft App Center was used directly for crash and error reporting. It was used interactively and through the reporting API Microsoft provides. For the commercial case study major issues were manually transferred to the project's bug tracking service and the bugs were actively managed and the underlying issues were generally addressed. Screenshots and pertinent statistics from App Center were entered into the bug tracking service as only a subset of the overall project team had direct access to any of the mobile analytics services. The project used the error reporting (non-fatal errors) extensively to analyse various operational aspects of the service the app provided in conjunction with the internal server-side APIs and services.

Microsoft App Center was the preferred mobile analytics service by the development team, partly as it included a UI they could use to link bug tracking to pertinent crashes and errors.

\section{Sentry}

\subsection{Sentry: Experiences of using mobile analytics}
Sentry was integrated into Local Halo's cross-platform app (for Android and iOS). Local Halo used the free tier, \emph{i.e.} they did not pay for the service, and they enabled a second account to support this research.

The account was configured to send reports and alerts by email, the reports were also checked online. Their API was evaluated which led to submitting some proposed improvements to their documentation in the form of a Pull Request, this was reviewed, improved, and then accepted~\footnote{\url{https://github.com/getsentry/sentry-docs/commits?author=julianharty}}.


  % exclusion_rationale = {}

@inproceedings{10.1145/3196398.3196434,
  author = {Mahmoudi, Mehran and Nadi, Sarah},
  title = {The Android Update Problem: An Empirical Study},
  year = {2018},
  isbn = {9781450357166},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3196398.3196434},
  doi = {10.1145/3196398.3196434},
  abstract = {
    Many phone vendors use Android as their underlying OS, but often extend it to add new functionality and to make it compatible with their specific phones. When a new version of Android is released, phone vendors need to merge or re-apply their customizations and changes to the new release. This is a difficult and time-consuming process, which often leads to late adoption of new versions. In this paper, we perform an empirical study to understand the nature of changes that phone vendors make, versus changes made in the original development of Android. By investigating the overlap of different changes, we also determine the possibility of having automated support for merging them. We develop a publicly available tool chain, based on a combination of existing tools, to study such changes and their overlap. As a proxy case study, we analyze the changes in the popular community-based variant of Android, LineageOS, and its corresponding Android versions. We investigate and report the common types of changes that occur in practice. Our findings show that 83\% of subsystems modified by LineageOS are also modified in the next release of Android. By taking the nature of overlapping changes into account, we assess the feasibility of having automated tool support to help phone vendors with the Android update problem. Our results show that 56\% of the changes in LineageOS have the potential to be safely automated.
  },
  booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
  pages = {220–230},
  numpages = {11},
  keywords = {Android, merge conflicts, software evolution, software merging},
  location = {Gothenburg, Sweden},
  series = {MSR '18},
  exclusion_rationale = {
    This research focuses on vendor specific modifications to the Android OS based on LineageOS. While it's interesting, it's not relevant to using analytics, doesn't touch on apps, and doesn't discuss software-in-use quality aspects.
  }
}

@inproceedings{10.1145/3052973.3052990,
    author = {Taylor, Vincent F. and Martinovic, Ivan},
    title = {To Update or Not to Update: Insights From a Two-Year Study of Android App Evolution},
    year = {2017},
    isbn = {9781450349444},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3052973.3052990},
    doi = {10.1145/3052973.3052990},
    abstract = {Although there are over 1,900,000 third-party Android apps in the Google Play Store,
    little is understood about how their security and privacy characteristics, such as
    dangerous permission usage and the vulnerabilities they contain, have evolved over
    time. Our research is two-fold: we take quarterly snapshots of the Google Play Store
    over a two-year period to understand how permission usage by apps has changed; and
    we analyse 30,000 apps to understand how their security and privacy characteristics
    have changed over the same two-year period. Extrapolating our findings, we estimate
    that over 35,000 apps in the Google Play Store ask for additional dangerous permissions
    every three months. Our statistically significant observations suggest that free apps
    and popular apps are more likely to ask for additional dangerous permissions when
    they are updated. Worryingly, we discover that Android apps are not getting safer
    as they are updated. In many cases, app updates serve to increase the number of distinct
    vulnerabilities contained within apps, especially for popular apps. We conclude with
    recommendations to stakeholders for improving the security of the Android ecosystem.},
    booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
    pages = {45–57},
    numpages = {13},
    keywords = {android, vulnerability, app, longitudinal, permission},
    location = {Abu Dhabi, United Arab Emirates},
    series = {ASIA CCS '17},
    exclusion_rationale = {
      The research work is interesting in terms of studying how Android apps tended to become more vulnerable and also to put the user's information at risk. They applied the OWASP Mobile Top 10 (from 2014, despite the 2016 list predating the paper being published~\url{https://owasp.org/www-project-mobile-top-10/}). They also encourage app stores to consider checking for vulnerabilities when apps are uploaded to the app store and the separation of permissions for libraries from those used by the core app. However I've decided the paper isn't sufficiently relevant to include in my thesis currently as:
      - It's dated
      - It doesn't actually answer the update question posed in the title, at least not from the end user's perspective
      - The focus is on security and privacy rather than the use of mobile analytics, or on reliability aspects.
      I may yet decide to include it depending on the focus my final thesis takes.
    }
}

@article{10.1109/MPRV.2011.1,
    author = {Butler, Margaret},
    title = {Android: Changing the Mobile Landscape},
    year = {2011},
    issue_date = {January 2011},
    publisher = {IEEE Educational Activities Department},
    address = {USA},
    volume = {10},
    number = {1},
    issn = {1536-1268},
    url = {https://doi.org/10.1109/MPRV.2011.1},
    doi = {10.1109/MPRV.2011.1},
    abstract = {The mobile phone landscape changed last year with the introduction of smart phones
    running Android, a platform marketed by Google. Android phones are the first credible
    threat to the iPhone market. Not only did Google target the same consumers as iPhone,
    it also aimed to win the hearts and minds of mobile application developers. On the
    basis of market share and the number of available apps, Android is a success.},
    journal = {IEEE Pervasive Computing},
    month = jan,
    pages = {4–7},
    numpages = {4},
    keywords = {Apple App Store, Android, iPhone, BlackBerry, App Inventor for Android, Technovation, Android, App Inventor for Android, iPhone, Apple App Store, BlackBerry, Technovation},
    exclusion_rationale = {Too early in the evolution of Android, seems also factually incorrect as Android launched in 2008. Not relevant, however it is cited by various papers of interest to my research, hence it's here to show I chose to exclude it.},
}

@inproceedings{musuvathi2008_finding_and_reproducing_heisenbugs,
  title={Finding and Reproducing Heisenbugs in Concurrent Programs.},
  author={Musuvathi, Madanlal and Qadeer, Shaz and Ball, Thomas and Basler, Gerard and Nainar, Piramanayagam Arumuga and Neamtiu, Iulian},
  year = {2008},
  exclusion_rationale = {TBD, I've yet to read the paper, hence this is on hold and not yet suitable to include in the thesis.}
}

@inproceedings{weissenbacher2012explaining,
  title={Explaining heisenbugs},
  author={Weissenbacher, Georg},
  booktitle={Runtime Verification},
  volume={9333},
  year={2012},
  url = {https://publik.tuwien.ac.at/files/PubDat_244157.pdf},
  abstract = {
    Heisenbugs are complex software bugs that alter their behaviour when attempts to isolate them are made. The term heisenbug is a pun on the name of physicist Werner Heisenberg and refers to bugs whose analysis is complicated by the probe effect, an unintended alteration of system behaviour caused by an observer.

    Heisenbugs are most prevalent in concurrent systems, where the interplay of multiple threads running on multi-core processors leads to intricate effects not anticipated by the developer. Faced with a heisenbug, it is the tedious task of the programmer to reproduce the erroneous behaviour and analyse its cause before the bug can be fixed.

    It is exactly in these situations that automated analyses are the most desirable. Model checkers and systematic testing tools, for instance, can automatically reproduce erroneous executions manifesting the bug. The subsequent inspection of the error trace, however, is still a time-consuming process that requires substantial insight. 

    My group developed two approaches to analyse erroneous executions and explain concurrency bugs, attacking the problem from different angles. In both cases, the goal is to allow the programmer to focus on the essence of the bug rather than the specifics of the failed execution. On the one hand, we use data mining to extract explanations from execution logs by juxtaposing successful runs of the program with failed executions. The resulting explanations highlight potentially problematic data dependencies that frequently occur in failing executions. The second approach relies on static analysis and automated reasoning to obtain a slice of an erroneous execution trace that reflects the core of the problem.

    After introducing both approaches, I will discuss their advantages as well as shortcomings, and explain differences regarding soundness and comprehensibility using case studies and empirical results.
  }
  exclusion_rationale = {This is solely an abstract. While it explains heisenbugs well I don't think I need to include an explanation of them. If I do, this will become a relevant reference.}
}

@InProceedings{10.1007/978-3-642-13166-0_32,
    author="Brito, Miguel A.
    and de S{\'a}-Soares, Filipe",
    editor="Lytras, Miltiadis D.
    and Ordonez De Pablos, Patricia
    and Avison, David
    and Sipior, Janice
    and Jin, Qun
    and Leal, Walter
    and Uden, Lorna
    and Thomas, Michael
    and Cervai, Sara
    and Horner, David",
    title="Computer Programming: Fail Fast to Learn Sooner",
    booktitle="Technology Enhanced Learning. Quality of Teaching and Educational Reform",
    year="2010",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="223--229",
    abstract="Computer programming is not only to know about the languages or the processes, it is essentially to know how to do it. This involves a constructivist approach in learning. For a newbie in computer programming it is hard to understand the difference between know-about disciplines and the know-how-to-do-it ones. This leads to failure because when they understand they aren't able to solve a programming problem it is usually too late to catch all the time meanwhile lost. Our solution is to get them to fail soon enough. This way they still have time to recover from an eventually bad start.",
    isbn="978-3-642-13166-0",
    exclusion_rationale = {The research is on undergraduate learning and how to help them learn in time. It's not on my topic at all.}
}

@INPROCEEDINGS{6624018,  
  author={Herzig, Kim and Zeller, Andreas},  
  booktitle={2013 10th Working Conference on Mining Software Repositories (MSR)},  
  title={The impact of tangled code changes}, 
  year={2013},
  volume={},
  number={}, 
  pages={121-130},
  abstract={When interacting with version control systems, developers often commit unrelated or loosely related code changes in a single transaction. When analyzing the version history, such tangled changes will make all changes to all modules appear related, possibly compromising the resulting analyses through noise and bias. In an investigation of five open-source Java projects, we found up to 15\% of all bug fixes to consist of multiple tangled changes. Using a multi-predictor approach to untangle changes, we show that on average at least 16.6\% of all source files are incorrectly associated with bug reports. We recommend better change organization to limit the impact of tangled changes.},  
  keywords={}, 
  doi={10.1109/MSR.2013.6624018}, 
  ISSN={2160-1860},
  month={May},
  exclusion_rationale = {The authors claim there is no impact of tangled commits ``Tangled change sets do not cause trouble in development." I disagree - they may cause trouble with reverting a subset of the changes in the commit. They may also increase the code review overhead as the reviewer needs to consider multiple purposes of the commit concurrently, etc.},
}

@INPROCEEDINGS{
  7886923,  
  author={Ray, Baishakhi and Hellendoorn, Vincent and Godhane, Saheel and Tu, Zhaopeng and Bacchelli, Alberto and Devanbu, Premkumar}, 
  booktitle={2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)},
  title={On the "Naturalness" of Buggy Code},  
  year={2016}, 
  volume={},  
  number={}, 
  pages={428-439},
  abstract={
    Real software, the kind working programmers produce by the kLOC to solve real-world problems, tends to be “natural”, like speech or natural language; it tends to be highly repetitive and predictable. Researchers have captured this naturalness of software through statistical models and used them to good effect in suggestion engines, porting tools, coding standards checkers, and idiom miners. This suggests that code that appears improbable, or surprising, to a good statistical language model is “unnatural” in some sense, and thus possibly suspicious. In this paper, we investigate this hypothesis. We consider a large corpus of bug fix commits (ca. 7,139), from 10 different Java projects, and focus on its language statistics, evaluating the naturalness of buggy code and the corresponding fixes. We find that code with bugs tends to be more entropic (i.e. unnatural), becoming less so as bugs are fixed. Ordering files for inspection by their average entropy yields cost-effectiveness scores comparable to popular defect prediction methods. At a finer granularity, focusing on highly entropic lines is similar in cost-effectiveness to some well-known static bug finders (PMD, FindBugs) and or- dering warnings from these bug finders using an entropy measure improves the cost-effectiveness of inspecting code implicated in warnings. This suggests that entropy may be a valid, simple way to complement the effectiveness of PMD or FindBugs, and that search-based bug-fixing methods may benefit from using entropy both for fault-localization and searching for fixes.},  
  keywords={},
  doi={10.1145/2884781.2884848},
  ISSN={1558-1225}, 
  month={May},
  exclusion_rationale = {This looks of interest, however it's currently off-topic. Might be of interest for future work?}
}

@inproceedings{10.1145/320719.322582,
    author = {Rekimoto, Jun},
    title = {Time-Machine Computing: A Time-Centric Approach for the Information Environment},
    year = {1999},
    isbn = {1581130759},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/320719.322582},
    doi = {10.1145/320719.322582},
    abstract = {This paper describes the concept of Time-Machine Computing (TMC), a time-centric approach
    to organizing information on computers. A system based on Time-Machine Computing allows
    a user to visit the past and the future states of computers. When a user needs to
    refer to a document that he/she was working on at some other time, he/she can travel
    in the time dimension and the system restores the computer state at that time. Since
    the user's activities on the system are automatically archived, the user's daily workspace
    is seamlessly integrated into the information archive. The combination of spatial
    information management of the desktop metaphor and time traveling allows a user to
    organize and archive information without being bothered by folder hierarchies or the
    file classification problems that are common in today's desktop environments. TMC
    also provides a mechanism for linking multiple applications and external information
    sources by exchanging time information. This paper describes the key features of TMC,
    a time-machine desktop environment called “TimeScape,” and several time-oriented application
    integration examples.},
    booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
    pages = {45–54},
    numpages = {10},
    keywords = {time-machine computing, information visualization, desktop environment, time traveling, inter-application communication, document management},
    location = {Asheville, North Carolina, USA},
    series = {UIST '99},
    exclusion_rationale = {This is an interesting concept and time-machines might be useful when testing mobile analytics, however it's too far removed from my actual PhD research to include.}
}

@INPROCEEDINGS{9058278,  
  author={Jain, Parita and Sharma, Anupam and Aggarwal, Puneet Kumar},  
  booktitle={2020 10th International Conference on Cloud Computing, Data Science   Engineering (Confluence)},  
  title={Key Attributes for a Quality Mobile Application}, 
  year={2020},  
  volume={}, 
  number={}, 
  pages={50-54}, 
  abstract={
    The innovative advancement of cell phones, the significance of the Internet in the present society and the blasting market of the mobile devices have upset the mobile software programming altogether known as the product quality of portable intuitive gadgets. The mobile software programming gets increasingly competent and complex, which enables designers to apply entrenched quality strategies and models, from the work area of software programming advancement to mobile software programming. But still, mobile software programming moreover still has its portable explicit qualities, comparing models and techniques that must be balanced for its use in the larger domain. In the following research, some of the key attributes that must be incorporated and taken care for developing a portable quality mobile applications are identified. The key attributes determined by investigating before developed quality models which allows enhancing knowledge that can be drifted in the near future.},  
  keywords={},  
  doi={10.1109/Confluence47617.2020.9058278},
  ISSN={},
  month={Jan},
  exclusion_rationale = {Excludes various key quality factors including security, stability, and performance. The article is too short to provide sufficient depth to apply it. In short, I'm not convinced their model is adequate.}
}

@ARTICLE{59,
  author={Boehm, B. W.}, 
  journal={Computer},  
  title={A spiral model of software development and enhancement},  
  year={1988},
  volume={21},
  number={5},
  pages={61-72},
  abstract={
    A short description is given of software process models and the issues they address. An outline is given of the process steps involved in the spiral model, an evolving risk-driven approach that provides a framework for guiding the software process, and its application to a software project is shown. A summary is given of the primary advantages and implications involved in using the spiral model and the primary difficulties in using it at its current incomplete level of elaboration.}, 
  keywords={},  
  doi={10.1109/2.59}, 
  ISSN={1558-0814}, 
  month={May},
  exclusion_rationale = {I'd hoped to find a discussion on the uncertainties in software development, it was partly addressed in this article but not in a way that seemed would apply to mobile app development (the paper predates them by many years).}
}

@online{raygun_homepage,
  title = {Error monitoring and crash reporting},
  url = {https://raygun.com/platform/crash-reporting},
  abstract = {
    Monitor and fix production errors with ease. Control the chaos around solving software bugs. Quickly diagnose problems in your codebase, enjoy faster development cycles and make sure users are having error free experiences.
  },
  claims = {
    Zero in on the root cause and replicate issues quickly with code-level diagnostics. Unlock end-to-end visibility into the errors and crashes that are detrimental to your customers’ experience. Stop relying on log files, or support tickets with incomplete information and solve issues quickly. See the full stack trace, environment, browser, version, OS, class name, host and more. Even identify the release or commit that introduced the issue. Filter through your errors by date, time, version, tag, host, OS, browser, custom tags and more. Reduce noise with configurable filters for machine name, version, IP address, hostname and more.
  },
  exclusion_rationale = {I don't know enough about their product or service to evaluate their claims here. I do refer to other sections of their website in my thesis.}
}

@Inbook{Wesslén1996,
    author="Wessl{\'e}n, Anders
    and Wohlin, Claes",
    editor="Bologna, Sandro
    and Bucci, Giacomo",
    title="Early Estimation of Software Reliability through Dynamic Analysis",
    bookTitle="Achieving Quality in Software: Proceedings of the third international conference on achieving quality in software, 1996",
    year="1996",
    publisher="Springer US",
    address="Boston, MA",
    pages="175--186",
    abstract="Early estimations and predictions of software quality attributes are essential to be in control of software development and to allow for delivery of software products which fulfil the requirements put on them. This paper focuses on a method enabling estimation and prediction of software reliability from the specification and design documents. The method is based on dynamic analysis of a well-defined high level description technique, and by applying usage-oriented analysis, it is illustrated, through a case study, how the reliability can be controlled. Furthermore, it is described how the output from the analysis can be used as an acceptance criterion of the design, as support in the planning process for the test phases to come and finally as a method to enable estimation and prediction of the reliability in the testing phase and operational phase. The method is still being evaluated and improved, but it can be concluded that so far the results are inspiring for the future.",
    isbn="978-0-387-34869-8",
    doi="10.1007/978-0-387-34869-8_15",
    url="https://doi.org/10.1007/978-0-387-34869-8_15",
    exclusion_rationale = {Having skim read the entire paper, I'm not convinced their approach would work for mobile apps or developer of those apps. For instance one of the team becomes the authoritative voice who needs to know how the software will be used. No-one knows how a mobile app will be used, and no-one has a complete understanding. Their case study is for what seems to be a relatively simple system intended for undergrads, not for real world scalable systems that have to survive in complex and challenging conditions. Their plot of MTBF and faults does not seem coherent.},
}

@article {Whitemedethics-2020-107061,
	author = {White, Lucie and van Basshuysen, Philippe},
	title = {Without a trace: Why did corona apps fail?},
	elocation-id = {medethics-2020-107061},
	year = {2021},
	doi = {10.1136/medethics-2020-107061},
	publisher = {Institute of Medical Ethics},
	abstract = {At the beginning of the COVID-19 pandemic, high hopes were put on digital contact tracing, using mobile phone apps to record and immediately notify contacts when a user reports as infected. Such apps can now be downloaded in many countries, but as second waves of COVID-19 are raging, these apps are playing a less important role than anticipated. We argue that this is because most countries have opted for app configurations that cannot provide a means of rapidly informing users of likely infections while avoiding too many false positive reports. Mathematical modelling suggests that differently configured apps have the potential to do this. These require, however, that some pseudonymised data be stored on a central server, which privacy advocates have cautioned against. We contend that their influential arguments are subject to two fallacies. First, they have tended to one-sidedly focus on the risks that centralised data storage entails for privacy, while paying insufficient attention to the fact that inefficient contact tracing involves ethical risks too. Second, while the envisioned system does entail risks of breaches, such risks are also present in decentralised systems, which have been falsely presented as {\textquoteleft}privacy preserving by design{\textquoteright}. When these points are understood, it becomes clear that we must rethink our approach to digital contact tracing in our fight against COVID-19.},
	issn = {0306-6800},
	URL = {https://jme.bmj.com/content/early/2021/01/08/medethics-2020-107061},
	eprint = {https://jme.bmj.com/content/early/2021/01/08/medethics-2020-107061.full.pdf},
	journal = {Journal of Medical Ethics},
	exclusion_rationale = {
	  An interesting article on the merits and risks of decentralised data storage and analysis by Covid-19 apps. However it doesn't mention other reasons the apps don't thrive such as poor reliability, etc. which is what this research concentrates on.
	}
	
@article{pub.1129492655,
 author = {Pietz, Jesse and McCoy, Scott and Wilck, Joseph H.},
 doi = {10.1080/0960085x.2020.1793698},
 journal = {European Journal of Information Systems},
 keywords = {},
 number = {4},
 pages = {1-17},
 title = {Chasing John Snow: data analytics in the COVID-19 era},
 url = {https://app.dimensions.ai/details/publication/pub.1129492655 and https://www.tandfonline.com/doi/pdf/10.1080/0960085X.2020.1793698?needAccess=true},
 volume = {29},
 year = {2020},
 exclusion_rationale = {
   This looks interesting in terms of data dashboard design, however it's too far removed from my current research to include.
 }
}

@INPROCEEDINGS{6384988,  
  author={Iqbal, Babar and Iqbal, Asif and Guimaraes, Mario and Khan, Kashif and Obaidli, Hanan Al},
  booktitle={2012 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery},
  title={Amazon Kindle Fire from a Digital Forensics Perspective},   year={2012}, 
  volume={}, 
  number={}, 
  pages={323-329},
  doi={10.1109/CyberC.2012.61},
  exclusion_rationale = {
    It's interesting work, however dated (from 2012 and based on the 1st release of the Kindle Fire OS). Similar, newer work would potentially be very interesting and help support the appendix on Amazon App development.
  },
  see_also = {Their 2013 paper https://doi.org/10.1007/978-3-319-14289-0_4},
}

@article{AHMAD2020110386,
    title = {StaDART: Addressing the problem of dynamic code updates in the security analysis of android applications},
    journal = {Journal of Systems and Software},
    volume = {159},
    pages = {110386},
    year = {2020},
    issn = {0164-1212},
    doi = {https://doi.org/10.1016/j.jss.2019.07.088},
    url = {https://www.sciencedirect.com/science/article/pii/S0164121219301530},
    author = {Maqsood Ahmad and Valerio Costamagna and Bruno Crispo and Francesco Bergadano and Yury Zhauniarovich},
    keywords = {Android, Dynamic code updates, Reflection, Dynamic class loading, Security analysis},
    abstract = {Dynamic code update techniques (Android Studio – support for dynamic delivery), such as dynamic class loading and reflection, enable Android apps to extend their functionality at runtime. At the same time, these techniques are misused by malware developers to transform a seemingly benign app into a malware, once installed on a real device. Among the corpus of evasive techniques used in modern real-world malware, evasive usage of dynamic code updates plays a key role. First, we demonstrate the ineffectiveness of existing tools to analyze apps in the presence of dynamic code updates using our test apps, i.e., Reflection-Bench and InboxArchiver. Second, we present StaDART, combining static and dynamic analysis of Android apps to reveal the concealed behavior of malware. StaDART performs dynamic code interposition using a vtable tampering technique for API hooking to avoid modifications to the Android framework. Furthermore, we integrate it with a triggering solution, DroidBot, to make it more scalable and fully automated. We present our evaluation results with a dataset of 2000 real world apps; containing 1000 legitimate apps and 1000 malware samples. The evaluation results with this dataset and Reflection-Bench show that StaDART reveals suspicious behavior that is otherwise hidden to static analysis tools.}
    exclusion_rationale = {I'm less interested in the security vulnerability aspects which is the main focus of this paper.}
}

@ARTICLE{8418369,  
  author={Gjoreski, Hristijan and Ciliberto, Mathias and Wang, Lin and Ordonez Morales, Francisco Javier and Mekki, Sami and Valentin, Stefan and Roggen, Daniel},
  journal={IEEE Access}, 
  title={The University of Sussex-Huawei Locomotion and Transportation Dataset for Multimodal Analytics With Mobile Devices},  
  year={2018},
  volume={6}, 
  number={}, 
  pages={42592-42604}, 
  abstract={
    Scientific advances build on reproducible researches which need publicly available benchmark data sets. The computer vision and speech recognition communities have led the way in establishing benchmark data sets. There are much less data sets available in mobile computing, especially for rich locomotion and transportation analytics. This paper presents a highly versatile and precisely annotated large-scale data set of smartphone sensor data for multimodal locomotion and transportation analytics of mobile users. The data set comprises seven months of measurements, collected from all sensors of four smartphones carried at typical body locations, including the images of a body-worn camera, while three participants used eight different modes of transportation in the south-east of the U.K., including in London. In total, 28 context labels were annotated, including transportation mode, participant's posture, inside/outside location, road conditions, traffic conditions, presence in tunnels, social interactions, and having meals. The total amount of collected data exceed 950 GB of sensor data, which corresponds to 2812 h of labeled data and 17 562 km of traveled distance. We present how we set up the data collection, including the equipment used and the experimental protocol. We discuss the data set, including the data curation process, the analysis of the annotations, and of the sensor data. We discuss the challenges encountered and present the lessons learned and some of the best practices we developed to ensure high quality data collection and annotation. We discuss the potential applications which can be developed using this large-scale data set. In particular, we present how a machine-learning system can use this data set to automatically recognize modes of transportations. Many other research questions related to transportation analytics, activity recognition, radio signal propagation and mobility modeling can be addressed through this data set. The full data set is being made available to the community, and a thorough preview is already published.}, 
  keywords={}, 
  doi={10.1109/ACCESS.2018.2858933}, 
  ISSN={2169-3536}, 
  month={},
  exclusion_rationale = {
    The data is from sensors and collected by 4 Huawei phones over a many months. It doesn't really overlap with my research.
  }
}

@inproceedings{10.5555/2886444.2886520,
    author = {Ng, Joanna},
    title = {Experience-Based Analytics},
    year = {2015},
    publisher = {IBM Corp.},
    address = {USA},
    abstract = {
      Data has been called the new oil. Despite of its high value, only one percent of the world's data has been extracted for its insights. Data analytics is currently available only to the technical elite of data and IT experts, completely out of reach for general users. End users today only have indirect access to insights, completely dependent on this technical elite. However, no exponential growth in the population of IT and data experts is fast enough to meet the demand of volume and speed of data analytics to go beyond today's one percent of data analyzed. We are far from the ultimate data utopia in which data analytics is provided as a utility, available to and accessible by general users in real time. This paper introduces experience-based analytics: analytics for end users in accessible forms that serve their data analytics requirements as individuals in real time, in a manner that is contextually relevant, transparent with cognitive insights and anticipation. The notion is for the data and IT experts to re-think from delivering analytics results to users as a final form of consumption, to a new paradigm in which general users are enable to perform their own analytics.},
    booktitle = {Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering},
    pages = {347–348},
    numpages = {2},
    keywords = {predictive analytics, prescriptive analytics, cognitive computing, data analytics, big data, data processing},
    location = {Markham, Canada},
    series = {CASCON '15},
    exclusion_rationale = {
      It might be interesting to present end users with reliability analytics however it is appropriate to first need to understand whether mobile analytics can help improve the quality of the work of the development team. This is also a very brief 2-page pape without much evidence or rigour.
    }
}

@ARTICLE{8854183,
  author={Agrawal, Amritanshu and Fu, Wei and Chen, Di and Shen, Xipeng and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering},  
  title={How to "DODGE" Complex Software Analytics},   
  year={2019}, 
  volume={},
  number={}, 
  pages={1-1}, 
  abstract={
  Machine learning techniques applied to software engineering tasks can be improved by hyperparameter optimization, i.e., automatic tools that find good settings for a learner's control parameters. We show that such hyperparameter optimization can be unnecessarily slow, particularly when the optimizers waste time exploring "redundant tunings", i.e., pairs of tunings which lead to indistinguishable results. By ignoring redundant tunings, DODGE, a tuning tool, runs orders of magnitude faster, while also generating learners with more accurate predictions than seen in prior state-of-the-art approaches.}, 
  keywords={},
  doi={10.1109/TSE.2019.2945020}, 
  ISSN={1939-3520},  
  month={},
  exclusion_rationale = {
    Although the title includes software analytics, they're not directly discussing software usage analytics such as mobile analytics. Furthermore, any tuning of the mobile analytics tools and services covered in my research is outside the scope of this research.
  }
}

@ARTICLE{585502,  
    author={Rosenblum, D.S. and Weyuker, E.J.}, 
    journal={IEEE Transactions on Software Engineering}, 
    title={Using coverage information to predict the cost-effectiveness of regression testing strategies},  
    year={1997},  
    volume={23},
    number={3}, 
    pages={146-156},  
    abstract={
      Selective regression testing strategies attempt to choose an appropriate subset of test cases from among a previously run test suite for a software system, based on information about the changes made to the system to create new versions. Although there has been a significant amount of research in recent years on the design of such strategies, there has been very little investigation of their cost-effectiveness. The paper presents some computationally efficient predictors of the cost-effectiveness of the two main classes of selective regression testing approaches. These predictors are computed from data about the coverage relationship between the system under test and its test suite. The paper then describes case studies in which these predictors were used to predict the cost-effectiveness of applying two different regression testing strategies to two software systems. In one case study, the TESTTUBE method selected an average of 88.1 percent of the available test cases in each version, while the predictor predicted that 87.3 percent of the test cases would be selected on average.
    },  
    keywords={},  
    doi={10.1109/32.585502}, 
    ISSN={1939-3520},  
    month={March},
    exclusion_rationale = {
      This paper may well be useful when I focus on software testing and coverage criteria. My first impressions are positive. It's not what I'm focusing on at the moment.
    }
    
    
@article{wong_be_2017,
	title = {Be more familiar with our enemies and pave the way forward: A review of the roles bugs played in software failures},
	volume = {133},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217301334},
	doi = {https://doi.org/10.1016/j.jss.2017.06.069},
	abstract = {There has been an increasing frequency of failures due to defective software that cost millions of dollars. Recent high profile incidents have drawn increased attention to the risks of failed software systems to the public. Yet aside from the Therac-25 case, very few incidents of software failure causing humans harm have been proven and widely reported. With increased government oversight and the expanded use of social networking for real time reporting of problems, we are only beginning to understand the potential for major injury or death related to software failures. However, debugging defective software can be costly and time consuming. Moreover, undetected bugs could induce great harm to the public when software systems are applied in safety-critical areas, such as consumer products, public infrastructure, transportation systems, etc. Therefore, it is vital that we remove these bugs as early as possible. To gain more understanding of the nature of these bugs, we review the reported software failures that have impacted the health, safety, and welfare of the public. A focus on lessons learned and implications for future software systems is also provided which acts as guidelines for engineers to improve the quality of their products and avoid similar failures from happening.},
	pages = {68--94},
	journaltitle = {Journal of Systems and Software},
	author = {Wong, W. Eric and Li, Xuelin and Laplante, Philip A.},
	date = {2017},
	keywords = {Accidents, Bugged software systems, Lessons learned, Mishaps, Software failures},
	exclusion_rationale = { 
	  An interesting paper on the contributions of software failures to various major real-world accidents. This paper appears to have been incorrectly cited by "A Study on Testers’ Learning Curve in Crowdsourced Software Testing". I cannot find any connection between the sentence in that paper and the contents of this paper.
	}
}

@ARTICLE{9435346,  
    author={Yao, Yongming and Huang, Song and Zong, Cheng and Liu, Erhu and Chen, Ning},
    journal={IEEE Access},  
    title={A Study on Testers’ Learning Curve in Crowdsourced Software Testing}, 
    year={2021}, 
    volume={9}, 
    number={}, 
    pages={77127-77137},  
    abstract={
      Recommending effective testers in crowdsourced software testing is a challenge. In this paper, we study the improvement of crowdsourced software testers' skills over time. We propose the project difficulty coefficient to eliminate the influence of the item on the tester's score. The hyperbolic learning curve model and exponential learning curve model are used to fit the learning ability of the testers. The experimental results show that when the test data is large, the exponential learning curve can better simulate the improvement of testers' skills.
    },  
    keywords={},  
    doi={10.1109/ACCESS.2021.3081592},
    ISSN={2169-3536},  
    month={},
    exclusion_rationale = {
      This paper has some interesting ideas on testers' effectiveness and the criteria they use to detect causes for their [in]effectiveness. However the paper seems to cite poorly (see above) and they effectively used students on a single crowdsourcing platform in China to support their claims. I'd need to spend far more time reading the paper to decide on its merit and relevance to my work.
    }
}


@article{gao_successes_2019,
	title = {Successes, challenges, and rethinking – an industrial investigation on crowdsourced mobile application testing},
	volume = {24},
	issn = {1573-7616},
	url = {https://doi.org/10.1007/s10664-018-9618-5},
	doi = {10.1007/s10664-018-9618-5},
	abstract = {The term crowdsourcing – a compound contraction of crowd and outsourcing – is a new paradigm for utilizing the power of crowds of people to facilitate large-scale tasks that are costly or time consuming with traditional methods. This paradigm offers mobile application companies the possibility to outsource their testing activities to crowdsourced testers (crowdtesters) who have various testing facilities and environments, as well as different levels of skills and expertise. With this so-called Crowdsourced Mobile Application Testing ({CMAT}), some of the well-recognized issues in testing mobile applications, such as multitude of mobile devices, fragmentation of device models, variety of {OS} versions, and omnifariousness of testing scenarios, could be mitigated. However, how effective is {CMAT} in practice? What are the challenges and issues presented by the process of applying {CMAT}? How can these issues and challenges be overcome and {CMAT} be improved? Although {CMAT} has attracted attention from both academia and industry, these questions have not been addressed or researched in depth based on a large-scale and real-life industrial study. Since June 2015, we have worked with Mooctest, Inc., a {CMAT} intermediary, on testing five real-life Android applications using their {CMAT} platform – Kikbug. Throughout the process, we have collected 1013 bug reports from 258 crowdtesters and found 247 bugs in total. This paper will present our industrial study thoroughly and give an insightful analysis to investigate the successes and challenges of applying {CMAT}.},
	pages = {537--561},
	number = {2},
	journaltitle = {Empirical Software Engineering},
	shortjournal = {Empirical Software Engineering},
	author = {Gao, Ruizhi and Wang, Yabin and Feng, Yang and Chen, Zhenyu and Eric Wong, W.},
	date = {2019-04-01},
	exclusion_rationale = {
	  This is an interesting paper and probably worth reading in future when I'm focusing on crowdsourced testing. It touches on finding crashes in mobile apps so has some overlap with my research, however I didn't find sufficient concrete information to cite it in my thesis. I also appreciated the discussion on the value of 'duplicate bugs'.
	}
}

@INPROCEEDINGS{4659256,
    author={Godfrey, Michael W. and German, Daniel M.}, 
    booktitle={2008 Frontiers of Software Maintenance},   
    title={The past, present, and future of software evolution},   
    year={2008},  
    volume={},  
    number={},  
    pages={129-138},  
    abstract={
      Change is an essential characteristic of software development, as software systems must respond to evolving requirements, platforms, and other environmental pressures. In this paper, we discuss the concept of software evolution from several perspectives. We examine how it relates to and differs from software maintenance. We discuss insights about software evolution arising from Lehmanpsilas laws of software evolution and the staged lifecycle model of Bennett and Rajlich. We compare software evolution to other kinds of evolution, from science and social sciences, and we examine the forces that shape change. Finally, we discuss the changing nature of software in general as it relates to evolution, and we propose open challenges and future directions for software evolution research.
    },
    keywords={}, 
    doi={10.1109/FOSM.2008.4659256}, 
    ISSN={}, 
    month={Sep.},
    exclusion_rationale = {
      It covers interesting topics however I'm not sure where it'd fit in my thesis:- perhaps in the discussion about mobile analytics tools needing to evolve, ditto apps needing to evolve? If so, it'd probably belong in the related works chapter. Laws 1, 7, and 8 do look relevant. 
    },
}

@INPROCEEDINGS{8933541,  
    author={Wang, Chong and Li, Ju and Liang, Peng and Daneva, Maya and Sinderen, Marten},  
    booktitle={2019 IEEE 27th International Requirements Engineering Conference Workshops (REW)},
    title={Developers' Eyes on the Changes of Apps: An Exploratory Study on App Changelogs},  
    year={2019},
    volume={}, 
    number={}, 
    pages={207-212},
    abstract={
      Release planning for mobile apps has only recently become an area of active research. As a result, little is known about the types of requirements that app developers pay the most attention to when releasing an app. This research uses the changelogs of apps to shed light on this. We report the results of an exploratory study in which we analyzed the requirements that dominate the changes of apps, according to a set of 3000 changelogs collected from 120 apps from three categories in the Apple App Store: Travel, Social networking, and Books. We analyzed the changelogs in terms of functional and non-functional requirements, from a developers' perspective. Our results suggest that developers' releases are by far more concerned with non-functional requirements than with functional requirements. We also found that usability and maintainability are the most frequently mentioned non-functional requirements (NFRs) in the changelogs. Surprisingly, reliability requirements formed only a fraction of the total number of NFRs addressed in all changelogs of apps in the three selected App Store categories.
    },  
    keywords={},  
    doi={10.1109/REW.2019.00042}, 
    ISSN={},  
    month={Sep.},
    exclusion_rationale = {
      The paper focuses on iOS apps in Apple's App Store rather than where I'm focusing (Google Play for Android apps). It has visible mistakes in the opening material e.g. contradictory claims of the number of Android apps, and bland claims that the number of apps will increase. The work appears to be based on the public release notes that accompany new releases of the iOS apps they're studying rather than my work which is in the use of mobile analytics. Where our work overlaps is mainly in the study of reliability of mobile apps.
    }
}

@article{pandey2019application,
  title={Application of fuzzy DEMATEL approach in analyzing mobile app issues},
  author={Pandey, Mamta and Litoriya, Ratnesh and Pandey, Prateek},
  journal={Programming and Computer Software},
  volume={45},
  number={5},
  pages={268--287},
  year={2019},
  publisher={Springer},
  doi = {10.1134/S0361768819050050},
  exclusion_rationale = {
    The opening material put me off entirely with specious claims. 
    The sources of the data being analysed are unclear and undated e.g. did any come from the BlackBerry store? if so, when were the reviews published? It's a pity as some of their claims would be relevant in terms of supporting my work however I can't trust it as evidence based on what I've read in this article.
    }
}

@inproceedings{han2014using,
  title={Using DEMATEL to analyze the quality characteristics of mobile applications},
  author={Han, Wen-Ming and Hsu, Cheng-Hsien and Yeh, Cheng-Yu},
  booktitle={Proc. of the International Conference on Future Information Engineering and Manufacturing Science},
  pages={131--134},
  year={2014},
  exclusion_rationale = {
    The method isn't described and nor are the volumes of responses, etc. Like the previous paper (which references this one) I'd love to have cited it but can't in conscience do so.
    }
}

@inproceedings{10.1145/1572272.1572291,
    author = {Sinha, Saurabh and Shah, Hina and G\"{o}rg, Carsten and Jiang, Shujuan and Kim, Mijung and Harrold, Mary Jean},
    title = {Fault Localization and Repair for Java Runtime Exceptions},
    year = {2009},
    isbn = {9781605583389},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1572272.1572291},
    doi = {10.1145/1572272.1572291},
    abstract = {This paper presents a new approach for locating and repairing faults that cause runtime exceptions in Java programs. The approach handles runtime exceptions that involve a flow of an incorrect value that finally leads to the exception. This important class of exceptions includes exceptions related to dereferences of null pointers, arithmetic faults (e.g., ArithmeticException), and type faults (e.g., ArrayStoreException). Given a statement at which such an exception occurred, the technique combines dynamic analysis (using stack-trace information) with static backward data-flow analysis (beginning at the point where the runtime exception occurred) to identify the source statement at which an incorrect assignment was made; this information is required to locate the fault. The approach also identifies the source statements that may cause this same exception on other executions, along with the reference statements that may raise an exception in other executions because of this incorrect assignment; this information is required to repair the fault. The paper also presents an application of our technique to null pointer exceptions. Finally, the paper describes an implementation of the null-pointer-exception analysis and a set of studies that demonstrate the advantages of our approach for locating and repairing faults in the program.},
    booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
    pages = {153–164},
    numpages = {12},
    keywords = {static analysis, fault localization, runtime exceptions, null dereference},
    location = {Chicago, IL, USA},
    series = {ISSTA '09},
    exclusion_rationale = {
      The work is relatively dated and not directly related to mobile apps. While there may well be useful connections and/or parallels in their approach the gaps are too great for me to justify spending the time on currently.
    }
}

@inproceedings{10.1145/3167918.3167942,
    author = {Imamura, Yuta and Uekawa, Hiroyuki and Ishihara, Yasuhiro and Sato, Masaya and Yamauchi, Toshihiro},
    title = {Web Access Monitoring Mechanism for Android Webview},
    year = {2018},
    isbn = {9781450354363},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3167918.3167942},
    doi = {10.1145/3167918.3167942},
    abstract = {In addition to conventional web browsers, WebView is used to display web content on Android. WebView is a component that enables the display of web content in mobile applications, and is extensively used. As WebView displays web content without having to redirect the user to web browsers, there is the possibility that unauthorized web access may be performed secretly via WebView, and information in Android may be stolen or tampered with. Therefore, it is necessary to monitor and analyze web access via WebView, particularly because attacks exploiting WebView have been reported. However, there is no mechanism for monitoring web access via WebView. In this work, the goals are to monitor web access via WebView and to analyze mobile applications using WebView. To achieve these goals, we propose a web access monitoring mechanism for Android WebView. In this paper, the design and implementation of a mechanism that does not require any modifications to the Android Framework and Linux kernel are presented for the Chromium Android System WebView app. In addition, this paper presents evaluation results for the proposed mechanism.},
    booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
    articleno = {1},
    numpages = {8},
    keywords = {webview, Android, web access monitoring},
    location = {Brisband, Queensland, Australia},
    series = {ACSW '18},
    exclusion_rationale = {
      This paper focuses on implementing HTTP request and response logging in a replacement for the core WebView component in Android 6.0.1 I'm not sure I agree with their claim that ``it is necessary to monitor and analyze web access via WebView". The work is also dated as Google have materially changed the WebView design and implementation several times since Android 6. Finally, their research isn't directly connected with mine - their focus is broadly on security, mine on mobile analytics to measure and help improve mobile analytics. 
    }
}

@article{emiliani_false_2000,
	Abstract = {Discusses the importance of precise communication as a prerequisite to achieving alignment between internal and external stakeholders. Consideration is given to popular management catch‐phrases in general, with specific analysis of the widely‐used statement: ``what gets measured gets managed''. The application of mathematical logic shows this to be a false statement, yet one that precipitates the management of measurements that may not add value as seen by the end‐use customer.},
	Author = {Emiliani, M.L.},
	Doi = {10.1108/00251740010694317},
	Issn = {0025-1747},
	Journal = {Management Decision},
	Month = jan,
	Number = {9},
	Pages = {612--615},
	Title = {The false promise of ``what gets measured gets managed''},
	Url = {https://doi.org/10.1108/00251740010694317},
	Urldate = {2022-06-08},
	Volume = {38},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1108/00251740010694317},
	Bdsk-Url-2 = {http://dx.doi.org/10.1108/00251740010694317}},
	exclusion_rationale = {
	  While this is an interesting and realistic assessment of the tosh management say in companies, it's not sufficiently in depth or on topic to cite as a counterpoint to arguing that what gets measured gets managed.
	}
}


@article{mcintosh_empirical_2016,
	title = {An empirical study of the impact of modern code review practices on software quality},
	volume = {21},
	issn = {1573-7616},
	url = {https://doi.org/10.1007/s10664-015-9381-9},
	doi = {10.1007/s10664-015-9381-9},
	abstract = {Software code review, i.e., the practice of having other team members critique changes to a software system, is a well-established best practice in both open source and proprietary software domains. Prior work has shown that formal code inspections tend to improve the quality of delivered software. However, the formal code inspection process mandates strict review criteria (e.g., in-person meetings and reviewer checklists) to ensure a base level of review quality, while the modern, lightweight code reviewing process does not. Although recent work explores the modern code review process, little is known about the relationship between modern code review practices and long-term software quality. Hence, in this paper, we study the relationship between post-release defects (a popular proxy for long-term software quality) and: (1) code review coverage, i.e., the proportion of changes that have been code reviewed, (2) code review participation, i.e., the degree of reviewer involvement in the code review process, and (3) code reviewer expertise, i.e., the level of domain-specific expertise of the code reviewers. Through a case study of the Qt, VTK, and ITK projects, we find that code review coverage, participation, and expertise share a significant link with software quality. Hence, our results empirically confirm the intuition that poorly-reviewed code has a negative impact on software quality in large systems using modern reviewing tools.},
	number = {5},
	journal = {Empirical Software Engineering},
	author = {McIntosh, Shane and Kamei, Yasutaka and Adams, Bram and Hassan, Ahmed E.},
	month = oct,
	year = {2016},
	pages = {2146--2189},
	exclusion_rationale = {
	    The topics align, and this paper does present post-release defects as an accepted proxy for a long-term measure of software quality. However it is too far removed from Android or mobile analytics to be included currently. Also they skip blithely past Android as a codebase as they accept 2\% of the code being reviewed when that's so unlikely to be true. Google instead performs many code reviews internally, outside the public eye. The codebase is extensively reviewed and often by experts who are highly competent software developers and engineers. 
	    
	    This paper might fit better with Developer Experience (DevEx).
	}
}

@misc{samsung_hossain2019_seven_mistakes_to_avoid_when_developing_for_the_galaxy_fold,
  title = {Seven Mistakes To Avoid When Developing For The Galaxy Fold},
  url = {https://developer.samsung.com/sdp/blog/en-us/2019/04/05/seven-mistakes-to-avoid-when-developing-for-the-galaxy-fold},
  author = {Md. Iqbal Hossain},
  year = {2019},
  publisher = {Samsung Developers},
  exclusion_rationale = {
    I think the article is too specific to the Samsung foldable devices to provide much insight beyond the specific instances where crashes could occur in poorly written Android apps where the crashes are triggered by the device being folded.
  }
}

@article{Weichbroth_Baj-Rogowska_2019, 
    title={Do online reviews reveal mobile application usability and user experience? The case of WhatsApp}, 
    volume={Vol. 18}, 
    ISSN={2300-5963}, 
    url={http://yadda.icm.edu.pl/baztech/element/bwmeta1.element.baztech-450fdfaf-caa5-4cc4-a644-8ff85d9744e7}, 
    journal={Annals of Computer Science and Information Systems}, 
    author={Weichbroth, Paweł and Baj-Rogowska, Anna}, 
    year={2019}, 
    pages={747–754},
    doi = {10.15439/2019F289},
    abstract = {
        The variety of hardware devices and the diversity of their users imposes new requirements and expectations on designers and developers of mobile applications (apps). While the Internet has enabled new forms of communication platform, online stores provide the ability to review apps. These informal online app reviews have become a viral form of electronic word-of-mouth (eWOM), covering a plethora of issues. In our study, we set ourselves the goal of investigating whether online reviews reveal usability and user experience (UUX) issues, being important quality-in-use characteristics. To address this problem, we used sentiment analysis techniques, with the aim of extracting relevant keywords from eWOM WhatsApp data. Based on the extracted keywords, we next identified the original users' reviews, and individually assigned each attribute and dimension to them. Eventually, the reported issues were thematically synthesized into 7 attributes and 8 dimensions. If one asks whether online reviews reveal genuine UUX issues, in this case, the answer is definitely affirmative.
    },
    exclusion_rationale = {
        Only 399 reviews were collected from Google Play, which seems a minute proportion of those for the WhatsApp app, which has 166 million reviews according to https://play.google.com/store/apps/details?id=com.whatsapp&hl=en_GB&gl=US on 09 July 2022. The paper seems to have simplistic conclusions e.g. eWOW works!
    }
}

@INPROCEEDINGS{8860063,  
    author={Weichbroth, Paweł and Baj-Rogowska, Anna},  
    booktitle={2019 Federated Conference on Computer Science and Information Systems (FedCSIS)},  
    title={Do Online Reviews Reveal Mobile Application Usability and User Experience? The Case of WhatsApp},   
    year={2019},  
    volume={}, 
    number={}, 
    pages={747-754},  
    abstract={
        The variety of hardware devices and the diversity of their users imposes new requirements and expectations on designers and developers of mobile applications (apps). While the Internet has enabled new forms of communication platform, online stores provide the ability to review apps. These informal online app reviews have become a viral form of electronic word-of-mouth (eWOM), covering a plethora of issues. In our study, we set ourselves the goal of investigating whether online reviews reveal usability and user experience (UUX) issues, being important quality-in-use characteristics. To address this problem, we used sentiment analysis techniques, with the aim of extracting relevant keywords from eWOM WhatsApp data. Based on the extracted keywords, we next identified the original users' reviews, and individually assigned each attribute and dimension to them. Eventually, the reported issues were thematically synthesized into 7 attributes and 8 dimensions. If one asks whether online reviews reveal genuine UUX issues, in this case, the answer is definitely affirmative.
    },  
    keywords={},  
    doi={10.15439/2019F289},  
    ISSN={2300-5963},  
    month={Sep.},
    exclusion_rationale = {
        A repeat of the above reference, I found that one first.
    }
}

@inproceedings{10.1145/3377811.3380328,
    author = {Bernal-C\'{a}rdenas, Carlos and Cooper, Nathan and Moran, Kevin and Chaparro, Oscar and Marcus, Andrian and Poshyvanyk, Denys},
    title = {Translating Video Recordings of Mobile App Usages into Replayable Scenarios},
    year = {2020},
    isbn = {9781450371216},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3377811.3380328},
    doi = {10.1145/3377811.3380328},
    abstract = {Screen recordings of mobile applications are easy to obtain and capture a wealth of information pertinent to software developers (e.g., bugs or feature requests), making them a popular mechanism for crowdsourced app feedback. Thus, these videos are becoming a common artifact that developers must manage. In light of unique mobile development constraints, including swift release cycles and rapidly evolving platforms, automated techniques for analyzing all types of rich software artifacts provide benefit to mobile developers. Unfortunately, automatically analyzing screen recordings presents serious challenges, due to their graphical nature, compared to other types of (textual) artifacts. To address these challenges, this paper introduces V2S, a lightweight, automated approach for translating video recordings of Android app usages into replayable scenarios. V2S is based primarily on computer vision techniques and adapts recent solutions for object detection and image classification to detect and classify user actions captured in a video, and convert these into a replayable test scenario. We performed an extensive evaluation of V2S involving 175 videos depicting 3,534 GUI-based actions collected from users exercising features and reproducing bugs from over 80 popular Android apps. Our results illustrate that V2S can accurately replay scenarios from screen recordings, and is capable of reproducing ≈89\% of our collected videos with minimal overhead. A case study with three industrial partners illustrates the potential usefulness of V2S from the viewpoint of developers.},
    booktitle = {Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering},
    pages = {309–321},
    numpages = {13},
    keywords = {screen recordings, bug reporting, object detection},
    location = {Seoul, South Korea},
    series = {ICSE '20},
    exclusion_rationale = {
        Their work is interesting and may be useful to help reproduce bugs that have been previously videoed, they do not investigate mobile analytics and nor does their approach suit working at a global app-store scale or for measuring the experiences of the majority of userbases. Screen recordings are not in widescale use, and in my experience their use is declining for mobile apps rather than becoming more prevalent so this work - while of interest for narrower, specific bug reproduction, etc. isn't likely to be adopted by mainstream app developers. This leaves aside additional topics such as complying with regulations such as GDPR.
    }
}

@inproceedings{nurmuradov2017_caret-hm-heatmapping-android-emulator,
    author = {Nurmuradov, Dmitry and Bryce, Renee},
    title = {Caret-HM: Recording and Replaying Android User Sessions with Heat Map Generation Using UI State Clustering},
    year = {2017},
    isbn = {9781450350761},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3092703.3098231},
    doi = {10.1145/3092703.3098231},
    abstract = {The Caret-HM framework allows Android developers to record and replay user sessions and convert them into heatmaps. One advantage of our framework over existing solutions is that it allows developers to control the environment while simplifying the recording process by giving users access to their applications via a web browser. The heatmap generation using Android user sessions and clustering UI states is a unique feature of our framework. Heat maps allow developers to identify the usage of application features for testing and guiding business decisions. We provide a qualitative comparison to the existing solutions. The video with demonstration is available at https://www.youtube.com/watch?v=eMSNAKM1Bj4},
    booktitle = {Proceedings of the 26th ACM SIGSOFT International Symposium on Software Testing and Analysis},
    pages = {400–403},
    numpages = {4},
    keywords = {Android, Heat Map, Web-based Android Emulator, Mobile, User Sessions},
    location = {Santa Barbara, CA, USA},
    series = {ISSTA 2017},
    exclusion_rationale = {
        Firstly it's demonstrated with Android emulators rather than real-world devices. Secondly it uses a toy demo app rather than real-world apps. This is too far removed from the world of app developers.
    }
}


@inproceedings{yildirim2019_ux_analytics_for_android_platforms,
  title={User Experience Analytics for Android Platforms},
  author={Y{\i}ld{\i}r{\i}m, {\.I}lkan},
  pages = {553--555},
  booktitle={ISAS2019-ENS - 3rd International Symposium on Innovative Approaches in Scientific Studies (Engineering and Natural Sciences)},
  url = {http://www.set-science.com/manage/uploads/ISAS2019-ENS_0042/SETSCI_ISAS2019-ENS_0042_00105.pdf},
  year = {2019},
  publisher = {SET Technology - Turkey},
  more_info = {http://www.set-science.com/index.php?go=d1001a2417e2b87d5b7c53e16c5e1675&conf_id=42&paper_id=105},
  volume = {4},
  address = {Ankara, Turkey},
  commentz = {This does not appear to be structured or run as a IEEE/ACM style conference and the citation is hard to ascertain.},
  exclusion_rationale = {
    From memory this paper was quite weak and given the lack of clarity of the extent of this being a peer-reviewed work, etc. it's unlikely to be a reference to depend on. Also the topic involves the use of AppSee and heatmapping which I've decided is too impractical for mainstream app developers to adopt (as discussed in my related works chapter).
  }
}

@mastersthesis{nystrom2011agile,
  title={Agile solo-defining and evaluating an agile software development process for a single software developer},
  author={Nystr{\"o}m, Anna},
  year={2011},
  publisher={Chalmers University of Technology},
  abstract = {
    The purpose of this thesis is to define an agile development process for software development. The development process is to be adapted for single developers working in collaboration with a customer.
    The market for smartphones has grown very quickly in the last few years. Both Apple’s product iPhone and a large range of smartphones running Android have reached market success. This type of phone can run many small applications for example games or utility programs. Many of these applications are developed by single developers. This increases the need for a well-adjusted development process for single developers.
    The process model was named Agile Solo and consisted of a number of compulsory practices to be carried out during the implementation phase of the project. Since the development process is agile the software is developed in weekly iterations. Preceding each iteration a meeting is held between the developer and the customer where they plan which tasks should be included in the coming iteration.
    After the definition of Agile Solo was completed the development process was tested in a project. An application for the operative system Android was developed in collaboration with software development company Abou AB. The application gave parents of preschool children the opportunity to report sick leave and vacation leave using their mobile phone.
    Using the development process during the implementation of the application was successful although some adjustments were made. For future solo projects the developer is recommended to use a tailored version of Agile Solo where the development process and its practices are adjusted during the project’s course.
  },
  exclusion_rationale = {
    This work is too limited to demonstrate it has been applied by a significant number of solo developers of mobile apps. It is based on a single developers (probably the masters student) developing a single mobile app. That's not bad BTW, nonetheless the approach hasn't been adopted widely so it's outside the scope of my research (on mobile analytics).
  },
}

@INPROCEEDINGS{7521555,  
    author={Pagotto, Tiago and Fabri, José Augusto and Lerario, Alexandre and Gonçalves, José Antonio},  
    booktitle={2016 11th Iberian Conference on Information Systems and Technologies (CISTI)},  
    title={Scrum solo: Software process for individual development},  
    year={2016},  
    volume={}, 
    number={},  
    pages={1-6},  
    abstract={
        In Brazil there are several small software companies with only one developer (solo developer). In a survey conducted by Secretaria de Política de Informática of Ministério de Ciência e Tecnologia has been indicated that about 60\% of market consolidated software companies started their activities with a single developer. The majority of these developers does not formally make use of a software process. At this point, this work aims to present a formal software process for solo developers - the Scrum Solo. Initially, the defined procedure was experienced in software development for the Laboratório de Inovação of Universidade Tecnológica Federal do Paraná. Afterwards, several students made use of Scrum Solo to elaborate their completion of course works. Nowadays, plenty software companies working with individual development benefit from the process described in this document.
    },
    keywords={},  
    doi={10.1109/CISTI.2016.7521555},  
    ISSN={},  
    month={June},
    exclusion_rationale = {
        From what I have gleaned from the paper, which is written mainly in Spanish, their approach was more widely adopted by students at a university (55 students did so) and some (8) of those students used the approach after they graduated. It's therefore a larger scale work than Scrum Solo ... DOI 10.1109/CISTI.2016.7521555 but still there's no evidence it's being used by solo developers of mobile apps.
    },
}

@ARTICLE{8978533,  
    author={Moyo, Sibonile and Mnkandla, Ernest},  
    journal={IEEE Access},  
    title={A Novel Lightweight Solo Software Development Methodology With Optimum Security Practices},  
    year={2020},
    volume={8},
    number={}, 
    pages={33735-33747}, 
    abstract={
        The diffusion of software into all areas of life and all forms of business, increases the demand for high-quality and secure software products. Software development methodologies are designed to improve the quality of software by incorporating practices that promote quality in the developed software. Software security is an important facet of software quality, particularly in this era, where most software is deployed for use over the Internet. Most research on developing high-quality and secure software is normally focused on teams at the expense of individual developers. In trying to fill this gap, in this paper we propose an agile secure-software development methodology. We design a methodology that promotes quality and security in the software products of solo developers. We integrate quality practices with lightweight security practices to produce agile secure software development practices. We draw quality practices from a solo software development framework designed in our previous study, while security practices are drawn from existing lightweight methodologies. We adapt Keramati and Mirian-Hosseinabadi's algorithm to integrate the two sets of practices, taking care to maintain an optimum degree of agility in the target methodology. We evaluate the utility of the resultant methodology through a case study. Results from the case study show that our proposed methodology can be used to build quality and secure software products without compromising the agility of the methodology.
    },  
    keywords={}, 
    doi={10.1109/ACCESS.2020.2971000},  
    ISSN={2169-3536}, 
    month={},
    exclusion_rationale = {
        A potentially laudable approach to help solo developers incorporate software security into their working practices. They only evaluated their approach in an academic context and they didn't seem to obtain any adoption from real-world mobile app developers. None of the devs in my case studies actively applied a security focus to their practices so this work is too far off-topic (OT) to be included in my research.
    }
}

@INPROCEEDINGS{6480419,  
    author={Tonelli, Adriano Olímpio and Bermejo, Paulo Henrique S. and Azevedo Santos, Mariana and Zambalde, André Luiz and Silva de Oliveira, Marcelo and Antonialli, Luiz Marcelo}, 
    booktitle={2013 46th Hawaii International Conference on System Sciences},  
    title={Agile Practices to Accelerate the Delivery of Software: A Quantitative Study with Software Professionals},
    year={2013},
    volume={}, 
    number={}, 
    pages={4771-4779}, 
    abstract={
        This study aims to investigate the perceptions of software professionals in relation with impact of agile practices to accelerate the delivery of software products. Quantitative data obtained from a sample of 109 professionals were collected and analyzed by Pearson correlation and factor analysis. The results of factor analysis showed that the perception of professionals in relation to agile practices can be grouped into seven factors. From the correlation analysis, it was observed that customer satisfaction is the main variable influencing the perceptions of professionals regarding the use of agile practices to meet the deadlines on software projects.
    },  
    keywords={}, 
    doi={10.1109/HICSS.2013.75}, 
    ISSN={1530-1605}, 
    month={Jan},
    exclusion_rationale = {
        Interesting but OT.
    }
}

@ARTICLE{8962332,  
    author={Osia, Seyed Ali and Shahin Shamsabadi, Ali and Sajadmanesh, Sina and Taheri, Ali and Katevas, Kleomenis and Rabiee, Hamid R. and Lane, Nicholas D. and Haddadi, Hamed}, 
    journal={IEEE Internet of Things Journal},  
    title={A Hybrid Deep Learning Architecture for Privacy-Preserving Mobile Analytics},  
    year={2020},  
    volume={7},  
    number={5},  
    pages={4505-4518},  
    abstract={
        Internet-of-Things (IoT) devices and applications are being deployed in our homes and workplaces. These devices often rely on continuous data collection to feed machine learning models. However, this approach introduces several privacy and efficiency challenges, as the service operator can perform unwanted inferences on the available data. Recently, advances in edge processing have paved the way for more efficient, and private, data processing at the source for simple tasks and lighter models, though they remain a challenge for larger and more complicated models. In this article, we present a hybrid approach for breaking down large, complex deep neural networks for cooperative, and privacy-preserving analytics. To this end, instead of performing the whole operation on the cloud, we let an IoT device to run the initial layers of the neural network, and then send the output to the cloud to feed the remaining layers and produce the final result. In order to ensure that the user's device contains no extra information except what is necessary for the main task and preventing any secondary inference on the data, we introduce Siamese fine-tuning. We evaluate the privacy benefits of this approach based on the information exposed to the cloud service. We also assess the local inference cost of different layers on a modern handset. Our evaluations show that by using Siamese fine-tuning and at a small processing cost, we can greatly reduce the level of unnecessary, potentially sensitive information in the personal data, thus achieving the desired tradeoff between utility, privacy, and performance.
    }, 
    keywords={}, 
    doi={10.1109/JIOT.2020.2967734}, 
    ISSN={2327-4662}, 
    month={May},
    exclusion_rationale = {
        The paper focuses on IoT devices, and isn't focused on the developer's use/application of mobile analytics. It might suit the discussion chapter. 
    },
}


@article{kaur_analytics_2021,
	title = {Analytics for measuring library use and satisfaction of mobile apps},
	volume = {38},
	issn = {0741-9058},
	url = {https://doi.org/10.1108/LHTN-04-2021-0014},
	doi = {10.1108/LHTN-04-2021-0014},
	abstract = {Purpose User review is a significant component of mobile app markets such as the Google Play Store, App Store, Microsoft Store and others. Users submit their reviews for downloaded apps on these sites in the form of star ratings and text reviews. Apps can contain huge volumes of feedback, making it difficult for the user and the developer to skim through thousands of such reviews to get an insight into usage and impact of such apps. Thus, the current study aims to assess the usage and satisfaction among users of the Mendeley’s Android app vs iOS app. Design/methodology/approach The analytics are performed by using Appbot analytics software which captured, monitored, measured and analyzed the review results for a particular period. Appbot provides easy-to-understand insights of an app using artificial intelligence algorithm tools. Findings The findings of the study reveal strong inclination, adoption and usage of Mendeley’s Android app compared to that of iOS among users. Originality/value The value of this research is in getting an insight of the pattern/behavior of users towards using apps on different platforms (Android vs iOS) and provides valuable results for the app developers in monitoring usage and enhancing features for the satisfaction of users. Without mobile app analytics, one will be blindly trying out different things without any evidence to back up their experiments.},
	number = {4},
	urldate = {2022-07-11},
	journal = {Library Hi Tech News},
	author = {Kaur, Simran and Chakravarty, Rupak},
	month = jan,
	year = {2021},
	pages = {10--12},
	exclusion_rationale = {
	    The library is one for books, etc. rather than a software library! Their focus is on measuring the satisfaction of using appbot to process users' reviews to try and determine the what users of both the Android and iOS Mendeley app think of that app on the respective platform. I don't think they're part of the development team or that their results would be used by the development team, therefore it's OT.
	}
},

@Article{electronics11020246,
    AUTHOR = {Ullah, Salim and Khan, Muhammad Sohail and Lee, Choonhwa and Hanif, Muhammad},
    TITLE = {Understanding Users&rsquo; Behavior towards Applications Privacy Policies},
    JOURNAL = {Electronics},
    VOLUME = {11},
    YEAR = {2022},
    NUMBER = {2},
    ARTICLE-NUMBER = {246},
    URL = {https://www.mdpi.com/2079-9292/11/2/246},
    ISSN = {2079-9292},
    ABSTRACT = {Recently, smartphone usage has increased tremendously, and smartphones are being used as a requirement of daily life, equally by all age groups. Smartphone operating systems such as Android and iOS have made it possible for anyone with development skills to create apps for smartphones. This has enabled smartphone users to download and install applications from stores such as Google Play, App Store, and several other third-party sites. During installation, these applications request resource access permissions from users. The resources include hardware and software like contact, memory, location, managing phone calls, device state, messages, camera, etc. As per Google&rsquo;s permission policy, it is the responsibility of the user to allow or deny any permissions requested by an app. This leads to serious privacy violation issues when an app gets illegal permission granted by a user (e.g., an app might request for granted map permission and there is no need for map permission in the app, and someone can thereby access your location by this app). This study investigates the behavior of the user when it comes to safeguarding their privacy while installing apps from Google Play. In this research, first, seven different applications with irrelevant permission requests were developed and uploaded to two different Play Store accounts. The apps were live for more than 12 months and data were collected through Play Store analytics as well as the apps&rsquo; policy page. The preliminary data analysis shows that only 20\% of users showed concern regarding their privacy and security either through interaction with the development team through email exchange or through commenting on the platform and other means accordingly.},
    DOI = {10.3390/electronics11020246},
    exclusion_rationale = {
        I wanted to like this paper, however there are some flaws that mean I'm reluctant to promote it. Table 1 (literacy rates by country) has errors in it, specifically for the UK and Zimbabwe literacy rates. Also their method for checking whether users read the privacy policy is a bit basic (nonetheless a fair start on how to measure an end user's engagement with it). For now, this paper will remain here. It might feature if I write more on privacy policies. I'd then also want to see if I can encourage them to correct the errors in their paper, I did try online but the website required me to create an acccount and I wasn't convinced that doing so would enable me to reach the authors of the paper.
    }
}


@article{not_yet_cited_lee2022_a_systematic_survey_on_android_api_usage_for_data_driven_analytics_with_smartphones,
    author = {Lee, Hansoo and Park, Joonyoung and Lee, Uichin},
    title = {A Systematic Survey on Android API Usage for Data-Driven Analytics with Smartphones},
    year = {2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3530814},
    doi = {10.1145/3530814},
    abstract = {Recent industrial and academic research has focused on data-driven analytics with smartphones by collecting user interaction, context, and device systems data through Application Programming Interfaces (APIs) and sensors. The Android OS provides various APIs to collect such mobile usage and sensor data for third-party developers. Usage Statistics API (US API) and Accessibility Service API (AS API) are representative Android APIs for collecting app usage data and are used for various research purposes as they can collect fine-grained interaction data (e.g., app usage history, user interaction type). Furthermore, other sensor APIs help to collect a user’s context and device state data, along with AS/US APIs. This review investigates mobile usage and sensor data-driven research using AS/US APIs, by categorizing the research purposes and the data types. In this paper, the surveyed studies are classified as follows: five themes and 21 subthemes, and a four-layer hierarchical data classification structure. This allows us to identify a data usage trend and derive insight into data collection according to research purposes. Several limitations and future research directions of mobile usage and sensor data-driven analytics research are discussed, including the impact of changes in the Android API versions on research, the privacy and data quality issues, and the mitigation of reproducibility risks with standardized data typology.},
    note = {Just Accepted},
    journal = {ACM Comput. Surv.},
    month = {apr},
    keywords = {data collection, Smartphone sensing, User interaction data, sensor, mobile device, smartphone, data driven, android accessibility, data analysis, Android API},
    exclusion_rationale = {
        This paper has an attractive illustration of Android APIs in Figure 1 and might be good to skim read to spot gaps in my literature review. It's not a core paper for my research so parking it for now.
    }
}

@INPROCEEDINGS{9284527,  
    author={Xiao, Jianmao and Chen, Shizhan and Chen, Shiping and Gao, Chao and Wu, Hongyue and Xue, Xiao and Feng, Zhiyong},  
    booktitle={2020 IEEE International Conference on Services Computing (SCC)},   
    title={Analytics on Health of Mobile Software Ecosystem Based on the Internal Operating Mechanism}, 
    year={2020}, 
    volume={}, 
    number={},
    pages={264-271},
    abstract={
        In addition to publishing and downloading mobile apps, Mobile App Store (MAS) has become the most important ecosystem on mobile smart devices, i.e., Mobile Software Ecosystem (MSECO). However, most of the existing work focus on the analysis of a single entity in MSECO, and rarely analyze the interaction between the entities (such as users, developers, etc.) in MSECO as well as the comprehensive effect of each entity to the entire ecosystem health. In this paper, we propose a method based on computational experiments to simulate and analyze the complex and dynamic interaction of various entities and, how these entities impact on health of MSECO. Firstly, a requirement-driven MSECO model named R-MSECO is established to break down the entire MSECO, which includes user-app interaction, developers-requirements interaction and macro-control of mobile platform three sub-models. Secondly, the health measurement method is proposed to measure the health of MSECO. Finally, we simulate the impact of the dynamic interaction of various entities on the health of MSECO based on computational experiments. The experimental results show that our method is helpful for mobile users to better understanding of the current state of MSECO as well as can provide a reference for developers and platform managers to make development and operation decisions, which is of great significance for the continued healthy development of MSECO.
    },  
    keywords={},  
    doi={10.1109/SCC49832.2020.00042},  
    ISSN={2474-2473}, 
    month={Nov},
    exclusion_rationale = {
        This appears to be a hypothetical and unrealistic model for measuring the health of a mobile app ecosystem. It has unrealistic expectations, not least that users provide requirements to app developers. Thankfully it's far removed from my research so I can park it here.
    }
}

@inproceedings{10.1145/3319535.3345658,
    author = {Rahman, Mizanur and Hernandez, Nestor and Recabarren, Ruben and Ahmed, Syed Ishtiaque and Carbunar, Bogdan},
    title = {The Art and Craft of Fraudulent App Promotion in Google Play},
    year = {2019},
    isbn = {9781450367479},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3319535.3345658},
    doi = {10.1145/3319535.3345658},
    abstract = {Black Hat App Search Optimization (ASO) in the form of fake reviews and sockpuppet accounts, is prevalent in peer-opinion sites, e.g., app stores, with negative implications on the digital and real lives of their users. To detect and filter fraud, a growing body of research has provided insights into various aspects of fraud posting activities, and made assumptions about the working procedures of the fraudsters from online data. However, such assumptions often lack empirical evidence from the actual fraud perpetrators. To address this problem, in this paper, we present results of both a qualitative study with 18 ASO workers we recruited from 5 freelancing sites, concerning activities they performed on Google Play, and a quantitative investigation with fraud-related data collected from other 39 ASO workers. We reveal findings concerning various aspects of ASO worker capabilities and behaviors, including novel insights into their working patterns, and supporting evidence for several existing assumptions. Further, we found and report participant-revealed techniques to bypass Google-imposed verifications, concrete strategies to avoid detection, and even strategies that leverage fraud detection to enhance fraud efficacy. We report a Google site vulnerability that enabled us to infer the mobile device models used to post more than 198 million reviews in Google Play, including 9,942 fake reviews. We discuss the deeper implications of our findings, including their potential use to develop the next generation fraud detection and prevention systems.},
    booktitle = {Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security},
    pages = {2437–2454},
    numpages = {18},
    keywords = {opinion spam, app store optimization, crowdturfing, search rank fraud, fake review},
    location = {London, United Kingdom},
    series = {CCS '19},
    exclusion_rationale = {
        This topic is already broadly covered via the AppWatcher paper. While there are some specifics here they don't materially affect the points I'm making.
    }
}

@inproceedings{10.1145/3077136.3080741,
    author = {Li, Shanshan and Caverlee, James and Niu, Wei and Kaghazgaran, Parisa},
    title = {Crowdsourced App Review Manipulation},
    year = {2017},
    isbn = {9781450350228},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3077136.3080741},
    doi = {10.1145/3077136.3080741},
    abstract = {With the rapid adoption of smartphones worldwide and the reliance on app marketplaces to discover new apps, these marketplaces are critical for connecting users with apps. And yet, the user reviews and ratings on these marketplaces may be strategically targeted by app developers. We investigate the use of crowdsourcing platforms to manipulate app reviews. We find that (i) apps targeted by crowdsourcing platforms are rated significantly higher on average than other apps; (ii) the reviews themselves arrive in bursts; (iii) app reviewers tend to repeat themselves by relying on some standard repeated text; and (iv) apps by the same developer tend to share a more similar language model: if one app has been targeted, it is likely that many of the other apps from the same developer have also been targeted.},
    booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
    pages = {1137–1140},
    numpages = {4},
    keywords = {crowdsourcing, user behavior, app reviews, manipulation},
    location = {Shinjuku, Tokyo, Japan},
    series = {SIGIR '17},
    exclusion_rationale = {
        This topic is already broadly covered via the AppWatcher paper. While there are some specifics here they don't materially affect the points I'm making.
    }
}

@INPROCEEDINGS{9024767,  
    author={Sahito, Sanam Fayaz and Gilal, Abdul Rehman and Abro, Rizwan Ali and Waqas, Ahmad and Shaikh, Khisaluddin},  
    booktitle={2019 13th International Conference on Mathematics, Actuarial Science, Computer Science and Statistics (MACS)}, 
    title={Research Publication Trends in Software Engineering},  
    year={2019},  
    volume={},
    number={},  
    pages={1-4}, 
    abstract={There has been outstanding growth in the field of Software Engineering. With this emergence, scholars of this area worked hard to produce researches that would really be effective in the progress of Software Engineering. New researchers always face number of problems while initiating any work. Lack of proper guideline and being progressing field, it becomes crucial to provide such detailed and up-to-date information about latest research publication trends in Software Engineering. This research has been conducted in order to address this problem and help the researcher community by providing them guidance. While conducting this study, about 57 research articles published only in 2018 have been considered from renowned Journal of Software Engineering. On the basis of title, abstract, content, contribution form, area, occurrences and citation, those articles are evaluated. Results show that software testing is on hype while comparing with development, maintenance, refactoring and management. MS scholars and PhD students surely get advantage after getting such information. This study is more focused on providing guidelines so that scholar community can emerge in a better way.
    },  
    keywords={},  
    doi={10.1109/MACS48846.2019.9024767},  
    ISSN={},  
    month={Dec},
    exclusion_rationale = {
        This paper provides a superficial guide intended to help post-graduate students pick topics that will be well cited in the field of software engineering. It has flaws in, e.g. the pie chart in Figure 1 should match the data presented in table 1 but doesn't (software testing should have roughly 50\% of the pie). Avoid this paper.
    }
}

@inproceedings{10.1145/3383219.3383238,
    author = {Patkar, Nitish and Ghafari, Mohammad and Nierstrasz, Oscar and Hotomski, Sofija},
    title = {Caveats in Eliciting Mobile App Requirements},
    year = {2020},
    isbn = {9781450377317},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3383219.3383238},
    doi = {10.1145/3383219.3383238},
    abstract = {Factors such as app stores or platform choices heavily affect functional and non-functional mobile app requirements. We surveyed 45 companies and interviewed ten experts to explore how factors that impact mobile app requirements are understood by requirements engineers in the mobile app industry.We observed the lack of knowledge in several areas. For instance, we observed that all practitioners were aware of data privacy concerns, however, they did not know that certain third-party libraries, usage aggregators, or advertising libraries also occasionally leak sensitive user data. Similarly, certain functional requirements may not be implementable in the absence of a third-party library that is either banned from an app store for policy violations or lacks features, for instance, missing desired features in ARKit library for iOS made practitioners turn to Android.We conclude that requirements engineers should have adequate technical experience with mobile app development as well as sufficient knowledge in areas such as privacy, security and law, in order to make informed decisions during requirements elicitation.},
    booktitle = {Proceedings of the Evaluation and Assessment in Software Engineering},
    pages = {180–189},
    numpages = {10},
    keywords = {requirements engineering, Mobile app development, requirements elicitation},
    location = {Trondheim, Norway},
    series = {EASE '20},
    exclusion_rationale = {
        This might yet fit in my thesis to indicate developers sometimes aren't aware of key considerations pertaining to the mobile apps they develop. For the moment it isn't necessary AFAIK.
        Their samples come from three European countries: Switzerland, Germany, and the Czech Republic.
    },
    extracts = {
        most of them [the survey participants] had no direct technical experience with mobile app development. [p. 180] (however the PDF doesn't have page numbers.)
        Review their threats to validity section if I need to extend mine. 
    }
}

@article{gawel1996_hertbergs_theory_of_motivation_and_maslows_hierarchy_of_needs_teachers_on_tclp,
    author = {Gawel, Joseph E.},
    year = {1996},
    title = {}Herzberg's Theory of Motivation and Maslow's Hierarchy of Needs},
    journal = {Practical Assessment, Research, and Evaluation},
    volume = {5},
    number = {11},
    doi =  {https://doi.org/10.7275/31qy-ea53},
    url = {https://scholarworks.umass.edu/pare/vol5/iss1/11},
    abstract = {
        Among various behavioral theories long generally believed and embraced by American business are those of Frederick Herzberg and Abraham Maslow. Herzberg, a psychologist, proposed a theory about job factors that motivate employees. Maslow, a behavioral scientist and contemporary of Herzberg's, developed a theory about the rank and satisfaction of various human needs and how people pursue these needs. These theories are widely cited in the business literature.
        In the education profession, however, researchers in the '80s raised questions about the applicability of Maslow's and Herzberg's theories to elementary and secondary school teachers: Do educators, in fact, fit the profiles of the average business employee? That is, do teachers (1) respond to the same motivators that Herzberg associated with employees in profit-making businesses and (2) have the same needs patterns as those uncovered by Maslow in his studies of business employees?
        This digest first provides brief outlines of the Herzberg and Maslow theories. It then summarizes a study by members of the Tennessee Career Ladder Program (TCLP). This study found evidence that the teachers in the program do not match the behavior of people employed in business. Specifically, the findings disagree with Herzberg in relation the importance of money as a motivator and, with Maslow in regard to the position of esteem in a person's hierarchy of needs.
    },
    exclusion_rationale = {
        Insufficiently relevant. It might fit in the discussion about developers and their motivations or where I'm applying Maslow's hierarchy of needs to software quality.
        
        Generally: This is a short, interesting short paper claims that teachers in the Tennessee Career Ladder Program (TLCP) considered salary as the most important hygiene factor, and the importance increased as the level of the position increased from level I to level III.
    }
}

@misc{wikipedia_maslows_hierarchy_of_needs,
  author = "{Wikipedia contributors}",
  title = "Maslow's hierarchy of needs --- {Wikipedia}{,} The Free Encyclopedia",
  year = "2020",
  url = "https://en.wikipedia.org/w/index.php?title=Maslow\%27s_hierarchy_of_needs&oldid=980201185",
  note = "[Online; accessed 29-September-2020]",
  exclusion_rationale = {
    Wikipedia is not to be cited where the original source exists in a citable form. So I've replaced this with the citation to Maslow's article from 1943. Finding and creating that citation took between 30 mins and over an hour as it was a needle in a haystack in the many and various copies and reprints, etc. of his work.
  }
}

@inproceedings{price2010_challenges_in_eliciting_privacy_and_usability_requirements_for_lifelogging,
  title={Challenges in eliciting privacy and usability requirements for lifelogging},
  author={Price, Blaine A},
  year={2010},
  url = {http://www.open.ac.uk/blogs/primma/wp-content/uploads/2010/09/Price-PUMP2010.pdf},
  exclusion_rationale = {
    This short (3 page) paper doesn't appear to have passed peer-review. It contains thoughts of the author about some of the likely challenges related to lifelogging. While there are parallels to collection of mobile analytics the paper wasn't looking in that direction so it has a weak connection to the subject of my research, too weak to include in my lit review.
  }
}

@misc{vanrappard2022_how_teams_spend_their_time,
    title = {How teams spend their time},
    author = {Steven van Rappard},
    year = {2022},
    url = {https://svanrappard.medium.com/how-teams-spend-their-time-4fa1dc2421cb},
    publisher = {{Medium Inc.}},
     exclusion_rationale = {
        This is a really motiviating article that ties in with recent discussions with Gordon Rugg on Meh, Ick, etc. and the like|dislike 2x2 matrix. It's only in the excluded bibliography as I doubt I'll discuss either work in my thesis.
     }
}

@article{10.1093/comjnl/43.2.95,
    author = {Randell, Brian},
    title = "{Turing Memorial Lecture Facing Up to Faults}",
    journal = {The Computer Journal},
    volume = {43},
    number = {2},
    pages = {95-106},
    year = {2000},
    month = {01},
    abstract = "{As individuals, organizations and indeed the world at large have become more dependent on computer-based systems, so there has been an ever-growing amount of research into means for improving the dependability of these systems. In particular, there has been much work on trying to gain an increased understanding of the many and varied types of faults that need to be prevented or tolerated in order to reduce the probability and severity of system failures. In this talk I discuss the assumptions that are often made by computing system designers regarding faults, survey a number of continuing issues related to fault tolerance, and identify some of the latest challenges facing researchers in this arena.}",
    issn = {0010-4620},
    doi = {10.1093/comjnl/43.2.95},
    url = {https://doi.org/10.1093/comjnl/43.2.95},
    eprint = {https://academic.oup.com/comjnl/article-pdf/43/2/95/1165299/430095.pdf},
     exclusion_rationale = {
        This is a good paper for generating ideas on faults, failures, reliability, dependability, etc. And it might fit well with my related work chapter, but for now I'll park it here in the excluded biography.
     },
}



@inproceedings{10.1145/1294261.1294275,
    author = {Tucek, Joseph and Lu, Shan and Huang, Chengdu and Xanthos, Spiros and Zhou, Yuanyuan},
    title = {Triage: Diagnosing Production Run Failures at the User's Site},
    year = {2007},
    isbn = {9781595935915},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1294261.1294275},
    doi = {10.1145/1294261.1294275},
    abstract = {Diagnosing production run failures is a challenging yet important task. Most previous work focuses on offsite diagnosis, i.e.development site diagnosis with the programmers present. This is insufficient for production-run failures as: (1) it is difficult to reproduce failures offsite for diagnosis; (2) offsite diagnosis cannot provide timely guidance for recovery or security purposes; (3)it is infeasible to provide a programmer to diagnose every production run failure; and (4) privacy concerns limit the release of information(e.g. coredumps) to programmers.To address production-run failures, we propose a system, called Triage, that automatically performs onsite software failure diagnosis at the very moment of failure. It provides a detailed diagnosis report, including the failure nature, triggering conditions, related code and variables, the fault propagation chain, and potential fixes. Triage achieves this by leveraging lightweight re-execution support to efficiently capture the failure environment and repeatedly replay the moment of failure, and dynamically--using different diagnosis techniques--analyze an occurring failure. Triage employs a failure diagnosis protocol that mimics the steps a human takes in debugging. This extensible protocol provides a framework to enable the use of various existing and new diagnosis techniques. We also propose a new failure diagnosis technique, delta analysis, to identify failure related conditions, code, and variables.We evaluate these ideas in real system experiments with 10 real software failures from 9 open source applications including four servers. Triage accurately diagnoses the evaluated failures, providing likely root causes and even the fault propagation chain, while keeping normal-run overhead to under 5\%. Finally, our user study of the diagnosis and repair of real bugs shows that Triage saves time (99.99\% confidence), reducing the total time to fix by almost half.},
    booktitle = {Proceedings of Twenty-First ACM SIGOPS Symposium on Operating Systems Principles},
    pages = {131–144},
    numpages = {14},
    keywords = {onsite, diagnosis, debugging},
    location = {Stevenson, Washington, USA},
    series = {SOSP '07},
    exclusion_rationale = {
        This is too specialised and relatively dated work. The concepts may be transferable, however that's too far removed from my current work to follow up currently.
    },
}

@article{10.1145/2110356.2110360,
    author = {Yuan, Ding and Zheng, Jing and Park, Soyeon and Zhou, Yuanyuan and Savage, Stefan},
    title = {Improving Software Diagnosability via Log Enhancement},
    year = {2012},
    issue_date = {February 2012},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {30},
    number = {1},
    issn = {0734-2071},
    url = {https://doi.org/10.1145/2110356.2110360},
    doi = {10.1145/2110356.2110360},
    abstract = {Diagnosing software failures in the field is notoriously difficult, in part due to the fundamental complexity of troubleshooting any complex software system, but further exacerbated by the paucity of information that is typically available in the production setting. Indeed, for reasons of both overhead and privacy, it is common that only the run-time log generated by a system (e.g., syslog) can be shared with the developers. Unfortunately, the ad-hoc nature of such reports are frequently insufficient for detailed failure diagnosis. This paper seeks to improve this situation within the rubric of existing practice. We describe a tool, LogEnhancer that automatically “enhances” existing logging code to aid in future post-failure debugging. We evaluate LogEnhancer on eight large, real-world applications and demonstrate that it can dramatically reduce the set of potential root failure causes that must be considered while imposing negligible overheads.},
    journal = {ACM Trans. Comput. Syst.},
    month = {feb},
    articleno = {4},
    numpages = {28},
    keywords = {program analysis, failure diagnostics, software diagnosability, debugging, Log},
    exclusion_rationale = {
        I agree with their opening statements in the abstract. Nonetheless their approach differs significantly and wasn't performed on mobile apps, so this paper isn't sufficiently related to cite AFAIK.
    }
}

@inproceedings{10.1145/3132747.3132769,
    author = {Bittau, Andrea and Erlingsson, \'{U}lfar and Maniatis, Petros and Mironov, Ilya and Raghunathan, Ananth and Lie, David and Rudominer, Mitch and Kode, Ushasree and Tinnes, Julien and Seefeld, Bernhard},
    title = {Prochlo: Strong Privacy for Analytics in the Crowd},
    year = {2017},
    isbn = {9781450350853},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3132747.3132769},
    doi = {10.1145/3132747.3132769},
    abstract = {The large-scale monitoring of computer users' software activities has become commonplace, e.g., for application telemetry, error reporting, or demographic profiling. This paper describes a principled systems architecture---Encode, Shuffle, Analyze (ESA)---for performing such monitoring with high utility while also protecting user privacy. The ESA design, and its Prochlo implementation, are informed by our practical experiences with an existing, large deployment of privacy-preserving software monitoring.With ESA, the privacy of monitored users' data is guaranteed by its processing in a three-step pipeline. First, the data is encoded to control scope, granularity, and randomness. Second, the encoded data is collected in batches subject to a randomized threshold, and blindly shuffled, to break linkability and to ensure that individual data items get "lost in the crowd" of the batch. Third, the anonymous, shuffled data is analyzed by a specific analysis engine that further prevents statistical inference attacks on analysis results.ESA extends existing best-practice methods for sensitive-data analytics, by using cryptography and statistical techniques to make explicit how data is elided and reduced in precision, how only common-enough, anonymous data is analyzed, and how this is done for only specific, permitted purposes. As a result, ESA remains compatible with the established workflows of traditional database analysis.Strong privacy guarantees, including differential privacy, can be established at each processing step to defend against malice or compromise at one or more of those steps. Prochlo develops new techniques to harden those steps, including the Stash Shuffle, a novel scalable and efficient oblivious-shuffling algorithm based on Intel's SGX, and new applications of cryptographic secret sharing and blinding. We describe ESA and Prochlo, as well as experiments that validate their ability to balance utility and privacy.},
    booktitle = {Proceedings of the 26th Symposium on Operating Systems Principles},
    pages = {441–459},
    numpages = {19},
    location = {Shanghai, China},
    series = {SOSP '17},
    exclusion_rationale = {
        Not developer or mobile app focused, so exclude. Could be relevant for work on logging or mobile analytics SDKs.
    }
}

@article{10.1145/3460345,
author = {He, Shilin and He, Pinjia and Chen, Zhuangbin and Yang, Tianyi and Su, Yuxin and Lyu, Michael R.},
    title = {A Survey on Automated Log Analysis for Reliability Engineering},
    year = {2021},
    issue_date = {July 2022},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    volume = {54},
    number = {6},
    issn = {0360-0300},
    url = {https://doi.org/10.1145/3460345},
    doi = {10.1145/3460345},
    abstract = {Logs are semi-structured text generated by logging statements in software source code. In recent decades, software logs have become imperative in the reliability assurance mechanism of many software systems, because they are often the only data available that record software runtime information. As modern software is evolving into a large scale, the volume of logs has increased rapidly. To enable effective and efficient usage of modern software logs in reliability engineering, a number of studies have been conducted on automated log analysis. This survey presents a detailed overview of automated log analysis research, including how to automate and assist the writing of logging statements, how to compress logs, how to parse logs into structured event templates, and how to employ logs to detect anomalies, predict failures, and facilitate diagnosis. Additionally, we survey work that releases open-source toolkits and datasets. Based on the discussion of the recent advances, we present several promising future directions toward real-world and next-generation automated log analysis.},
    journal = {ACM Comput. Surv.},
    month = {jul},
    articleno = {130},
    numpages = {37},
    keywords = {Log, log parsing, log mining, log compression, log analysis, logging},
    exclusion_rationale = {
        This will be relevant when I'm focusing on logging, not now though.
    }
}

@inproceedings{10.1145/3453483.3454101,
    author = {Zuo, Gefei and Ma, Jiacheng and Quinn, Andrew and Bhatotia, Pramod and Fonseca, Pedro and Kasikci, Baris},
    title = {Execution Reconstruction: Harnessing Failure Reoccurrences for Failure Reproduction},
    year = {2021},
    isbn = {9781450383912},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3453483.3454101},
    doi = {10.1145/3453483.3454101},
    abstract = {Reproducing production failures is crucial for software reliability. Alas, existing bug reproduction approaches are not suitable for production systems because they are not simultaneously efficient, effective, and accurate. In this work, we survey prior techniques and show that existing approaches over-prioritize a subset of these properties, and sacrifice the remaining ones. As a result, existing tools do not enable the plethora of proposed failure reproduction use-cases (e.g., debugging, security forensics, fuzzing) for production failures. We propose Execution Reconstruction (ER), a technique that strikes a better balance between efficiency, effectiveness and accuracy for reproducing production failures. ER uses hardware-assisted control and data tracing to shepherd symbolic execution and reproduce failures. ER’s key novelty lies in identifying data values that are both inexpensive to monitor and useful for eliding the scalability limitations of symbolic execution. ER harnesses failure reoccurrences by iteratively performing tracing and symbolic execution, which reduces runtime overhead. Whereas prior production-grade techniques can only reproduce short executions, ER can reproduce any reoccuring failure. Thus, unlike existing tools, ER reproduces fully replayable executions that can power a variety of debugging and reliabilty use cases. ER incurs on average 0.3\% (up to 1.1\%) runtime monitoring overhead for a broad range of real-world systems, making it practical for real-world deployment.},
    booktitle = {Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation},
    pages = {1155–1170},
    numpages = {16},
    keywords = {symbolic execution, debugging},
    location = {Virtual, Canada},
    series = {PLDI 2021},
    exclusion_rationale = {
        This might be of interest for future work, not yet though.
    }
}

@InProceedings{10.1007/978-3-030-12388-8_19,
    author="Kohli, Puneet
    and Chadha, Anjali",
    editor="Arai, Kohei
    and Bhatia, Rahul",
    title="Enabling Pedestrian Safety Using Computer Vision Techniques: A Case Study of the 2018 Uber Inc. Self-driving Car Crash",
    booktitle="Advances in Information and Communication",
    year="2020",
    publisher="Springer International Publishing",
    address="Cham",
    pages="261--279",
    abstract="Human lives are important. The decision to allow self-driving vehicles operate on our roads carries great weight. This has been a hot topic of debate between policy-makers, technologists and public safety institutions. The recent Uber Inc. self-driving car crash, resulting in the death of a pedestrian, has strengthened the argument that autonomous vehicle technology is still not ready for deployment on public roads. In this work, we analyze the Uber car crash and shed light on the question, ``Could the Uber Car Crash have been avoided?''. We apply state-of-the-art Computer Vision models to this highly practical scenario. More generally, our experimental results are an evaluation of various image enhancement and object recognition techniques for enabling pedestrian safety in low-lighting conditions using the Uber crash as a case study.",
    isbn="978-3-030-12388-8",
    exclusion_rationale = {
        I found this in the context of looking for research into the prevalence and use of vehicle dashcams. It isn't suitable to support my thesis given the gruesome subject - it'd unnecessarily distract the reader of my thesis. Nonetheless the work is very interesting e.g. for captur.ai's work, hence I'm recording it here.
    }
}

@article{MANTELERO2016238,
    title = {Personal data for decisional purposes in the age of analytics: From an individual to a collective dimension of data protection},
    journal = {Computer Law & Security Review},
    volume = {32},
    number = {2},
    pages = {238-255},
    year = {2016},
    issn = {0267-3649},
    doi = {https://doi.org/10.1016/j.clsr.2016.01.014},
    url = {https://www.sciencedirect.com/science/article/pii/S0267364916300280},
    author = {Alessandro Mantelero},
    keywords = {Big data, Right to privacy, Data protection, Group privacy, Collective interests, Data protection authorities, Risk assessment},
    abstract = {In the big data era, new technologies and powerful analytics make it possible to collect and analyse large amounts of data in order to identify patterns in the behaviour of groups, communities and even entire countries. Existing case law and regulations are inadequate to address the potential risks and issues related to this change of paradigm in social investigation. This is due to the fact that both the right to privacy and the more recent right to data protection are protected as individual rights. The social dimension of these rights has been taken into account by courts and policymakers in various countries. Nevertheless, the rights holder has always been the data subject and the rights related to informational privacy have mainly been exercised by individuals. This atomistic approach shows its limits in the existing context of mass predictive analysis, where the larger scale of data processing and the deeper analysis of information make it necessary to consider another layer, which is different from individual rights. This new layer is represented by the collective dimension of data protection, which protects groups of persons from the potential harms of discriminatory and invasive forms of data processing. On the basis of the distinction between individual, group and collective dimensions of privacy and data protection, the author outlines the main elements that characterise the collective dimension of these rights and the representation of the underlying interests.},
    exclusion_rationale = {
        This is more focused on the people aspects than monitoring of app failures and flaws so it's somewhat removed from my research. Nonetheless the concept of Group privacy is relevant. This might migrate into my thesis at some point.
    }
}

@ARTICLE{7814287,  
    author={Huang, Gang and Xu, Mengwei and Lin, Felix Xiaozhu and Liu, Yunxin and Ma, Yun and Pushp, Saumay and Liu, Xuanzhe},  
    journal={IEEE Transactions on Mobile Computing},  
    title={ShuffleDog: Characterizing and Adapting User-Perceived Latency of Android Apps},   year={2017},  volume={16},  number={10}, 
    pages={2913-2926}, 
    abstract={
    Numerous complains have been made by Android users who severely suffer from the sluggish response when interacting with their devices. However, very few studies have been conducted to understand the user-perceived latency or mitigate the UI-lagging problem. In this paper, we conduct the first systematic measurement study to quantify the user-perceived latency using typical interaction-intensive Android apps in running with and without background workloads. We reveal the insufficiency of Android system in ensuring the performance of foreground apps and therefore design a new system to address the insufficiency accordingly. We develop a lightweight tracker to accurately identify all delay-critical threads that contribute to the slow response of user interactions. We then build a resource manager that can efficiently schedule various system resources including CPU, I/O, and GPU, for optimizing the performance of these threads. We implement the proposed system on commercial smartphones and conduct comprehensive experiments to evaluate our implementation. Evaluation results show that our system is able to significantly reduce the user-perceived latency of foreground apps in running with aggressive background workloads, up to 10x, while incurring negligible system overhead of less than 3.1 percent CPU and 7 MB memory.
    },  
    keywords={},  
    doi={10.1109/TMC.2017.2651823}, 
    ISSN={1558-0660},  
    month={Oct},
    exclusion_rationale = {
        An interesting paper on how they managed to improve algorithms within Android to reduce user-perceived latency. It ties in with the work that reduces ANRs because of flaws in the algorithm that writes to SD-cards. In terms of my PhD this is relatively distant as it's OS and User centric rather than focusing on what developers can do, etc.
    }
}

@ARTICLE{8720158,  
    author={Guo, Bin and Ouyang, Yi and Guo, Tong and Cao, Longbing and Yu, Zhiwen},  
    journal={IEEE Access},   
    title={Enhancing Mobile App User Understanding and Marketing With Heterogeneous Crowdsourced Data: A Review},  
    year={2019}, 
    volume={7}, 
    number={}, 
    pages={68557-68571}, 
    abstract={The mobile app market has been surging in recent years. It has some key differentiating characteristics which make it different from traditional markets. To enhance mobile app development and marketing, it is important to study the key research challenges such as app user profiling, usage pattern understanding, popularity prediction, requirement and feedback mining, and so on. This paper reviews CrowdApp, a research field that leverages heterogeneous crowdsourced data for mobile app user understanding and marketing. We first characterize the opportunities of the CrowdApp, and then present the key research challenges and state-of-the-art techniques to deal with these challenges. We further discuss the open issues and future trends of the CrowdApp. Finally, an evolvable app ecosystem architecture based on heterogeneous crowdsourced data is presented.
    },  
    keywords={}, 
    doi={10.1109/ACCESS.2019.2918325}, 
    ISSN={2169-3536},  
    month={},
    exclusion_rationale = {
        The core of this paper provides a useful literature review of various aspects of research into mobile apps. However it then peters out with their proposal for a vague CrowdApp system that the authors consider would augment the collection of recommendations from end users and combine it with various other sources of existing data. They do not appear to have make any more effort into developing their concept.
    }
}


@article{spolaor2018_delta_data_extraction_and_logging_tool_for_android,  
  author={Spolaor, Riccardo and Santo, Elia Dal and Conti, Mauro}, 
  journal={IEEE Transactions on Mobile Computing}, 
  title={DELTA: Data Extraction and Logging Tool for Android},
  year={2018},  
  volume={17}, 
  number={6}, 
  pages={1289-1302},
  abstract={
    In recent years, the use of smartphones has increased exponentially, and so have their capabilities. Together with an increase in processing power, smartphones are now equipped with a variety of sensors and provide an extensive set of API. These capabilities allow us to extract data related to environment, user habits, and operating system itself. This data is extremely valuable in many research fields such as user authentication, intrusion, and information leaks detection. For these reasons, researchers need a solid and reliable logging tool to collect data from mobile devices. In this paper, we first survey the existing logging tools available on the Android platform, comparing their features and their impact on the system. Then, we present DELTA - Data Extraction and Logging Tool for Android, which improves the existing Android logging solutions in terms of flexibility, fine-grained tuning capabilities, extensibility, and available set of logging features. We fully implement DELTA and we run a thorough performance evaluation. The results show that our tool has a low impact on the performance of the system, on battery consumption, and on user experience. Finally, we make the DELTA source code available to the research community.},  
  keywords={},  
  doi={10.1109/TMC.2017.2762692}, 
  ISSN={1558-0660},  
  month={June},
  exclusion_rationale = {
        The researchers focus on providing dynamic, extensible logging for research-oriented logging within mobile apps. This is in principle relevant to logging by developers even if it's more research than practitioner oriented. 
        However, what tips the balance against including this research is the lack of availability of their source code (or at least I can't find it and their paper doesn't provide a link to it).
  }
}


@inproceedings{balagtas2009_a_methodology_and_framework_to_simplify_usability_analysis_of mobile_apps,
    title={A methodology and framework to simplify usability analysis of mobile applications},
    author={Balagtas-Fernandez, Florence and Hussmann, Heinrich},
    booktitle={2009 IEEE/ACM International Conference on Automated Software Engineering},
    pages={520--524},
    year={2009},
    organization={IEEE},
    abstract = {Usability analysis is an important step in software development in order to improve certain aspects of the system. However, it is often a challenge especially when it comes to evaluating applications running on mobile devices because of the restrictions posed by the device and the lack of supporting tools and software available to collect the necessary usability data. This paper proposes a methodology and framework to aid developers in preparing the mobile system for usability analysis. The focus is on the simplification of the developer's task in preparing the system for evaluation and the processing of the collected usability data by automating some of the tasks involved in the process.},
    exclusion_rationale = {
        This is a relatively old paper in the field of mobile apps. Their focus is on usability and finding ways to measure usability. I like their visuals of the developer tasks and their explanation of what's involved and various pertinent factors that would need to be addressed.
        
        Apparently they developed a small Android utility library called EvaHelper which generated output in GraphQL. They seem to also have some sort of integration with Anddroid DDMS (long since gone) to access logs and/or to use a demo Android app that generates the log messages. Sadly they do not publish the apps they used the software with, nor the source code (or even binaries) of the library and/or apps that used EvaHelper. 
    }
}

@article{Caputo_2022,
	doi = {10.1109/tdsc.2022.3146020},
	url = {https://doi.org/10.1109\%2Ftdsc.2022.3146020},
	year = 2022,
	publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
	pages = {1--1},
	author = {Davide Caputo and Francesco Pagano and Giovanni Bottino and Luca Verderame and Alessio Merlo},
	title = {You Can{\textquotesingle}t Always Get What You Want: Towards User-Controlled Privacy on Android},
	journal = {{IEEE} Transactions on Dependable and Secure Computing},
	abstract = {
	    Mobile applications (hereafter, apps) collect a plethora of information regarding the user behavior and his device through third-party analytics libraries. However, the collection and usage of such data raised several privacy concerns, mainly because the end-user - i.e., the actual owner of the data - is out of the loop in this collection process. Also, the existing privacy-enhanced solutions that emerged in the last years follow an "all or nothing" approach, leaving the user the sole option to accept or completely deny the access to privacy-related data.

        This work has the two-fold objective of assessing the privacy implications on the usage of analytics libraries in mobile apps and proposing a data anonymization methodology that enables a trade-off between the utility and privacy of the collected data and gives the user complete control over the sharing process. To achieve that, we present an empirical privacy assessment on the analytics libraries contained in the 4500 most-used Android apps of the Google Play Store between November 2020 and January 2021. Then, we propose an empowered anonymization methodology, based on MobHide, that gives the end-user complete control over the collection and anonymization process. Finally, we empirically demonstrate the applicability and effectiveness of such anonymization methodology thanks to HideDroid, a fully-fledged anonymization app for the Android ecosystem.
	},
	exclusion_rationale = {
	    This paper is interesting even if it's got flaws in (starting from their very overoptimistic 4.83m apps in Google Play when the maximum estimated number to 2022 is around 3.6m apps (in March 2018) according to the same source they used. https://www.statista.com/statistics/266210/number-of-available-applications-in-the-google-play-store/ (Note: this is a different URL that is publicly available.) Furthermore, since Sep 2018, with one exception (3,040,000 in Sep 2020) the number of apps has been under 3m, which doesn't match their claim of an ongoing increase.
	    
	    What I find most interesting is their patching of analytics messages and their measure of the acceptance rate by each of the server-side services. For whatever reason they weren't able to get to grips with protobuf so their acceptance rate for Firebase was abysmally low.
	    
	    Some of their data - the captured analytics requests is available in JSON format on kaggle.com https://www.kaggle.com/datasets/x3no21/android-analytics-requests-network-traffic which may be of interest in future.
	    
	    It's odd to see so much traffic going to the defunct safedk.com (Table 3). Also, it's not clear if they analysed amplitude's traffic or spoofed it, they cite amplitude's Android SDK in passing.
	    
	    The paper provides lots of interesting topics that aren't directly related to how devs use mobile analytics so it's currently excluded from my core thesis.
	}
}


@inproceedings{lee2014_user_interaction_based_profiling_system_for_android_app_tuning,
    author = {Lee, Seokjun and Yoon, Chanmin and Cha, Hojung},
    title = {User Interaction-Based Profiling System for Android Application Tuning},
    year = {2014},
    isbn = {9781450329682},
    publisher = {Association for Computing Machinery},
    url = {https://doi.org/10.1145/2632048.2636091},
    doi = {10.1145/2632048.2636091},
    abstract = {Quality improvement in mobile applications should be based on the consideration of several factors, such as users' diversity in spatio-temporal usage, as well as the device's resource usage, including battery life. Although application tuning should consider this practical issue, it is difficult to ensure the success of this process during the development stage due to the lack of information about application usage. This paper proposes a user interaction-based profiling system to overcome the limitations of development-level application debugging. In our system, the analysis of both device behavior and energy consumption is possible with fine-grained process-level application monitoring. By providing fine-grained information, including user interaction, system behavior, and power consumption, our system provides meaningful analysis for application tuning. The proposed method does not require the source code of the application and uses a web-based framework so that users can easily provide their usage data. Our case study with a few popular applications demonstrates that the proposed system is practical and useful for application tuning.},
    booktitle = {Proceedings of the 2014 ACM International Joint Conference on Pervasive and Ubiquitous Computing},
    pages = {289–299},
    numpages = {11},
    keywords = {mobile application, tuning, debugging, webbased framework, profiling, user interaction},
    address = {Seattle, Washington},
    series = {UbiComp '14},
    exclusion_rationale = {
        I like the idea their work is practical given it required users to upload usage data via a web-based framework. Their focus is more on profiling for battery use. 
        
        This is actually one of the key papers I cite from at industry conferences and events. Yet I don't know how best to integrate it into my thesis. It's the one that discusses whether a behaviour is desirable, or not. As my thesis focuses on failures in terms of stability/reliability there's a general perception/agreement that the failures are not desirable.  
        
        They didn't use mobile analytics AFAIK their analysis seemed to be 1-1 from data recorded through use of the app to understanding the behaviours. They modified the Android kernel (in Android 4.3) and incorporated software called AppScope.
        
        Their approach is complementary to using mobile analytics, and indeed it could find performance related bugs with the use of mobile analytics. However it required modifications to the Android kernel which means it's not viable for end-user devices (unless Google Android provides the mechanisms to collect and transmit the data). Also users would need to accept using devices with the additional data collection and Google would have to allow that data collection, and developers have the wherewithal to modify Android to add the necessary support.
    }
}

@ARTICLE{5137778,  
    author={Mitchener, Jonathan},  
    journal={Engineering & Technology},  
    title={Perfecting the ecosystem - [comms device ecosystems]},   
    year={2009},  
    volume={4},  
    number={8},  
    pages={70-71},  
    abstract={
        Ecosystems of software, services and accessories can help make mobile devices more attractive prospects. The idea of adding, deleting and managing content on a iPhone using the iTunes software has been extended with the latest release, so it now includes managing new applications software rather than just content. The App Store for iPhone is just about its most important feature, now that people have become accustomed to the innovations of the gadget-a multi-touch screen, the seamless combination of Wi-Fi and cellular data services, and an industrial-strength operating system.
    },  
    keywords={},  
    doi={10.1049/et.2009.0820},  
    ISSN={1750-9637},  
    month={May},
    exclusion_rationale = {
        Too far removed from my research, nonetheless it touches on the mobile phone ecosystem with a focus on Apple, so of interest.
    }
}

@article{KOCH20141423,
    title = {Joining a smartphone ecosystem: Application developers’ motivations and decision criteria},
    journal = {Information and Software Technology},
    volume = {56},
    number = {11},
    pages = {1423-1435},
    year = {2014},
    note = {Special issue on Software Ecosystems},
    issn = {0950-5849},
    doi = {https://doi.org/10.1016/j.infsof.2014.03.010},
    url = {https://www.sciencedirect.com/science/article/pii/S0950584914000718},
    author = {Stefan Koch and Markus Kerschbaum},
    keywords = {Smartphone operating systems, Application markets, Open innovation, User innovation, Motivation, Ecosystem management},
    abstract = {Context
    The ecosystems surrounding current smartphones operating systems, especially the application markets, provide significant value for customers and therefore possibilities for provider differentiation. Why do independent application developers and innovators join these ecosystems, and which factors influence their choice between different platform options?
    Objective
    This paper evaluates why innovators publish applications for smartphone operating systems, and which factors influence their choice between the two most common platforms, Android and Apple iOS, and leading them to join this respective ecosystem.
    Method
    A quantitative questionnaire containing questions related to demographics, motivational factors, factors impacting choice of platform and application publishing history. 113 Application developers from all over the world responded, relatively evenly split between the two operating systems.
    Results
    The main motivations are the experience of fun and intellectual stimulation during the process itself and learning of new skills or know-how. Financial gain, on the other hand, was found to be of less importance. There are also significant differences between the developers according to their preferred platform, e.g. iOS developers are more often motivated by financial gain. In choosing which ecosystem to join, network size, openness and entry barriers play major roles, and according to these criteria the two ecosystems are perceived to be significantly different. In addition, the toolkit quality is one of the most important factors for developers, but not a point of differentiation between the two ecosystems.
    Conclusion
    This paper complements prior research with the viewpoint of the developers themselves, focusing on how they perceive both technical and economic, as well as governance related aspects. In addition, most research so far has focused on one aspect only, mostly application markets, while this study assess the perception of the whole ecosystem, including end user device, markets and OS. It is concluded that the motivations and perceptions of developers comprise a major component in the creation and management of a large and diverse ecosystem, and that there exists a significant group of user innovators, who are not motivated by financial gain. There are several other aspects besides network size that drive the choice of platform. In addition, developers perceive hardware, software, marketplaces and other aspects as one single construct. Any platform owner therefore has to carefully consider and manage their expectations and perceptions.},
    exclusion_rationale = {
        I don't think I need this as evidence of the motivation of developers who want to create mobile apps, nonetheless if I do, here is a relevant paper from 2014.
    }
}

@INPROCEEDINGS{8618824,  
    author={Lachgar, Mohamed and Benouda, Hanane and Elfirdoussi, Selwa}, 
    booktitle={2018 International Symposium on Advanced Electrical and Communication Technologies (ISAECT)},  
    title={Android REST APIs: Volley vs Retrofit},   
    year={2018},  
    volume={},  
    number={},  
    pages={1-6},  
    abstract={
        In the old days, networking in Android was a nightmare. Nowadays the problem is to find out which solution fits better the project's necessities. Therefore, almost every Android applications use a Web REST API for data transfer. Previously, developers preferred to write their own code to retrieve and analyze data. However, they now have a whole range of REST client libraries, which can speed up development by reducing the coding efforts, and efficiently analyze data. The REST (Representational State Transfer) has become the most commonly used way for creating, publishing, and consuming Web services, exploiting JavaScript Object Notation (JSON) as a data exchange format. Android Volley and Retrofit are the most used libraries for accessing the REST Web APIs today. In this paper, we will present a comparative study between these two libraries, in order to disclose the advantages and limitations of each of them.
    },
    keywords={},  
    doi={10.1109/ISAECT.2018.8618824},  
    ISSN={},  
    month={Nov},
    exclusion_rationale = {
        This paper focuses on two REST APIs used in Android apps. It claims they are the most popular however it doesn't provide evidence to confirm this claim. I'm seeking research into the use of third-party libraries such as OkHttp which is mentioned but not covered in this paper. Their work is orthogonal to mine.
    }
}

@inproceedings{10.1145/3372787.3390433,
    author = {Gon\c{c}alves, Klinsman M. and Vaz, Yasmine G. and Cruz, Eberth F. and Silva, Rafael E. and Souza, Lineker and Azevedo, F\'{a}bio M. and Sardinha, Eduardo D. and Fonseca, Paulo and Pahins, C\'{\i}cero A. L.},
    title = {MoraySTF: A Novel Approach for Requirement Definition for GSD Projects in a Mobile Ecosystem},
    year = {2020},
    isbn = {9781450370936},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3372787.3390433},
    doi = {10.1145/3372787.3390433},
    abstract = {SIDIA is an R&amp;D Institute located in Manaus (AM) focused on research and software development. SIDIA works in partnership with the Global Device Manufacturer developing the Android operating system embedded in mobile devices (smartphones and tablets) for Latin America. This complex scenario involves the development of products in collaboration with partners in different locations to accomplish manufacturing schedules. This poses a challenge in managing software development projects. This experience report describes a tool-based approach aiming to improve the availability of resources (software and hardware under development) as well as the requirements management process. We also report the lessons learned and difficulties of adopting the tool-based approach in the software development process.},
    booktitle = {Proceedings of the 15th International Conference on Global Software Engineering},
    pages = {96–100},
    numpages = {5},
    keywords = {mobile remote access, requirements engineering, SW development process, GSD challenges},
    location = {Seoul, Republic of Korea},
    series = {ICGSE '20},
    exclusion_rationale = {
        I participated in this conference and discussed the work with one of the authors. They used OpenSTF as a basis for their automated testing which is relevant for demonstrating device farms are sometimes used. However IIRC they didn't use it for testing mobile apps and they didn't work with mobile analytics either.
    }
}

@INPROCEEDINGS{8115614,  
    author={Mao, Ke and Harman, Mark and Jia, Yue},
    booktitle={2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE)},   
    title={Crowd intelligence enhances automated mobile testing},  
    year={2017}, 
    volume={},
    number={}, 
    pages={16-26},  
    abstract={
        We show that information extracted from crowd-based testing can enhance automated mobile testing. We introduce Polariz, which generates replicable test scripts from crowd-based testing, extracting cross-app `motif' events: automatically-inferred reusable higher-level event sequences composed of lower-level observed event actions. Our empirical study used 434 crowd workers from Mechanical Turk to perform 1,350 testing tasks on 9 popular Google Play apps, each with at least 1 million user installs. The findings reveal that the crowd was able to achieve 60.5\% unique activity coverage and proved to be complementary to automated search-based testing in 5 out of the 9 subjects studied. Our leave-one-out evaluation demonstrates that coverage attainment can be improved (6 out of 9 cases, with no disimprovement on the remaining 3) by combining crowd-based and search-based testing.
    },  
    keywords={},  
    doi={10.1109/ASE.2017.8115614}, 
    ISSN={},  
    month={10},
    exclusion_rationale = {
        While this work is interesting in terms of combining human and automated software testing it's not necessarily on topic for my research. I like it for hybrid man+machine combinations and this might be relevant to work Bashar etc are doing on combining humans with robots (according to a chat with Arosha on 27 July 2022).
    }
}

@Article{Baltes2022,
    author={Baltes, Sebastian
    and Ralph, Paul},
    title={Sampling in software engineering research: a critical review and guidelines},
    journal={Empirical Software Engineering},
    year={2022},
    month={Apr},
    day={28},
    volume={27},
    number={4},
    pages={94},
    abstract={
        Representative sampling appears rare in empirical software engineering research. Not all studies need representative samples, but a general lack of representative sampling undermines a scientific field. This article therefore reports a critical review of the state of sampling in recent, high-quality software engineering research. The key findings are: (1) random sampling is rare; (2) sophisticated sampling strategies are very rare; (3) sampling, representativeness and randomness often appear misunderstood. These findings suggest that software engineering research has a generalizability crisis. To address these problems, this paper synthesizes existing knowledge of sampling into a succinct primer and proposes extensive guidelines for improving the conduct, presentation and evaluation of sampling in software engineering research. It is further recommended that while researchers should strive for more representative samples, disparaging non-probability sampling is generally capricious and particularly misguided for predominately qualitative research.
    },
    issn={1573-7616},
    doi={10.1007/s10664-021-10072-8},
    url={https://doi.org/10.1007/s10664-021-10072-8},
    exclusion_rationale = {
        This exclusion is temporary as this is a very long and indepth article which would take me hours to digest. That's not the best use of my time currently and while it might help me improve my methodology it's unlikely to help me improve the actual research at this stage in my thesis. 
    }
}

@inproceedings{10.1145/3368089.3409767,
author = {Hermann, Ben and Winter, Stefan and Siegmund, Janet},
    title = {Community Expectations for Research Artifacts and Evaluation Processes},
    year = {2020},
    isbn = {9781450370431},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3368089.3409767},
    doi = {10.1145/3368089.3409767},
    abstract = {Background. Artifact evaluation has been introduced into the software engineering and programming languages research community with a pilot at ESEC/FSE 2011 and has since then enjoyed a healthy adoption throughout the conference landscape. Objective. In this qualitative study, we examine the expectations of the community toward research artifacts and their evaluation processes. Method. We conducted a survey including all members of artifact evaluation committees of major conferences in the software engineering and programming language field since the first pilot and compared the answers to expectations set by calls for artifacts and reviewing guidelines. Results. While we find that some expectations exceed the ones expressed in calls and reviewing guidelines, there is no consensus on quality thresholds for artifacts in general. We observe very specific quality expectations for specific artifact types for review and later usage, but also a lack of their communication in calls. We also find problematic inconsistencies in the terminology used to express artifact evaluation’s most important purpose – replicability. Conclusion. We derive several actionable suggestions which can help to mature artifact evaluation in the inspected community and also to aid its introduction into other communities in computer science.},
    booktitle = {Proceedings of the 28th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    pages = {469–480},
    numpages = {12},
    keywords = {Artifact Evaluation, Replicability, Study, Reproducibility},
    location = {Virtual Event, USA},
    series = {ESEC/FSE 2020},
    exclusion_rationale = {
        This looks interesting but not core to my thesis. Something to revisit in future?
    }
}

@book{kitchenham2015evidence,
  title={Evidence-based software engineering and systematic reviews},
  author={Kitchenham, Barbara Ann and Budgen, David and Brereton, Pearl},
  volume={4},
  year={2015},
  publisher={CRC press},
  exclusion_rationale = {
    Mainly cost and the inability to obtain the book quickly and inexpensively. From reading the preview on Google Books it contains sensible advice. It doesn't seem to have pivotal content that'd supersede my other references.
  }
}

@article{clarke2013_teaching_thematic_analysis,
  title={Teaching thematic analysis: Overcoming challenges and developing strategies for effective learning},
  author={Clarke, Victoria and Braun, Virginia},
  journal={The psychologist},
  volume={26},
  number={2},
  year={2013},
  publisher={British Psychological Society},
  url = {https://uwe-repository.worktribe.com/preview/937606/Teaching},
  exclusion_rationale = {
    This is primarily about teaching thematic analysis - a good thing and an interesting paper. Nonetheless I don't currently have a need to cite it in my thesis as I already cite some of their other work on Thematic Analysis.
  }
}

@InProceedings{pareek2013_human_boosting,
  title = 	 {Human Boosting},
  author = 	 {Pareek, Harsh and Ravikumar, Pradeep},
  booktitle = 	 {Proceedings of the 30th International Conference on Machine Learning},
  pages = 	 {338--346},
  year = 	 {2013},
  editor = 	 {Dasgupta, Sanjoy and McAllester, David},
  volume = 	 {28},
  number =       {1},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Atlanta, Georgia, USA},
  month = 	 {17--19 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v28/pareek13.pdf},
  url = 	 {https://proceedings.mlr.press/v28/pareek13.html},
  abstract = 	 {
    Humans may be exceptional learners but they have biological limitations and moreover, inductive biases similar to machine learning algorithms. This puts limits on human learning ability and on the kinds of learning tasks humans can easily handle. In this paper, we consider the problem of “boosting” human learners to extend the learning ability of human learners and achieve improved performance on tasks which individual humans find difficult. We consider classification (category learning) tasks, propose a boosting algorithm for human learners and give theoretical justifications. We conduct experiments using Amazon’s Mechanical Turk on two synthetic datasets – a crosshair task with a nonlinear decision boundary and a gabor patch task with a linear boundary but which is inaccessible to human learners – and one real world dataset – the Opinion Spam detection task introduced in (Ott et al). Our results show that boosting human learners produces gains in accuracy and can overcome some fundamental limitations of human learners.
  },
  exclusion_rationale = {
    This is an interesting concept and the paper is cited in Soware Analytics, so what? (Menzies and Zimmermann 2013) for humans-in-the-loop in software analytics. However it's too far removed for me to cite in my thesis. I have forwarded the paper and the concept to captur.ai.
  }
}

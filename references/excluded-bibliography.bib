  % exclusion_rationale = {}

@inproceedings{10.1145/3196398.3196434,
  author = {Mahmoudi, Mehran and Nadi, Sarah},
  title = {The Android Update Problem: An Empirical Study},
  year = {2018},
  isbn = {9781450357166},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3196398.3196434},
  doi = {10.1145/3196398.3196434},
  abstract = {
    Many phone vendors use Android as their underlying OS, but often extend it to add new functionality and to make it compatible with their specific phones. When a new version of Android is released, phone vendors need to merge or re-apply their customizations and changes to the new release. This is a difficult and time-consuming process, which often leads to late adoption of new versions. In this paper, we perform an empirical study to understand the nature of changes that phone vendors make, versus changes made in the original development of Android. By investigating the overlap of different changes, we also determine the possibility of having automated support for merging them. We develop a publicly available tool chain, based on a combination of existing tools, to study such changes and their overlap. As a proxy case study, we analyze the changes in the popular community-based variant of Android, LineageOS, and its corresponding Android versions. We investigate and report the common types of changes that occur in practice. Our findings show that 83\% of subsystems modified by LineageOS are also modified in the next release of Android. By taking the nature of overlapping changes into account, we assess the feasibility of having automated tool support to help phone vendors with the Android update problem. Our results show that 56\% of the changes in LineageOS have the potential to be safely automated.
  },
  booktitle = {Proceedings of the 15th International Conference on Mining Software Repositories},
  pages = {220–230},
  numpages = {11},
  keywords = {Android, merge conflicts, software evolution, software merging},
  location = {Gothenburg, Sweden},
  series = {MSR '18},
  exclusion_rationale = {
    This research focuses on vendor specific modifications to the Android OS based on LineageOS. While it's interesting, it's not relevant to using analytics, doesn't touch on apps, and doesn't discuss software-in-use quality aspects.
  }
}

@inproceedings{10.1145/3052973.3052990,
    author = {Taylor, Vincent F. and Martinovic, Ivan},
    title = {To Update or Not to Update: Insights From a Two-Year Study of Android App Evolution},
    year = {2017},
    isbn = {9781450349444},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3052973.3052990},
    doi = {10.1145/3052973.3052990},
    abstract = {Although there are over 1,900,000 third-party Android apps in the Google Play Store,
    little is understood about how their security and privacy characteristics, such as
    dangerous permission usage and the vulnerabilities they contain, have evolved over
    time. Our research is two-fold: we take quarterly snapshots of the Google Play Store
    over a two-year period to understand how permission usage by apps has changed; and
    we analyse 30,000 apps to understand how their security and privacy characteristics
    have changed over the same two-year period. Extrapolating our findings, we estimate
    that over 35,000 apps in the Google Play Store ask for additional dangerous permissions
    every three months. Our statistically significant observations suggest that free apps
    and popular apps are more likely to ask for additional dangerous permissions when
    they are updated. Worryingly, we discover that Android apps are not getting safer
    as they are updated. In many cases, app updates serve to increase the number of distinct
    vulnerabilities contained within apps, especially for popular apps. We conclude with
    recommendations to stakeholders for improving the security of the Android ecosystem.},
    booktitle = {Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security},
    pages = {45–57},
    numpages = {13},
    keywords = {android, vulnerability, app, longitudinal, permission},
    location = {Abu Dhabi, United Arab Emirates},
    series = {ASIA CCS '17},
    exclusion_rationale = {
      The research work is interesting in terms of studying how Android apps tended to become more vulnerable and also to put the user's information at risk. They applied the OWASP Mobile Top 10 (from 2014, despite the 2016 list predating the paper being published~\url{https://owasp.org/www-project-mobile-top-10/}). They also encourage app stores to consider checking for vulnerabilities when apps are uploaded to the app store and the separation of permissions for libraries from those used by the core app. However I've decided the paper isn't sufficiently relevant to include in my thesis currently as:
      - It's dated
      - It doesn't actually answer the update question posed in the title, at least not from the end user's perspective
      - The focus is on security and privacy rather than the use of mobile analytics, or on reliability aspects.
      I may yet decide to include it depending on the focus my final thesis takes.
    }
}

@article{10.1109/MPRV.2011.1,
    author = {Butler, Margaret},
    title = {Android: Changing the Mobile Landscape},
    year = {2011},
    issue_date = {January 2011},
    publisher = {IEEE Educational Activities Department},
    address = {USA},
    volume = {10},
    number = {1},
    issn = {1536-1268},
    url = {https://doi.org/10.1109/MPRV.2011.1},
    doi = {10.1109/MPRV.2011.1},
    abstract = {The mobile phone landscape changed last year with the introduction of smart phones
    running Android, a platform marketed by Google. Android phones are the first credible
    threat to the iPhone market. Not only did Google target the same consumers as iPhone,
    it also aimed to win the hearts and minds of mobile application developers. On the
    basis of market share and the number of available apps, Android is a success.},
    journal = {IEEE Pervasive Computing},
    month = jan,
    pages = {4–7},
    numpages = {4},
    keywords = {Apple App Store, Android, iPhone, BlackBerry, App Inventor for Android, Technovation, Android, App Inventor for Android, iPhone, Apple App Store, BlackBerry, Technovation},
    exclusion_rationale = {Too early in the evolution of Android, seems also factually incorrect as Android launched in 2008. Not relevant, however it is cited by various papers of interest to my research, hence it's here to show I chose to exclude it.},
}

@inproceedings{musuvathi2008_finding_and_reproducing_heisenbugs,
  title={Finding and Reproducing Heisenbugs in Concurrent Programs.},
  author={Musuvathi, Madanlal and Qadeer, Shaz and Ball, Thomas and Basler, Gerard and Nainar, Piramanayagam Arumuga and Neamtiu, Iulian},
  year = {2008},
  exclusion_rationale = {TBD, I've yet to read the paper, hence this is on hold and not yet suitable to include in the thesis.}
}

@inproceedings{weissenbacher2012explaining,
  title={Explaining heisenbugs},
  author={Weissenbacher, Georg},
  booktitle={Runtime Verification},
  volume={9333},
  year={2012},
  url = {https://publik.tuwien.ac.at/files/PubDat_244157.pdf},
  abstract = {
    Heisenbugs are complex software bugs that alter their behaviour when attempts to isolate them are made. The term heisenbug is a pun on the name of physicist Werner Heisenberg and refers to bugs whose analysis is complicated by the probe effect, an unintended alteration of system behaviour caused by an observer.

    Heisenbugs are most prevalent in concurrent systems, where the interplay of multiple threads running on multi-core processors leads to intricate effects not anticipated by the developer. Faced with a heisenbug, it is the tedious task of the programmer to reproduce the erroneous behaviour and analyse its cause before the bug can be fixed.

    It is exactly in these situations that automated analyses are the most desirable. Model checkers and systematic testing tools, for instance, can automatically reproduce erroneous executions manifesting the bug. The subsequent inspection of the error trace, however, is still a time-consuming process that requires substantial insight. 

    My group developed two approaches to analyse erroneous executions and explain concurrency bugs, attacking the problem from different angles. In both cases, the goal is to allow the programmer to focus on the essence of the bug rather than the specifics of the failed execution. On the one hand, we use data mining to extract explanations from execution logs by juxtaposing successful runs of the program with failed executions. The resulting explanations highlight potentially problematic data dependencies that frequently occur in failing executions. The second approach relies on static analysis and automated reasoning to obtain a slice of an erroneous execution trace that reflects the core of the problem.

    After introducing both approaches, I will discuss their advantages as well as shortcomings, and explain differences regarding soundness and comprehensibility using case studies and empirical results.
  }
  exclusion_rationale = {This is solely an abstract. While it explains heisenbugs well I don't think I need to include an explanation of them. If I do, this will become a relevant reference.}
}

@InProceedings{10.1007/978-3-642-13166-0_32,
    author="Brito, Miguel A.
    and de S{\'a}-Soares, Filipe",
    editor="Lytras, Miltiadis D.
    and Ordonez De Pablos, Patricia
    and Avison, David
    and Sipior, Janice
    and Jin, Qun
    and Leal, Walter
    and Uden, Lorna
    and Thomas, Michael
    and Cervai, Sara
    and Horner, David",
    title="Computer Programming: Fail Fast to Learn Sooner",
    booktitle="Technology Enhanced Learning. Quality of Teaching and Educational Reform",
    year="2010",
    publisher="Springer Berlin Heidelberg",
    address="Berlin, Heidelberg",
    pages="223--229",
    abstract="Computer programming is not only to know about the languages or the processes, it is essentially to know how to do it. This involves a constructivist approach in learning. For a newbie in computer programming it is hard to understand the difference between know-about disciplines and the know-how-to-do-it ones. This leads to failure because when they understand they aren't able to solve a programming problem it is usually too late to catch all the time meanwhile lost. Our solution is to get them to fail soon enough. This way they still have time to recover from an eventually bad start.",
    isbn="978-3-642-13166-0",
    exclusion_rationale = {The research is on undergraduate learning and how to help them learn in time. It's not on my topic at all.}
}

@INPROCEEDINGS{6624018,  
  author={Herzig, Kim and Zeller, Andreas},  
  booktitle={2013 10th Working Conference on Mining Software Repositories (MSR)},  
  title={The impact of tangled code changes}, 
  year={2013},
  volume={},
  number={}, 
  pages={121-130},
  abstract={When interacting with version control systems, developers often commit unrelated or loosely related code changes in a single transaction. When analyzing the version history, such tangled changes will make all changes to all modules appear related, possibly compromising the resulting analyses through noise and bias. In an investigation of five open-source Java projects, we found up to 15\% of all bug fixes to consist of multiple tangled changes. Using a multi-predictor approach to untangle changes, we show that on average at least 16.6\% of all source files are incorrectly associated with bug reports. We recommend better change organization to limit the impact of tangled changes.},  
  keywords={}, 
  doi={10.1109/MSR.2013.6624018}, 
  ISSN={2160-1860},
  month={May},
  exclusion_rationale = {The authors claim there is no impact of tangled commits ``Tangled change sets do not cause trouble in development." I disagree - they may cause trouble with reverting a subset of the changes in the commit. They may also increase the code review overhead as the reviewer needs to consider multiple purposes of the commit concurrently, etc.},
}

@INPROCEEDINGS{
  7886923,  
  author={Ray, Baishakhi and Hellendoorn, Vincent and Godhane, Saheel and Tu, Zhaopeng and Bacchelli, Alberto and Devanbu, Premkumar}, 
  booktitle={2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE)},
  title={On the "Naturalness" of Buggy Code},  
  year={2016}, 
  volume={},  
  number={}, 
  pages={428-439},
  abstract={
    Real software, the kind working programmers produce by the kLOC to solve real-world problems, tends to be “natural”, like speech or natural language; it tends to be highly repetitive and predictable. Researchers have captured this naturalness of software through statistical models and used them to good effect in suggestion engines, porting tools, coding standards checkers, and idiom miners. This suggests that code that appears improbable, or surprising, to a good statistical language model is “unnatural” in some sense, and thus possibly suspicious. In this paper, we investigate this hypothesis. We consider a large corpus of bug fix commits (ca. 7,139), from 10 different Java projects, and focus on its language statistics, evaluating the naturalness of buggy code and the corresponding fixes. We find that code with bugs tends to be more entropic (i.e. unnatural), becoming less so as bugs are fixed. Ordering files for inspection by their average entropy yields cost-effectiveness scores comparable to popular defect prediction methods. At a finer granularity, focusing on highly entropic lines is similar in cost-effectiveness to some well-known static bug finders (PMD, FindBugs) and or- dering warnings from these bug finders using an entropy measure improves the cost-effectiveness of inspecting code implicated in warnings. This suggests that entropy may be a valid, simple way to complement the effectiveness of PMD or FindBugs, and that search-based bug-fixing methods may benefit from using entropy both for fault-localization and searching for fixes.},  
  keywords={},
  doi={10.1145/2884781.2884848},
  ISSN={1558-1225}, 
  month={May},
  exclusion_rationale = {This looks of interest, however it's currently off-topic. Might be of interest for future work?}
}

@inproceedings{10.1145/320719.322582,
    author = {Rekimoto, Jun},
    title = {Time-Machine Computing: A Time-Centric Approach for the Information Environment},
    year = {1999},
    isbn = {1581130759},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/320719.322582},
    doi = {10.1145/320719.322582},
    abstract = {This paper describes the concept of Time-Machine Computing (TMC), a time-centric approach
    to organizing information on computers. A system based on Time-Machine Computing allows
    a user to visit the past and the future states of computers. When a user needs to
    refer to a document that he/she was working on at some other time, he/she can travel
    in the time dimension and the system restores the computer state at that time. Since
    the user's activities on the system are automatically archived, the user's daily workspace
    is seamlessly integrated into the information archive. The combination of spatial
    information management of the desktop metaphor and time traveling allows a user to
    organize and archive information without being bothered by folder hierarchies or the
    file classification problems that are common in today's desktop environments. TMC
    also provides a mechanism for linking multiple applications and external information
    sources by exchanging time information. This paper describes the key features of TMC,
    a time-machine desktop environment called “TimeScape,” and several time-oriented application
    integration examples.},
    booktitle = {Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology},
    pages = {45–54},
    numpages = {10},
    keywords = {time-machine computing, information visualization, desktop environment, time traveling, inter-application communication, document management},
    location = {Asheville, North Carolina, USA},
    series = {UIST '99},
    exclusion_rationale = {This is an interesting concept and time-machines might be useful when testing mobile analytics, however it's too far removed from my actual PhD research to include.}
}

@INPROCEEDINGS{9058278,  
  author={Jain, Parita and Sharma, Anupam and Aggarwal, Puneet Kumar},  
  booktitle={2020 10th International Conference on Cloud Computing, Data Science   Engineering (Confluence)},  
  title={Key Attributes for a Quality Mobile Application}, 
  year={2020},  
  volume={}, 
  number={}, 
  pages={50-54}, 
  abstract={
    The innovative advancement of cell phones, the significance of the Internet in the present society and the blasting market of the mobile devices have upset the mobile software programming altogether known as the product quality of portable intuitive gadgets. The mobile software programming gets increasingly competent and complex, which enables designers to apply entrenched quality strategies and models, from the work area of software programming advancement to mobile software programming. But still, mobile software programming moreover still has its portable explicit qualities, comparing models and techniques that must be balanced for its use in the larger domain. In the following research, some of the key attributes that must be incorporated and taken care for developing a portable quality mobile applications are identified. The key attributes determined by investigating before developed quality models which allows enhancing knowledge that can be drifted in the near future.},  
  keywords={},  
  doi={10.1109/Confluence47617.2020.9058278},
  ISSN={},
  month={Jan},
  exclusion_rationale = {Excludes various key quality factors including security, stability, and performance. The article is too short to provide sufficient depth to apply it. In short, I'm not convinced their model is adequate.}
}

@ARTICLE{59,
  author={Boehm, B. W.}, 
  journal={Computer},  
  title={A spiral model of software development and enhancement},  
  year={1988},
  volume={21},
  number={5},
  pages={61-72},
  abstract={
    A short description is given of software process models and the issues they address. An outline is given of the process steps involved in the spiral model, an evolving risk-driven approach that provides a framework for guiding the software process, and its application to a software project is shown. A summary is given of the primary advantages and implications involved in using the spiral model and the primary difficulties in using it at its current incomplete level of elaboration.}, 
  keywords={},  
  doi={10.1109/2.59}, 
  ISSN={1558-0814}, 
  month={May},
  exclusion_rationale = {I'd hoped to find a discussion on the uncertainties in software development, it was partly addressed in this article but not in a way that seemed would apply to mobile app development (the paper predates them by many years).}
}

@online{raygun_homepage,
  title = {Error monitoring and crash reporting},
  url = {https://raygun.com/platform/crash-reporting},
  abstract = {
    Monitor and fix production errors with ease. Control the chaos around solving software bugs. Quickly diagnose problems in your codebase, enjoy faster development cycles and make sure users are having error free experiences.
  },
  claims = {
    Zero in on the root cause and replicate issues quickly with code-level diagnostics. Unlock end-to-end visibility into the errors and crashes that are detrimental to your customers’ experience. Stop relying on log files, or support tickets with incomplete information and solve issues quickly. See the full stack trace, environment, browser, version, OS, class name, host and more. Even identify the release or commit that introduced the issue. Filter through your errors by date, time, version, tag, host, OS, browser, custom tags and more. Reduce noise with configurable filters for machine name, version, IP address, hostname and more.
  },
  exclusion_rationale = {I don't know enough about their product or service to evaluate their claims here. I do refer to other sections of their website in my thesis.}
}

@Inbook{Wesslén1996,
    author="Wessl{\'e}n, Anders
    and Wohlin, Claes",
    editor="Bologna, Sandro
    and Bucci, Giacomo",
    title="Early Estimation of Software Reliability through Dynamic Analysis",
    bookTitle="Achieving Quality in Software: Proceedings of the third international conference on achieving quality in software, 1996",
    year="1996",
    publisher="Springer US",
    address="Boston, MA",
    pages="175--186",
    abstract="Early estimations and predictions of software quality attributes are essential to be in control of software development and to allow for delivery of software products which fulfil the requirements put on them. This paper focuses on a method enabling estimation and prediction of software reliability from the specification and design documents. The method is based on dynamic analysis of a well-defined high level description technique, and by applying usage-oriented analysis, it is illustrated, through a case study, how the reliability can be controlled. Furthermore, it is described how the output from the analysis can be used as an acceptance criterion of the design, as support in the planning process for the test phases to come and finally as a method to enable estimation and prediction of the reliability in the testing phase and operational phase. The method is still being evaluated and improved, but it can be concluded that so far the results are inspiring for the future.",
    isbn="978-0-387-34869-8",
    doi="10.1007/978-0-387-34869-8_15",
    url="https://doi.org/10.1007/978-0-387-34869-8_15",
    exclusion_rationale = {Having skim read the entire paper, I'm not convinced their approach would work for mobile apps or developer of those apps. For instance one of the team becomes the authoritative voice who needs to know how the software will be used. No-one knows how a mobile app will be used, and no-one has a complete understanding. Their case study is for what seems to be a relatively simple system intended for undergrads, not for real world scalable systems that have to survive in complex and challenging conditions. Their plot of MTBF and faults does not seem coherent.},
}

@article {Whitemedethics-2020-107061,
	author = {White, Lucie and van Basshuysen, Philippe},
	title = {Without a trace: Why did corona apps fail?},
	elocation-id = {medethics-2020-107061},
	year = {2021},
	doi = {10.1136/medethics-2020-107061},
	publisher = {Institute of Medical Ethics},
	abstract = {At the beginning of the COVID-19 pandemic, high hopes were put on digital contact tracing, using mobile phone apps to record and immediately notify contacts when a user reports as infected. Such apps can now be downloaded in many countries, but as second waves of COVID-19 are raging, these apps are playing a less important role than anticipated. We argue that this is because most countries have opted for app configurations that cannot provide a means of rapidly informing users of likely infections while avoiding too many false positive reports. Mathematical modelling suggests that differently configured apps have the potential to do this. These require, however, that some pseudonymised data be stored on a central server, which privacy advocates have cautioned against. We contend that their influential arguments are subject to two fallacies. First, they have tended to one-sidedly focus on the risks that centralised data storage entails for privacy, while paying insufficient attention to the fact that inefficient contact tracing involves ethical risks too. Second, while the envisioned system does entail risks of breaches, such risks are also present in decentralised systems, which have been falsely presented as {\textquoteleft}privacy preserving by design{\textquoteright}. When these points are understood, it becomes clear that we must rethink our approach to digital contact tracing in our fight against COVID-19.},
	issn = {0306-6800},
	URL = {https://jme.bmj.com/content/early/2021/01/08/medethics-2020-107061},
	eprint = {https://jme.bmj.com/content/early/2021/01/08/medethics-2020-107061.full.pdf},
	journal = {Journal of Medical Ethics},
	exclusion_rationale = {
	  An interesting article on the merits and risks of decentralised data storage and analysis by Covid-19 apps. However it doesn't mention other reasons the apps don't thrive such as poor reliability, etc. which is what this research concentrates on.
	}
	
@article{pub.1129492655,
 author = {Pietz, Jesse and McCoy, Scott and Wilck, Joseph H.},
 doi = {10.1080/0960085x.2020.1793698},
 journal = {European Journal of Information Systems},
 keywords = {},
 number = {4},
 pages = {1-17},
 title = {Chasing John Snow: data analytics in the COVID-19 era},
 url = {https://app.dimensions.ai/details/publication/pub.1129492655 and https://www.tandfonline.com/doi/pdf/10.1080/0960085X.2020.1793698?needAccess=true},
 volume = {29},
 year = {2020},
 exclusion_rationale = {
   This looks interesting in terms of data dashboard design, however it's too far removed from my current research to include.
 }
}

@INPROCEEDINGS{6384988,  
  author={Iqbal, Babar and Iqbal, Asif and Guimaraes, Mario and Khan, Kashif and Obaidli, Hanan Al},
  booktitle={2012 International Conference on Cyber-Enabled Distributed Computing and Knowledge Discovery},
  title={Amazon Kindle Fire from a Digital Forensics Perspective},   year={2012}, 
  volume={}, 
  number={}, 
  pages={323-329},
  doi={10.1109/CyberC.2012.61},
  exclusion_rationale = {
    It's interesting work, however dated (from 2012 and based on the 1st release of the Kindle Fire OS). Similar, newer work would potentially be very interesting and help support the appendix on Amazon App development.
  },
  see_also = {Their 2013 paper https://doi.org/10.1007/978-3-319-14289-0_4},
}

@article{AHMAD2020110386,
    title = {StaDART: Addressing the problem of dynamic code updates in the security analysis of android applications},
    journal = {Journal of Systems and Software},
    volume = {159},
    pages = {110386},
    year = {2020},
    issn = {0164-1212},
    doi = {https://doi.org/10.1016/j.jss.2019.07.088},
    url = {https://www.sciencedirect.com/science/article/pii/S0164121219301530},
    author = {Maqsood Ahmad and Valerio Costamagna and Bruno Crispo and Francesco Bergadano and Yury Zhauniarovich},
    keywords = {Android, Dynamic code updates, Reflection, Dynamic class loading, Security analysis},
    abstract = {Dynamic code update techniques (Android Studio – support for dynamic delivery), such as dynamic class loading and reflection, enable Android apps to extend their functionality at runtime. At the same time, these techniques are misused by malware developers to transform a seemingly benign app into a malware, once installed on a real device. Among the corpus of evasive techniques used in modern real-world malware, evasive usage of dynamic code updates plays a key role. First, we demonstrate the ineffectiveness of existing tools to analyze apps in the presence of dynamic code updates using our test apps, i.e., Reflection-Bench and InboxArchiver. Second, we present StaDART, combining static and dynamic analysis of Android apps to reveal the concealed behavior of malware. StaDART performs dynamic code interposition using a vtable tampering technique for API hooking to avoid modifications to the Android framework. Furthermore, we integrate it with a triggering solution, DroidBot, to make it more scalable and fully automated. We present our evaluation results with a dataset of 2000 real world apps; containing 1000 legitimate apps and 1000 malware samples. The evaluation results with this dataset and Reflection-Bench show that StaDART reveals suspicious behavior that is otherwise hidden to static analysis tools.}
    exclusion_rationale = {I'm less interested in the security vulnerability aspects which is the main focus of this paper.}
}

@ARTICLE{8418369,  
  author={Gjoreski, Hristijan and Ciliberto, Mathias and Wang, Lin and Ordonez Morales, Francisco Javier and Mekki, Sami and Valentin, Stefan and Roggen, Daniel},
  journal={IEEE Access}, 
  title={The University of Sussex-Huawei Locomotion and Transportation Dataset for Multimodal Analytics With Mobile Devices},  
  year={2018},
  volume={6}, 
  number={}, 
  pages={42592-42604}, 
  abstract={
    Scientific advances build on reproducible researches which need publicly available benchmark data sets. The computer vision and speech recognition communities have led the way in establishing benchmark data sets. There are much less data sets available in mobile computing, especially for rich locomotion and transportation analytics. This paper presents a highly versatile and precisely annotated large-scale data set of smartphone sensor data for multimodal locomotion and transportation analytics of mobile users. The data set comprises seven months of measurements, collected from all sensors of four smartphones carried at typical body locations, including the images of a body-worn camera, while three participants used eight different modes of transportation in the south-east of the U.K., including in London. In total, 28 context labels were annotated, including transportation mode, participant's posture, inside/outside location, road conditions, traffic conditions, presence in tunnels, social interactions, and having meals. The total amount of collected data exceed 950 GB of sensor data, which corresponds to 2812 h of labeled data and 17 562 km of traveled distance. We present how we set up the data collection, including the equipment used and the experimental protocol. We discuss the data set, including the data curation process, the analysis of the annotations, and of the sensor data. We discuss the challenges encountered and present the lessons learned and some of the best practices we developed to ensure high quality data collection and annotation. We discuss the potential applications which can be developed using this large-scale data set. In particular, we present how a machine-learning system can use this data set to automatically recognize modes of transportations. Many other research questions related to transportation analytics, activity recognition, radio signal propagation and mobility modeling can be addressed through this data set. The full data set is being made available to the community, and a thorough preview is already published.}, 
  keywords={}, 
  doi={10.1109/ACCESS.2018.2858933}, 
  ISSN={2169-3536}, 
  month={},
  exclusion_rationale = {
    The data is from sensors and collected by 4 Huawei phones over a many months. It doesn't really overlap with my research.
  }
}

@inproceedings{10.5555/2886444.2886520,
    author = {Ng, Joanna},
    title = {Experience-Based Analytics},
    year = {2015},
    publisher = {IBM Corp.},
    address = {USA},
    abstract = {
      Data has been called the new oil. Despite of its high value, only one percent of the world's data has been extracted for its insights. Data analytics is currently available only to the technical elite of data and IT experts, completely out of reach for general users. End users today only have indirect access to insights, completely dependent on this technical elite. However, no exponential growth in the population of IT and data experts is fast enough to meet the demand of volume and speed of data analytics to go beyond today's one percent of data analyzed. We are far from the ultimate data utopia in which data analytics is provided as a utility, available to and accessible by general users in real time. This paper introduces experience-based analytics: analytics for end users in accessible forms that serve their data analytics requirements as individuals in real time, in a manner that is contextually relevant, transparent with cognitive insights and anticipation. The notion is for the data and IT experts to re-think from delivering analytics results to users as a final form of consumption, to a new paradigm in which general users are enable to perform their own analytics.},
    booktitle = {Proceedings of the 25th Annual International Conference on Computer Science and Software Engineering},
    pages = {347–348},
    numpages = {2},
    keywords = {predictive analytics, prescriptive analytics, cognitive computing, data analytics, big data, data processing},
    location = {Markham, Canada},
    series = {CASCON '15},
    exclusion_rationale = {
      It might be interesting to present end users with reliability analytics however it is appropriate to first need to understand whether mobile analytics can help improve the quality of the work of the development team. This is also a very brief 2-page pape without much evidence or rigour.
    }
}

@ARTICLE{8854183,
  author={Agrawal, Amritanshu and Fu, Wei and Chen, Di and Shen, Xipeng and Menzies, Tim},
  journal={IEEE Transactions on Software Engineering},  
  title={How to "DODGE" Complex Software Analytics},   
  year={2019}, 
  volume={},
  number={}, 
  pages={1-1}, 
  abstract={
  Machine learning techniques applied to software engineering tasks can be improved by hyperparameter optimization, i.e., automatic tools that find good settings for a learner's control parameters. We show that such hyperparameter optimization can be unnecessarily slow, particularly when the optimizers waste time exploring "redundant tunings", i.e., pairs of tunings which lead to indistinguishable results. By ignoring redundant tunings, DODGE, a tuning tool, runs orders of magnitude faster, while also generating learners with more accurate predictions than seen in prior state-of-the-art approaches.}, 
  keywords={},
  doi={10.1109/TSE.2019.2945020}, 
  ISSN={1939-3520},  
  month={},
  exclusion_rationale = {
    Although the title includes software analytics, they're not directly discussing software usage analytics such as mobile analytics. Furthermore, any tuning of the mobile analytics tools and services covered in my research is outside the scope of this research.
  }
}

@ARTICLE{585502,  
    author={Rosenblum, D.S. and Weyuker, E.J.}, 
    journal={IEEE Transactions on Software Engineering}, 
    title={Using coverage information to predict the cost-effectiveness of regression testing strategies},  
    year={1997},  
    volume={23},
    number={3}, 
    pages={146-156},  
    abstract={
      Selective regression testing strategies attempt to choose an appropriate subset of test cases from among a previously run test suite for a software system, based on information about the changes made to the system to create new versions. Although there has been a significant amount of research in recent years on the design of such strategies, there has been very little investigation of their cost-effectiveness. The paper presents some computationally efficient predictors of the cost-effectiveness of the two main classes of selective regression testing approaches. These predictors are computed from data about the coverage relationship between the system under test and its test suite. The paper then describes case studies in which these predictors were used to predict the cost-effectiveness of applying two different regression testing strategies to two software systems. In one case study, the TESTTUBE method selected an average of 88.1 percent of the available test cases in each version, while the predictor predicted that 87.3 percent of the test cases would be selected on average.
    },  
    keywords={},  
    doi={10.1109/32.585502}, 
    ISSN={1939-3520},  
    month={March},
    exclusion_rationale = {
      This paper may well be useful when I focus on software testing and coverage criteria. My first impressions are positive. It's not what I'm focusing on at the moment.
    }
    
    
@article{wong_be_2017,
	title = {Be more familiar with our enemies and pave the way forward: A review of the roles bugs played in software failures},
	volume = {133},
	issn = {0164-1212},
	url = {https://www.sciencedirect.com/science/article/pii/S0164121217301334},
	doi = {https://doi.org/10.1016/j.jss.2017.06.069},
	abstract = {There has been an increasing frequency of failures due to defective software that cost millions of dollars. Recent high profile incidents have drawn increased attention to the risks of failed software systems to the public. Yet aside from the Therac-25 case, very few incidents of software failure causing humans harm have been proven and widely reported. With increased government oversight and the expanded use of social networking for real time reporting of problems, we are only beginning to understand the potential for major injury or death related to software failures. However, debugging defective software can be costly and time consuming. Moreover, undetected bugs could induce great harm to the public when software systems are applied in safety-critical areas, such as consumer products, public infrastructure, transportation systems, etc. Therefore, it is vital that we remove these bugs as early as possible. To gain more understanding of the nature of these bugs, we review the reported software failures that have impacted the health, safety, and welfare of the public. A focus on lessons learned and implications for future software systems is also provided which acts as guidelines for engineers to improve the quality of their products and avoid similar failures from happening.},
	pages = {68--94},
	journaltitle = {Journal of Systems and Software},
	author = {Wong, W. Eric and Li, Xuelin and Laplante, Philip A.},
	date = {2017},
	keywords = {Accidents, Bugged software systems, Lessons learned, Mishaps, Software failures},
	exclusion_rationale = { 
	  An interesting paper on the contributions of software failures to various major real-world accidents. This paper appears to have been incorrectly cited by "A Study on Testers’ Learning Curve in Crowdsourced Software Testing". I cannot find any connection between the sentence in that paper and the contents of this paper.
	}
}

@ARTICLE{9435346,  
    author={Yao, Yongming and Huang, Song and Zong, Cheng and Liu, Erhu and Chen, Ning},
    journal={IEEE Access},  
    title={A Study on Testers’ Learning Curve in Crowdsourced Software Testing}, 
    year={2021}, 
    volume={9}, 
    number={}, 
    pages={77127-77137},  
    abstract={
      Recommending effective testers in crowdsourced software testing is a challenge. In this paper, we study the improvement of crowdsourced software testers' skills over time. We propose the project difficulty coefficient to eliminate the influence of the item on the tester's score. The hyperbolic learning curve model and exponential learning curve model are used to fit the learning ability of the testers. The experimental results show that when the test data is large, the exponential learning curve can better simulate the improvement of testers' skills.
    },  
    keywords={},  
    doi={10.1109/ACCESS.2021.3081592},
    ISSN={2169-3536},  
    month={},
    exclusion_rationale = {
      This paper has some interesting ideas on testers' effectiveness and the criteria they use to detect causes for their [in]effectiveness. However the paper seems to cite poorly (see above) and they effectively used students on a single crowdsourcing platform in China to support their claims. I'd need to spend far more time reading the paper to decide on its merit and relevance to my work.
    }
}


@article{gao_successes_2019,
	title = {Successes, challenges, and rethinking – an industrial investigation on crowdsourced mobile application testing},
	volume = {24},
	issn = {1573-7616},
	url = {https://doi.org/10.1007/s10664-018-9618-5},
	doi = {10.1007/s10664-018-9618-5},
	abstract = {The term crowdsourcing – a compound contraction of crowd and outsourcing – is a new paradigm for utilizing the power of crowds of people to facilitate large-scale tasks that are costly or time consuming with traditional methods. This paradigm offers mobile application companies the possibility to outsource their testing activities to crowdsourced testers (crowdtesters) who have various testing facilities and environments, as well as different levels of skills and expertise. With this so-called Crowdsourced Mobile Application Testing ({CMAT}), some of the well-recognized issues in testing mobile applications, such as multitude of mobile devices, fragmentation of device models, variety of {OS} versions, and omnifariousness of testing scenarios, could be mitigated. However, how effective is {CMAT} in practice? What are the challenges and issues presented by the process of applying {CMAT}? How can these issues and challenges be overcome and {CMAT} be improved? Although {CMAT} has attracted attention from both academia and industry, these questions have not been addressed or researched in depth based on a large-scale and real-life industrial study. Since June 2015, we have worked with Mooctest, Inc., a {CMAT} intermediary, on testing five real-life Android applications using their {CMAT} platform – Kikbug. Throughout the process, we have collected 1013 bug reports from 258 crowdtesters and found 247 bugs in total. This paper will present our industrial study thoroughly and give an insightful analysis to investigate the successes and challenges of applying {CMAT}.},
	pages = {537--561},
	number = {2},
	journaltitle = {Empirical Software Engineering},
	shortjournal = {Empirical Software Engineering},
	author = {Gao, Ruizhi and Wang, Yabin and Feng, Yang and Chen, Zhenyu and Eric Wong, W.},
	date = {2019-04-01},
	exclusion_rationale = {
	  This is an interesting paper and probably worth reading in future when I'm focusing on crowdsourced testing. It touches on finding crashes in mobile apps so has some overlap with my research, however I didn't find sufficient concrete information to cite it in my thesis. I also appreciated the discussion on the value of 'duplicate bugs'.
	}
}

@INPROCEEDINGS{4659256,
    author={Godfrey, Michael W. and German, Daniel M.}, 
    booktitle={2008 Frontiers of Software Maintenance},   
    title={The past, present, and future of software evolution},   
    year={2008},  
    volume={},  
    number={},  
    pages={129-138},  
    abstract={
      Change is an essential characteristic of software development, as software systems must respond to evolving requirements, platforms, and other environmental pressures. In this paper, we discuss the concept of software evolution from several perspectives. We examine how it relates to and differs from software maintenance. We discuss insights about software evolution arising from Lehmanpsilas laws of software evolution and the staged lifecycle model of Bennett and Rajlich. We compare software evolution to other kinds of evolution, from science and social sciences, and we examine the forces that shape change. Finally, we discuss the changing nature of software in general as it relates to evolution, and we propose open challenges and future directions for software evolution research.
    },
    keywords={}, 
    doi={10.1109/FOSM.2008.4659256}, 
    ISSN={}, 
    month={Sep.},
    exclusion_rationale = {
      It covers interesting topics however I'm not sure where it'd fit in my thesis:- perhaps in the discussion about mobile analytics tools needing to evolve, ditto apps needing to evolve? If so, it'd probably belong in the related works chapter. Laws 1, 7, and 8 do look relevant. 
    },
}

@INPROCEEDINGS{8933541,  
    author={Wang, Chong and Li, Ju and Liang, Peng and Daneva, Maya and Sinderen, Marten},  
    booktitle={2019 IEEE 27th International Requirements Engineering Conference Workshops (REW)},
    title={Developers' Eyes on the Changes of Apps: An Exploratory Study on App Changelogs},  
    year={2019},
    volume={}, 
    number={}, 
    pages={207-212},
    abstract={
      Release planning for mobile apps has only recently become an area of active research. As a result, little is known about the types of requirements that app developers pay the most attention to when releasing an app. This research uses the changelogs of apps to shed light on this. We report the results of an exploratory study in which we analyzed the requirements that dominate the changes of apps, according to a set of 3000 changelogs collected from 120 apps from three categories in the Apple App Store: Travel, Social networking, and Books. We analyzed the changelogs in terms of functional and non-functional requirements, from a developers' perspective. Our results suggest that developers' releases are by far more concerned with non-functional requirements than with functional requirements. We also found that usability and maintainability are the most frequently mentioned non-functional requirements (NFRs) in the changelogs. Surprisingly, reliability requirements formed only a fraction of the total number of NFRs addressed in all changelogs of apps in the three selected App Store categories.
    },  
    keywords={},  
    doi={10.1109/REW.2019.00042}, 
    ISSN={},  
    month={Sep.},
    exclusion_rationale = {
      The paper focuses on iOS apps in Apple's App Store rather than where I'm focusing (Google Play for Android apps). It has visible mistakes in the opening material e.g. contradictory claims of the number of Android apps, and bland claims that the number of apps will increase. The work appears to be based on the public release notes that accompany new releases of the iOS apps they're studying rather than my work which is in the use of mobile analytics. Where our work overlaps is mainly in the study of reliability of mobile apps.
    }
}

@article{pandey2019application,
  title={Application of fuzzy DEMATEL approach in analyzing mobile app issues},
  author={Pandey, Mamta and Litoriya, Ratnesh and Pandey, Prateek},
  journal={Programming and Computer Software},
  volume={45},
  number={5},
  pages={268--287},
  year={2019},
  publisher={Springer},
  doi = {10.1134/S0361768819050050},
  exclusion_rationale = {
    The opening material put me off entirely with specious claims. 
    The sources of the data being analysed are unclear and undated e.g. did any come from the BlackBerry store? if so, when were the reviews published? It's a pity as some of their claims would be relevant in terms of supporting my work however I can't trust it as evidence based on what I've read in this article.
    }
}

@inproceedings{han2014using,
  title={Using DEMATEL to analyze the quality characteristics of mobile applications},
  author={Han, Wen-Ming and Hsu, Cheng-Hsien and Yeh, Cheng-Yu},
  booktitle={Proc. of the International Conference on Future Information Engineering and Manufacturing Science},
  pages={131--134},
  year={2014},
  exclusion_rationale = {
    The method isn't described and nor are the volumes of responses, etc. Like the previous paper (which references this one) I'd love to have cited it but can't in conscience do so.
    }
}

@inproceedings{10.1145/1572272.1572291,
    author = {Sinha, Saurabh and Shah, Hina and G\"{o}rg, Carsten and Jiang, Shujuan and Kim, Mijung and Harrold, Mary Jean},
    title = {Fault Localization and Repair for Java Runtime Exceptions},
    year = {2009},
    isbn = {9781605583389},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/1572272.1572291},
    doi = {10.1145/1572272.1572291},
    abstract = {This paper presents a new approach for locating and repairing faults that cause runtime exceptions in Java programs. The approach handles runtime exceptions that involve a flow of an incorrect value that finally leads to the exception. This important class of exceptions includes exceptions related to dereferences of null pointers, arithmetic faults (e.g., ArithmeticException), and type faults (e.g., ArrayStoreException). Given a statement at which such an exception occurred, the technique combines dynamic analysis (using stack-trace information) with static backward data-flow analysis (beginning at the point where the runtime exception occurred) to identify the source statement at which an incorrect assignment was made; this information is required to locate the fault. The approach also identifies the source statements that may cause this same exception on other executions, along with the reference statements that may raise an exception in other executions because of this incorrect assignment; this information is required to repair the fault. The paper also presents an application of our technique to null pointer exceptions. Finally, the paper describes an implementation of the null-pointer-exception analysis and a set of studies that demonstrate the advantages of our approach for locating and repairing faults in the program.},
    booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
    pages = {153–164},
    numpages = {12},
    keywords = {static analysis, fault localization, runtime exceptions, null dereference},
    location = {Chicago, IL, USA},
    series = {ISSTA '09},
    exclusion_rationale = {
      The work is relatively dated and not directly related to mobile apps. While there may well be useful connections and/or parallels in their approach the gaps are too great for me to justify spending the time on currently.
    }
}

@inproceedings{10.1145/3167918.3167942,
    author = {Imamura, Yuta and Uekawa, Hiroyuki and Ishihara, Yasuhiro and Sato, Masaya and Yamauchi, Toshihiro},
    title = {Web Access Monitoring Mechanism for Android Webview},
    year = {2018},
    isbn = {9781450354363},
    publisher = {Association for Computing Machinery},
    address = {New York, NY, USA},
    url = {https://doi.org/10.1145/3167918.3167942},
    doi = {10.1145/3167918.3167942},
    abstract = {In addition to conventional web browsers, WebView is used to display web content on Android. WebView is a component that enables the display of web content in mobile applications, and is extensively used. As WebView displays web content without having to redirect the user to web browsers, there is the possibility that unauthorized web access may be performed secretly via WebView, and information in Android may be stolen or tampered with. Therefore, it is necessary to monitor and analyze web access via WebView, particularly because attacks exploiting WebView have been reported. However, there is no mechanism for monitoring web access via WebView. In this work, the goals are to monitor web access via WebView and to analyze mobile applications using WebView. To achieve these goals, we propose a web access monitoring mechanism for Android WebView. In this paper, the design and implementation of a mechanism that does not require any modifications to the Android Framework and Linux kernel are presented for the Chromium Android System WebView app. In addition, this paper presents evaluation results for the proposed mechanism.},
    booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
    articleno = {1},
    numpages = {8},
    keywords = {webview, Android, web access monitoring},
    location = {Brisband, Queensland, Australia},
    series = {ACSW '18},
    exclusion_rationale = {
      This paper focuses on implementing HTTP request and response logging in a replacement for the core WebView component in Android 6.0.1 I'm not sure I agree with their claim that ``it is necessary to monitor and analyze web access via WebView". The work is also dated as Google have materially changed the WebView design and implementation several times since Android 6. Finally, their research isn't directly connected with mine - their focus is broadly on security, mine on mobile analytics to measure and help improve mobile analytics. 
    }
}

@article{emiliani_false_2000,
	Abstract = {Discusses the importance of precise communication as a prerequisite to achieving alignment between internal and external stakeholders. Consideration is given to popular management catch‐phrases in general, with specific analysis of the widely‐used statement: ``what gets measured gets managed''. The application of mathematical logic shows this to be a false statement, yet one that precipitates the management of measurements that may not add value as seen by the end‐use customer.},
	Author = {Emiliani, M.L.},
	Doi = {10.1108/00251740010694317},
	Issn = {0025-1747},
	Journal = {Management Decision},
	Month = jan,
	Number = {9},
	Pages = {612--615},
	Title = {The false promise of ``what gets measured gets managed''},
	Url = {https://doi.org/10.1108/00251740010694317},
	Urldate = {2022-06-08},
	Volume = {38},
	Year = {2000},
	Bdsk-Url-1 = {https://doi.org/10.1108/00251740010694317},
	Bdsk-Url-2 = {http://dx.doi.org/10.1108/00251740010694317}},
	exclusion_rationale = {
	  While this is an interesting and realistic assessment of the tosh management say in companies, it's not sufficiently in depth or on topic to cite as a counterpoint to arguing that what gets measured gets managed.
	}
}


@article{mcintosh_empirical_2016,
	title = {An empirical study of the impact of modern code review practices on software quality},
	volume = {21},
	issn = {1573-7616},
	url = {https://doi.org/10.1007/s10664-015-9381-9},
	doi = {10.1007/s10664-015-9381-9},
	abstract = {Software code review, i.e., the practice of having other team members critique changes to a software system, is a well-established best practice in both open source and proprietary software domains. Prior work has shown that formal code inspections tend to improve the quality of delivered software. However, the formal code inspection process mandates strict review criteria (e.g., in-person meetings and reviewer checklists) to ensure a base level of review quality, while the modern, lightweight code reviewing process does not. Although recent work explores the modern code review process, little is known about the relationship between modern code review practices and long-term software quality. Hence, in this paper, we study the relationship between post-release defects (a popular proxy for long-term software quality) and: (1) code review coverage, i.e., the proportion of changes that have been code reviewed, (2) code review participation, i.e., the degree of reviewer involvement in the code review process, and (3) code reviewer expertise, i.e., the level of domain-specific expertise of the code reviewers. Through a case study of the Qt, VTK, and ITK projects, we find that code review coverage, participation, and expertise share a significant link with software quality. Hence, our results empirically confirm the intuition that poorly-reviewed code has a negative impact on software quality in large systems using modern reviewing tools.},
	number = {5},
	journal = {Empirical Software Engineering},
	author = {McIntosh, Shane and Kamei, Yasutaka and Adams, Bram and Hassan, Ahmed E.},
	month = oct,
	year = {2016},
	pages = {2146--2189},
	exclusion_rationale = {
	    The topics align, and this paper does present post-release defects as an accepted proxy for a long-term measure of software quality. However it is too far removed from Android or mobile analytics to be included currently. Also they skip blithely past Android as a codebase as they accept 2\% of the code being reviewed when that's so unlikely to be true. Google instead performs many code reviews internally, outside the public eye. The codebase is extensively reviewed and often by experts who are highly competent software developers and engineers. 
	    
	    This paper might fit better with Developer Experience (DevEx).
	}
}

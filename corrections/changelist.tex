\chapter*{List of  corrections}~\label{ch-list-of-corrections}
\addcontentsline{toc}{chapter}{List of corrections}
\chaptermark{List of corrections}
%\setcounter{section}{-1} % So the rest of the sections align with the comments of the examiners:

\section*{Report to candidate}
\addcontentsline{toc}{section}{Report to candidate}
These items are repeated \emph{verbatim} from the post-viva report, followed by a short sentence in italics that links to the response for that item. Each item is then addressed in order as separate sections in this meta-chapter.

\textbf{Guidance to the student}
\begin{enumerate}
    \item The RQs need to be revisited and made more focused on the actual research carried out. The terms used in framing the work also need to be clear and defined. These RQs then need to motivated and frame all subsequent chapters. \emph{Addressed in \href{corrections-rqs}{Revision of the Research Questions}}.
    \item Discuss the specific contributions to knowledge that the work makes as these are not really distilled down or presented explicitly.
    \item Give an explanation of the case study and action research methodology and the mechanics of the research methods that were actually implemented at each case study company/project.
    \item Clarify exactly what research was done at each case study and why. For example, exactly who was interviewed at each CS, and how were interviews designed and conducted as well as the data collected analysed and used.
    \item Clarify the data that was collected at each case study and how it was analysed and how it was validated, with illustrative data provided throughout.
    \item More information is needed to clarify the research process i.e., to provide a clear link between the data collected, the findings and the conclusions drawn.
    \item Throughout the thesis thining of material is necessary. Only material directly relevant to the RQs should be included. Only findings with clear evidence should be presented. Remove all informal asides; in particular, reconsider Chapter 2 and Chapter 9. Ensure that the findings and contributions are discussed in relation to the literature in Chapter 9.
    \item Review the consistency and rigour of the language and terminology used throughout; for example the discussion of the software process throughout.
    \item Provide a rationale for the fishbone diagrams and fully explain the basis of the themes.
    \item Provide more specific information on the literature review method used; for example, specific search criteria, tags and keywords.
    \item Carefully distinguish between what the data is providing evidence of, what the literature is saying and the informal views/experiences of the author.
    \item Provide more detail in the Appendices of the data and the data analysis done in relation to the RQs.
\end{enumerate}

\section{Revision of the Research Questions}~\label{corrections-rqs}
\emph{``The RQs need to be revisited and made more focused on the actual research carried out. The terms used in framing the work also need to be clear and defined. These RQs then need to motivated and frame all subsequent chapters.''}

\subsection{Focus the RQs on the actual research carried out}
The Research Questions are in \secref{section-research-questions}

\begin{kaobox}[frametitle=Revisions to the Research Questions]
At the viva:
\begin{quote}
  \emph{How can applying analytics improve software development and software testing for mobile apps in practice?}
\end{quote} 
Revised to:
\begin{quote}
  \emph{How can applying mobile analytics in software development practice improve the reliability of mobile apps?}
\end{quote}
\end{kaobox}


%I believe the research covered ways and effects  of using \emph{mobile} analytics to improve software development and the resulting artefacts.

%TBC Focus areas...

%The research also touches on \textbf{software testing} mainly in terms of prior art and in practices of the development teams. Automated tests were developed during the Commercial, \myindex{C1}, app-centric case study to reproduce a major crash that caused a spike in the crash rate and they measured the improvement in the crash rate using mobile analytics when the underlying fix was released. Mobile Analytics complemented automated tests and interactive testing by providing objective measurements of the stability of the apps. The research did not encompass many improvements in software testing practices, nonetheless it identified that Google uses usage analytics to determine which locales to use in their automated `robo'\index{Robo} testing as part of providing pre-launch reports.


\subsection{Clearly define the terms used in framing the work}
Terms to define:\sidenote{Most of this list has been integrated into the Introduction now (\nth{18} Feb 2023). The item on quality hasn't TBD where it'd be useful - probably in the related work chapter.}  
{\tiny
\begin{itemize}
    \item Applying mobile analytics: the use of mobile analytics in order to effect improvements to the practices and the artefacts. Applying mobile analytics refers to both collecting data from the usage of the app and also making use of the analysis of this data to identify and address issues that can improve the app. Improvement of the app focuses on increasing the stability/reliability by reducing ANRs, crashes, and through improving how the app handles various errors (typically reported through Exceptions).
    \item Mobile analytics: Analytics where the data is collected by software running on mobile smartphone-based devices pertaining to the app's qualities-in-use. This research focused on analytics collected pertaining to the stability of the app, where stability includes the reliability of the app.
    \item Software testing: Note I need to also add index entries for software testing. Decide if it's to be Testing->Software in the index.
    \item Software development: which includes tasks performed by the software developers such as bug reporting and bug tracking.  Use of Scrum development practices, following recommendations and guides that include application compatibility, UI guidelines, and designing for performance and responsiveness, \emph{etc}. [Software] testing~\sidecite[][pp.398 - 399]{wasserman2010_software_engineering_issues_for_mobile_app_devt}.~\sidenote{This short paper skims over topics without evidence developers actually do them. Their survey, cited in this paper isn't available so appears to have not actually been published.}
    \item In practice: the key scope of measurement focuses on the efficacy in real-world projects.
    \item Exception(s): TBC
    \item Quality: the literature does not align, \emph{e.g.}, \emph{``reliability (robustness, connectivity, stability), quality (usability, installability)''}\cite[p.399]{wasserman2010_software_engineering_issues_for_mobile_app_devt} places stability as one of three contributory qualities to reliability, and limits quality to two sub-qualities.         
\end{itemize}
}


\subsection{Changes in the thesis}
The \secref{research-focus-section} now includes a paragraph on connections between the research 
focus and software testing for  mobile apps. The \secref{section-research-questions} includes a more precise main research question and clarification of the terms that comprise it. The six perspectives have been reviewed and 1a and 2a made more percise.

The Introduction chapter was also tidied up and reorganised as part of improving the readability of this chapter.


\section{Specify my research contributions}
\emph{``Discuss the specific contributions to knowledge that the work makes as these are not really distilled down or presented explicitly.''}

\textbf{What did we know before my research? and what do we now know?} - frame using the 3 verticals.

What we knew before my research:


\subsection{My contributions to knowledge}
The research contributes to the understanding of tools and information seldom available to research - of professional app developers, their artefacts, and of professional mobile analytics tools and services. 

\newthought{Processes}: 
My research contributes knowledge on the approaches various app development teams apply when they use mobile analytics including the selection, integration of code and services, and their application of mobile analytics to detect, identify, and address errors and failures reported by mobile analytics. It builds on prior research, for example, on Insight, and confirms their findings. It contributes new knowledge in the adoption platform-level and commercial in-app mobile analytics, including a) usage patterns by development teams ranging from individual  developers, small teams and large,  sharded teams, and b) public opensource projects, hybrid projects that combined private and proprietary practices, through to a development team at a major corporation.

Some of the findings were surprising in terms of the patterns of use and in the efficacy of using mobile analytics to achieve significant improvements.

Development teams who embedded mobile analytics into their ongoing, core practices, were able to achieve highly reliable and stable apps. 

\newthought{Artefacts}: 
The research extended prior art in studies of opensource mobile app codebases, with a focus on the use of the most popular product offering: Firebase Analytics. It also contributes insights from proprietary, commercial codebases and issue tracking artefacts.

\newthought{[Mobile  Analytics] Tools}:
The research identified characteristics of a wide range of mobile analytics tools that serve Android app developers in particular. It also found and  presents a range of flaws found in professionally-developed mobile analytics tools, including several of the most-used mobile analytics offerings.

The research contributes material relevant to professional app developers and to the developers of mobile analytics. Several of the tool development organisations including Amplitude, Google, and Iteratively actively sought insights and updates from my research.

Improvements were identified in all three areas and some of these were implemented during the research. 

Note: In addition to specifying my research contributions add explicit summaries of my contributions that have already been published.


\section{Make the details of the methodology explicit for each case study}
\emph{``Give an explanation of the case study and action research methodology and the mechanics of the research methods that were actually implemented at each case study company/project.''}

Highlight the methodological constructs:
\begin{itemize}
    \item Case Studies: Action Research.
    \item Case Studies: Interview-based using semi-structured techniques.
    \item Analysis of source code and issues databases.
\end{itemize}

Chapter 5 includes a summary of the methodology and the mechanics. I'm not sure how to adequately these changes without writing lots of text. Perhaps a couple of paragraphs.

\section{Be specific about my research, including interviews}
\emph{``Clarify exactly what research was done at each case study and why. For example, exactly who was interviewed at each CS, and how were interviews designed and conducted as well as the data collected analysed and used.''}

Revise Chapter \ref{chapter-case-studies-overview} to add these details. Add to tables and to the respective narrative. In the Methods chapter: the questions covered these areas: e.g. access to the tools in order to conduct the research (research activity) and primary data (questions pertaining to their use  of mobile analytics). Methods chapter: corroboration was achieved using at least one of these techniques...

Interviews were qualitative in nature and, as such, primarily open and flexible in their arrangements to facilitate interviewees being able to provide rich experiences and insights as they arose. Frame the use and the effects of interviews using \sidecite{rapley2001_the_artfulness_of_open_ended_interviewing_etc}. E-mail based interviews are recognised as an established research practice see \sidecite{bampton_cowton_2002_the_e_interview}. More senior participants and volunteers have a great deal of autonomy and choose what they are willing to provide including whether they respond at all, (see \sidecite{james2006_credibility_authenticity_and_voice_dilemmas_in_online_interviewing} for a discussion on these aspects), and all participants ultimately had a great deal of freedom in practice in terms of their contributions that formed the basis for aspects of this research. The use of online interviews, in a similar vein to \sidecite{deakin2014_skype_interviewing_etc}, however often using other video-conferencing services, forms a key aspect of my research.

The evidence was analysed, compared, and filtered to provide representative findings of note. 

\subsection{GTAF}

\begin{itemize}
    \item[Who] Co-founder and Lead dev; additional background discussions with another developer who was another post-graduate student during the case study. 
    \item[Why]
    \item[Interview design] Prepared Q's that led to an open discussion.
    \item[Interview conducted] 50 minute Google Meet call \nth{8} Sep 2020. Combined with email correspondence  before and after the interview.
    \item[Data Collected] Contemporaneous notes, emails, access to Google Play Console with Android  Vitals and Issue database.
    \item[Data analysed] See below:
    \begin{itemize}
        \item[Contemporaneous notes] these led to various of the presented findings. In general my findings were validated via the Google document I shared with the project's founders (one was the person I interviewed), others were validated during the email correspondence. Note: Owing to the subject being unwell I did not receive validation of every finding. 
        \item[Emails] Corroborated findings.
        \item[Mobile analytics] Google Play Console and Android Vitals for reports, failures, statistics,
        \item[Issues database] Analysed to find issues that included references to mobile analytics as a source of that issue.
    \end{itemize}
    \item[Data used] Google Play Console and Android Vitals reports, Issues with Firebase links.
    \item[Corroboration] (if the methods were specific to each case study.) Google Doc written and shared with Project leads.
\end{itemize}

\subsection{Local Halo}

\begin{itemize}
    \item[Who] The CEO was interviewed twice where he confirmed they were happy to participate and support the research. The CTO provided access to mobile analytics and provided ongoing support and feedback during the active case study. 
    \item[Why]
    \item[Interview design] Open discussion with CEO. Three primary topics with the CTO: 1) their use of mobile analytics generally, 2) failure reporting and management, and 3) their development team practices.
    \item[Interview conducted] With the CEO, the first call, was for 25 minutes on Zoom on \nth{10} Oct 2019, it was introductory in nature. The subsequent discussion was in-person near Kings Cross, London  on \nth{27} Nov 2019 for approximately 60 minutes. This went into more detail about the research and in mobile analytics. The discussion with the CTO focused on the team's use of mobile analytics and their development practices and used Google Meet on \nth{17} Jan 2020 for approximately 60 minutes.
    \item[Data Collected] Contemporaneous notes during the interviews. 
    \item[Data analysed] See below:
    \begin{itemize}
        \item[Contemporaneous notes] These recorded the use of three distinct mobile analytics services: Mixpanel for marketing and business development, Sentry for technology-facing issues, and Google Play Console with Android Vitals. Key points were shared by email to check understanding and for accuracy.
        \item[Correspondence emails] during the case study primarily discussed errors that occurred during the case study. These corroborated findings from mobile analytics and automated emails.
        \item[Automated emails] generated by Sentry on an ongoing basis included weekly summary reports for the website and for their cross-platform mobile app. A subset of these were compared with the results from Android Vitals, particularly when Android reported crashes in the Local Halo app and conversely Sentry had no data for the app on those dates.
        \item[Mobile analytics] Google Play Console and Android Vitals for reports, failures, statistics, which were available for six months. These were collected both using Vitals Scraper and also reviewed interactively online during the case study. Access to the company's Sentry Mobile Analytics was provided indefinitely and only terminated when Sentry changed their free-of-charge service offering and removed support for multiple logins. 
        \item[Issues database] N/A by agreement with the CTO.
    \end{itemize}
    \item[Data used] Google Play Console and Android Vitals reports, Sentry reports. Access was initially provided for three months, this was extended for another three months. 
    \item[Corroboration] (if the methods were specific to each case study.) 
\end{itemize}

\subsection{Moodspace}

\begin{itemize}
    \item[Who] CTO of the organisation.
    \item[Why]
    \item[Interview design] Questions written up in emails on their use of Android Vitals in particular; these were answered by email together with snapshots of their analytics reports.
    \item[Interview conducted] By email with the bulk of the information provided on \nth{13} and \nth{15} June 2019.
    \item[Data Collected] Snapshots of Android Vitals and Google Play Console, answers provided via email.
    \item[Data analysed] See below:
    \begin{itemize}
        \item[Contemporaneous notes]  none.
        \item[Emails] Their use of Android Vitals and their assessment of possible improvements to Google Play Console and Android Vitals.
        \item[Mobile analytics] Their snapshots of Google Play Console and Android Vitals.
        \item[Issues database] N/A
    \end{itemize}
    \item[Data used] The contents of the reports they provided.
    \item[Corroboration] (if the methods were specific to each case study.) 
\end{itemize}

\subsection{Moonpig}

\begin{itemize}
    \item[Who] 
    Primarily one of their lead developers; this was supplemented by informal discussions with several of their development team at events hosted by Moonpig. Their legal and marking team also agreed thee findings of the research could be published.
    \item[Why]
    \item[Interview design] 
    Started as open-ended discussions about software quality practices at Moonpig, then extended into their use of mobile analytics and their app development practices. 
    \item[Interview conducted] 
    At least six in-person meetings supplemented by video calls and email discussions during the case study.
    \item[Data collected] 
    Snapshots of Android Vitals and Google Play Console, answers provided via email.
    \item[Data analysed] 
    See below:
    \begin{itemize}
        \item[Contemporaneous notes]  
        Provided concrete examples of how they were using mobile analytics, of failures, and how they addressed those failures.
        \item[Emails] 
        Ongoing updates on their use of mobile analytics, bug reporting, a discussion of a crash reported in a review by an end-user of their Android app, and the company's decision to halt their support of the research around the time the company listed on the stock market.
        \item[Mobile analytics] 
        Their snapshots of Google Play Console, Android Vitals, and Firebase Analytics.
        \item[Issues database] 
        N/A
    \end{itemize}
    \item[Data used] 
    The contents of the reports they provided and examples they provided during the course of the case study.
    \item[Corroboration] 
    Their lead developer reviewed peer-reviewed research published during the case study and had access at his request to the PhD thesis. The findings were corroborated on an ongoing basis between 2019 and 2022.
\end{itemize}

\subsection{Smartnavi}

\begin{itemize}
    \item[Who] The project owner and main developer.
    \item[Why]
    \item[Interview design] The contents of the interview questions were informed by prior analysis of the app's source code on GitHub.com as part of collaborative research on the use of Firebase Analytics for logging purposes. It was designed as a one-shot call that would cover as much of the ground as practical rather than needing to rely on multiple calls (which might be rejected by the interviewee as too burdensome).
    \item[Interview conducted] on Google Meet for 60 minutes, and was an open-ended discussion that started with the history and rationale for his app; his use of Firebase Analytics in the app, crash reporting, challenges of developing code that needed to run as a background service on Android -  where newer releases of Android had become increasingly restrictive of background processes in general.
    \item[Data collected] Contemporaneous notes;  GitHub codebase history; additional email follow-up discussions.
    \item[Data analysed] :
    \begin{itemize}
        \item[Contemporaneous notes] These were summarised, by me, and shared both by email and in discussion with co-researchers on the Firebase Analytics remote logging project. Note: the audio calls of the meetings with fellow researchers were performed in Zoom and generally recorded. 
        \item[Emails] Including corroboration that Google required Android developers who used Fabric Crashlytics SDK to migrate to the Firebase Crashlytics SDK by \nth{15} November 2020.
        \item[Mobile analytics] The usage and effects of mobile analytics were discussed however the contents were not provided as the app was no longer being developed actively.
        \item[Issues database] \url{https://github.com/Phantast/smartnavi/issues} of which \href{https://github.com/Phantast/smartnavi/issues/10}{app crashes on moto defy} discusses tradeoffs between releasing the app on F-Droid that prohibits Crashlytics and other  commercial Mobile Analytics and the challenge of the developer knowing about, finding, and eventually being able to address the cause of the crash. In \href{https://github.com/Phantast/smartnavi/issues/11}{app crashes when launching} the most-likely technically competent user provided a partial crash log which enabled the bug to be identified and fixed.
    \end{itemize}
    \item[Data used] Source code examples, findings from the interview and discussions with the developer.
    \item[Corroboration] Discussion with the interviewee on  the analysis and findings. 
\end{itemize}

\subsection{Kiwix}

\begin{itemize}
    \item[Who] The two primary project leads: the marketing/finances/business lead and the engineering lead. This was combined with ongoing \emph{ad-hoc} discussions with various developers who worked on the Kiwix project in general and the Android app in particular. Overall, at least 10 of the project team participated in work directly related to this research.
    \item[Why] From a research perspective the purposes of this case study contributed multi-year perspective on the use of crash analytics by a hybrid development team (led by a professional developer) who actively attended to failures reported by the platform-level mobile analytics (Android Vitals). The project also facilitated a comparison between an experiment app and a control app which demonstrated the improvements in the reliability of the experiment [app] were most likely to be as a result of the release and use of that app, which had fixes applied to that app's codebase. The self-imposed restrictions on their rejection of embedding any analytics in the app also gave the project added value from a research perspective as their only source of mobile analytics came from the platform. 
    \item[Interview design] Open ended discussions with the project leads who asked for help to reduce the failure rate of the project's Android apps.
    \item[Interview conducted] \emph{ad-hoc} discussions with both project leads. Working discussions with the Android developers.
    \item[Data collected] Android Vitals reports, contemporaneous notes from discussions, hackathon summaries, emails including those about ways the app crashed (e.g. from the testing performed by \url{http://www.test1080.com/}). When the professional development lead joined () and left the project (Dec 2020).
    \item[Data analysed] The majority of the data came from Android Vitals reports collected both interactively and using vitals scraper, these recorded the failures and failure rates at various levels of granularity. The issues database and the source code documented the changes to the project's artefacts. The emails and notes recorded the thinking, rationale, and so on.
    \item[Data used] Representative examples of key results recorded in the mobile analytics and in the source code are included in this thesis.
    \item[Corroboration] The causes, fixes, and improvements in the failures were discussed on an ongoing basis with developers and with the project leads. A draft of my MobileSoft 2019 paper was reviewed by Stephane, one of the project leads. It was also shared with the then lead of the Android project (Isaac) and both Emmanuel and Stephane. 
\end{itemize}

% https://wiki.kiwix.org/wiki/UkHackathon2017
% https://wiki.kiwix.org/wiki/Hackathon_Google_Zurich_2018
% https://wiki.kiwix.org/wiki/Hackathon_Wikimania_2019#Android_2 (where two critical bugs were fixed).
% bug fix release 2.5.3 https://github.com/kiwix/kiwix-android/pull/1388

\subsection{Catrobat}

\begin{itemize}
    \item[Who] The product owner (Matthias Müller), the project lead (Prof. Wolfgang Slany), various developers of the mobile apps in a workshop in Graz, Austria the hackathon in Graz, and for the workshop in Wroclaw, Poland). 
    \item[Why] The project corroborated the improvements that applying mobile analytics could provide even teams who had implemented many other recommended software development practices. It also enabled comparisons between Fabric Crashlytics, the side-effects of migration to Firebase Crashlytics. 
    \item[Interview design] Open-ended interviews to learn of their concerns, their use of mobile analytics, their pain-points.
    \item[Interview conducted] Open discussion with the product owner; which led to a more structured discussion with the project lead who selected the app to focus on. \emph{Ad-hoc} conversations with the developers.
    \item[Data collected] From Fabric Crashlytics, Firebase Crashlytics, Google Play Console and Android Vitals, github codebases, issues database, project wiki, continuous integration service including reports, contemporaneous notes and emails.
    \item[Data analysed] :
    \begin{itemize}
        \item[Contemporaneous notes] various...
        \item[Emails] Early snapshots of the statistics for their two main Android apps from Google Play Console and Android Vitals. Sources of additional information, for example about correlations with higher crash rates and Huawei phones \url{https://jira.catrob.at/browse/CATROID-373}, about the reasons the project team wanted to have a hackathon (to reduce the measured crash rate from 4\% to below the bad behavior threshold of 1.09\%, details of who was invited to the hackathon and who participated (6 developers - of these 2 were students and 4 were longer-term contributors who had completed their academic studies, Matthias, Wolfgang, Joe, me). Releases of vitals scraper shared with the project leads. Confirmation that crashlytics reporting was broken in the Android release shortly before \nth{17} November 2019. Records of progress in improving the crash rate of Pocket Code. Confirmation of the bug fix release, released on \nth{6} Jan 2020. Utility of a Turkish review that pinpointed a long standing bug that was fixed server-side around \nth{1} April 2020.
        \item[Mobile analytics] Identified vast differences in the counts reported by Fabric Crashlytics and Android Vitals; measured the cumulative improvements in the app at the time of the hackathon and for two months afterwards.
        \item[Issues database] Recorded the top 10 crashes and top 10 ANRs identified during the hackathon and measured their progress as some of them were addressed. 
    \end{itemize}
    \item[Data used] TBC cross-reference later in the editing process.
    \item[Corroboration] A joint paper with Matthias Mueller (Better Android Apps Using Android Vitals).
\end{itemize}

\subsection{C1}

\begin{itemize}
    \item[Who] CTO of the project, and his overall Apex management (2 people who were effectively the CEO and CTO of the entire company), several of the Android developers, development leads, and their managers; several of the consulting company Xnsio (also known as Znsio). 
    \item[Why] A very popular complex mobile app with real-time performance requirements developed by an extremely large development team (larger than any of the other app-centric case studies by an order of magnitude). The first that included both proprietary and commercial mobile analytics SDKs.
    \item[Interview design] Open-ended for the introductory interviews/discussions. Thematic for interviews with developers, leads, and their manager.
    \item[Interview conducted] Initially led by the business so they could determine the suitability of being involved in the research. Generally the interviews were conducted using video conferencing, several were complemented by written discussions in Microsoft Teams and/or emails.
    \item[Data collected] Reports and other outputs from various of the mobile analytics services, source code, automated CI and CB results, issues database, email and Microsoft Teams conversations and updates, contemporaneous notes. Correspondence with a commercial provider of mobile analytics about their export mechanisms. 
    \item[Data used] Only non-identifiable materials have been included in this publication; the rest of the material has corroborated and aligns with findings from other case studies covered in this thesis.
    \item[Corroboration] with the Apex management and the head of the consulting company who represented the rest of the engineering team.
\end{itemize}


\section{Illustrative data}
\emph{``Clarify the data that was collected at each case study and how it was analysed and how it was validated, with illustrative data provided throughout.''}

TBD draw illustrative data from as many case studies as practical.

\section{Traceable threads from data collected to findings and conclusions}
\emph{``More information is needed to clarify the research process i.e., to provide a clear link between the data collected, the findings and the conclusions drawn.''}

To be covered in the new chapter 9 (Discussion) or in the Conclusion chapter - synthesise these are the conclusions I draw with result to the RQs.

\section{Thinning and pruning of the material}

\section{Increasing consistency and rigour}

\section{Swimming with the fishbones [fishbone diagrams]}

\section{Be specific in the literature review method(s) used}
\begin{kaobox}

    I suspect this item is partly because of what I wrote in \secref{rw-tactics-and-topics-for-this-chapter}.
    
    This is an interesting challenge given the protracted journey of my PhD and the interludes, events, etc. How do you suggest I address this retrospectively? Whatever is written is a veneer of what actually happened over the years. To get things started I've started the following sub-section on keyword searches, perhaps they'd be better placed in an appendix though?
\end{kaobox}

The literature review method combined many iterative searches for possible keywords using Google Scholar, IEEE, ACM, and occasionally the Open University's online library search~\sidenote{Marian recommends I resist trying to provide a specious formulae of how to perform online searches for prior work. Doing so is a) not reflective of reality, b) incorrect, c) highly unlikely to discover the identical candidate materials, d) focusing on minutia rather than on the substance of finding, reading, and selecting relevant material which is so much more nuanced than the results of keyword searches online.}. 

Candidate matches were selected based on a combination of reading the abstract, snowballing through papers that cite the particular paper and their relevance to the original search. The search results were also filtered by their publication year to uncover recent related work that might not have been heavily cited yet. In the early years of the research these were stored in Zotero~\sidenote{A paid account was used to ensure there was sufficient storage available and to facilitate sharing of the libraries.} (counts are provided in \ref{tab:zotero-libraries-counts}. In later years the references were primarily stored as part of this PhD thesis project in Overleaf~\sidenote{A paid account was used to facilitate collaboration, and to enable the use of github integration to help preserve the records of the literature that has been reviewed.}, again counts are in \ref{tab:zotero-libraries-counts}. Allowing for a total margin of 5\% for duplicates and/or irrelevant items at least 2075 unique references, the exact number is unlikely to be material~\sidecite[][pp.146 - 149]{hubbard2014measure}.

There may be a small number of duplicates given the various locations references are stored, and there may be some irrelevant references given the characteristics of working with Zotero (and one of the reasons I stopped using it actively).

Over 100 papers were printed out and hand annotated with analysis and notes on the connections to the research. In addition in the order of 100 personally owned books on related topics were consulted, ranging from those published in the 1970's to those published in 2023.

Generally prior work was read and their bibliography was checked, in turn, using snowballing until no new relevant information was found. As a concrete example, one of the papers returned in the search results was \href{https://scholar.google.com/scholar?cites=17913946012612049501&as_sdt=2005&sciodt=0,5&hl=en}{\emph{``Software engineering process models for mobile app development: A systematic literature review''}}. one paper in the next 40 search results that had cited that paper extended that topic~\sidecite{martinez2020_an_agile_based_integrated_framework_for_mobile_app_devt_considering_ilities}. This seemed potentially interesting but petered-out into their own set of quality attributes, they termed -ilities, that lacked performance or reliability which they then tested through a small mobile app project created by three students. So this paper did not build materially on the research I was interested in. Nonetheless at least four of the other references in the bibliography in this paper were checked in case they contained relevant research. 

\begin{table}
    \centering
    \begin{tabular}{r|l}
       Item  &  Library \\
     172 & `My Library' \\
     113 & AppStoreReviewsAndRankings \\
     428 & Better Software Testing for Mobile Apps \\
      21 & Putting Testing at the Heart of Management \\
     579 & Software Quality API \\
     820 & References in the PhD project in Overleaf \\
      52 & References imported from the joint authorship logging paper \\
      \hline
      2185 & individual references \\
    \end{tabular}
    \caption{Items collected in Zotero and Overleaf, by \nth{12} Feb 2023}
    \label{tab:zotero-libraries-counts}
\end{table}


Literature searches were performed on an ongoing basis throughout the research.

\subsection{Keyword searches}

\newthought{Software Development Practices for Mobile Apps}

\verb|software development practices mobile apps| and the same search terms since 2019.

\verb|android exception better OR handler| given the specific and consistent use of exceptions as a concept, and as a language construct in Java and Kotlin and Android's origins in Java, research into how others have implemented exception handlers or improved (made better) exceptions are both relevant. None of the following searches returned any similar research for the iOS platform \verb|ios error handling|, \verb|ios error handling design|, and \verb|ios error better OR handler|. Error is a key term in Swift development \url{https://docs.swift.org/swift-book/LanguageGuide/ErrorHandling.html} Apple recommends Swift for iOS app development~\url{https://developer.apple.com/swift/} and more developers used Swift (4.91\%) than Objective-C (2.39\%) according to the StackOverflow 2022 Survey~\url{https://survey.stackoverflow.co/2022/\#technology-most-popular-technologies} \sidenote{Additional error reporting can be recorded by mobile analytics such as by Sentry.io \url{https://sentry.io/for/swift/}.}

% Trustworthy sources to demonstrate the relevance of Swift, etc. are hard to find. Here's some lower-grade ones in the interim:
% https://www.itmagination.com/blog/is-objective-c-still-relevant-in-2022-or-is-swift-the-only-real-choice



\section{Distinguishing sources: data|literature|author's industry perspective}


\section{In appendices, provide more details of the data and data analysis done in relation to the RQs}


\section{Additional Improvements to the thesis}
There are numerous minor opportunities to improve the thesis in terms of readability. These include copy-editing of the contents, tidying up loose-ends, replacing poor-quality figures with clearer ones, and using side-citations wherever practical (some \verb+\cite{}+'s were left in the thesis unnecessarily. I'd also like to add epigraphs to the chapters that lack them.

The examiners also indicated they would appreciate a list of my publications related to the research contained in my thesis,  so I suggest I reinstate this list.

\chapter{Applying analytics to development practices}~\label{chapter-applying-analytics-to-development-practices}
Analytics data is based on the software being used, so the software needs to be created and able to run before relevant data is generated.

Analytics, such as user-journeys, can help to answer questions about the usage of the software. They help establish \emph{what-is}. As we understand more about what-is we can then consider \emph{what-would-be-better} and do gap analysis between what-is and what-would-be-better.

Various data can be potentially collected. What can be collected depends on the observation mechanisms. The choices of observation mechanisms within an app are made by developers or their stakeholders. Observation may be within an app or external to it, for instance by the operating system as Google Android does~\footnote{There are other custom versions of Android, for instance used in Amazon Kindle Fire devices.}. Within an app the observation may focus at a single layer, for instance the visual user interface, or several.


\section{Overview of applying analytics to development practices}
The development team have various choices available to them in terms of applying analytics to their software development practices. Their ~\href{subsection-levels-of-engagement}{\emph{levels of engagement}} range from not using analytics at all through to actively using an optimal mix of sources. 
Sources can include various forms of passive analytics to more hands-on techniques such as incorporating libraries and adding code to the app to report events, activities, and so on.

\begin{itemize}
    \item Decide whether to use any existing, pre-provided analytics. This includes\emph{passive analytics} (gathered without the developers needing to actively include analytics tools in their app). It may also include analytics provided as a side-effect of incorporating libraries into the app without the developers needing to add code to record additional information. 
    \item Decide whether to incorporate analytics into the app, and if so what data to collect, which analytics library/libraries to incorporate and the many associated aspects we will cover in this chapter.
    \item Consider whether and how to test analytics and whether to filter [out] analytics during automated and internal testing.
    \item Use and analyse the analytics data from the app and the platform (where available).
    \item Triage and prioritise potential issues reported from external sources (pre-launch testing, new releases, active mainstream releases, etc.)
\end{itemize}

\subsection{Levels of engagement}~\label{subsection-levels-of-engagement}
Continuum of levels of engagement, or commitment, by developers:
\begin{enumerate}
    \setcounter{enumi}{-1} % unexpectedly this sets the first item in this list to zero.
    \item No analytics incorporated in the development process. If they exist, they're ignored.
    \item Passive analytics incorporated, app does not contain any crash recording, remote logging, or other mobile analytics libraries.
    \item App incorporates one or more of the above mentioned libraries, initialises them where necessary but does not add any other additional calls to the libraries.
    \item App incorporates additional code to call one or standard methods using the APIs (\emph{etc.} if other mechanisms are available).
    \item App includes custom reporting where specific parameters are included in relevant API calls.
\end{enumerate}

% The next topic  incorporating analytics,


\subsection{Incorporating passive analytics to development practices}
As mentioned earlier, passive analytics are those not actively under the control or influence of the development team, they are provided from other sources such as the operating system or the app store. In my research the passive analytics are all managed by the app store, Google Play Console.

Later in this thesis, the section titled \href{google_play_console_section}{\emph{\nameref{google_play_console_section}}} provides examples of a variety of reports developers may receive on the performance of their Android app. Developers can integrate and incorporate the passive analytics Google provides through the various reports in order to a) better understand how their app is doing b) change their app so it performs better as reported by these reports.

Here are the reports in the most likely chronological order of being generated if developers follow various recommendations made by Google, \emph{i.e.} to create and take advantage of test releases and use release management tools when rolling out a release of their Android app into production. They are not guaranteed to be produced or be available, and the contents may expire after a period determined by the app store.

\begin{enumerate}
    \item \textbf{Pre-launch reports}: 
    \item \textbf{Alpha and Beta channels}:
    \item \textbf{Release Management}: Note this fits with existing research in release management by Shane Mcintosh and Guenther Ruhe, and others.
    
    \item (the app) \textbf{Dashboard, including User Feedback}:
    \item \textbf{Android Vitals}:
\end{enumerate}

\subsubsection{Privacy and Responsibilities for using passive analytics}
For passive analytics the developer does not actively choose what to collect or how it's collected, therefore they are constrained by whoever, or whatever if we discount the people involved in deciding what to collect, etc. and assume algorithms such as AI determine the data. Google, at least, is careful to only share non PII % MUST_DO expand and add PII to the Glossary.
data and with a few exceptions limits reports to populations that exceed thresholds determined by Google internally. %MUST_DO add reference to Google Help article(s).

Nonetheless, I recommend developers consider ethical and legal responsibilities if they discover that sensitive and other PII data is being collected through the passive analytics. This may include avoiding reports with such data in them and also reporting the concerns to upstream providers of analytics (and where appropriate internal and external legal authorities).

\section{Adding and incorporating a crash-reporting library}
Crash-reporting libraries need to be incorporated into an application before they can be used, as mentioned in the section on~\href{section-packaging-mobile-apps}{\emph{packaging mobile apps}}. Generally~\footnote{A small minority of developers may follow other practices, nonetheless the principles mentioned here still apply}, the developer adds a few configuration lines to their application's build file (in \texttt{app/build.gradle} for Android apps) and also several lines of code to initialise the library when the application starts. These install the library as the global crash handler for the app, each time the app is started the library is initialised. 

When the library is initialised, it may perform various actions such recording details of the operating system release, the model of device, \emph{etc.}. They may also perform house-keeping activities, for instance Crashlytics transmits crash reports from previous sessions.

Some crash-reporting libraries offer developers an API to add \emph{breadcrumbs} at run-time. If/when a crash occurs and is reported, the immediately preceding breadcrumb data may help developers piece together possible causes for a particular crash.

Some crash-reporting libraries offer developers a mechanism to report non-fatal crashes: caught exceptions. These would be handled by the application yet be considered noteworthy and worthy of analysis by the development team. A good example of a library that includes support for non-fatal crash reporting is the popular Crashlytics offering.  

\subsection{Testing crash-reporting}
\begin{itemize}
    \item Sanity test
    \item Latency
\end{itemize}

Testing a system intended to measure quality may adversely affect their rating of your apps and potentially even their willingness to accept you in their system. \emph{c.f.} credit checks may adversely affect your credit score score~\footnote{\url{https://www.experian.co.uk/consumer/guides/searches-and-credit-checks.html}}. The system may not distinguish between your testing of the measurement system and those experienced by end users of the software. Google is adamant they will not accept Android apps that crash: ~\emph{``\textbf{Broken Functionality} We donâ€™t allow apps that crash, force close, freeze, or otherwise function abnormally."}~\cite{google_play_developer_policy_center}.

\section{Designing the messages}
This section applies to messages that an app could emit regardless of the conduit (\emph{i.e.} it applies to logging and using mobile analytics).

\emph{Related concepts}: The uneven U, computer protocols (layers, formatting, and contents), structured messages, what to log. %MUST_DO expand this section.

Developers have control over what to log, how, and when to generate the log messages. They may be constrained in various ways by APIs, message lengths, encoding, and formats, access to messages, and when messages will be transmitted, \emph{etc.} 

It is possible to test the constraints, for instance by writing custom automated tests and/or apps that generate a variety of messages where the outputs are checked somehow. The checking may be partly or completely performed programmatically (we did some unpublished research in this area in 2018).

The purpose of the message may differ in the type and level of information it is intended to convey. Some messages may contain low-level, or detailed, error messages intended to help improve the technical aspects of the software to make the software more robust. Other messages may aim to communicate intent, completion of a task, activity or user-journey in the software. For example, IBM published a paper about software called CX Mobile that aims to record and visualise user journeys for iOS and Android apps~\cite{hu_tealeaf_cxmobile}.

\section{Designing logging}
\subsection{Testing logging}

\section{Designing in-app analytics}
\subsection{Testing in-app analytics}

\section{An aside on 'pre-launch reports'}
Google provide a free service called pre-launch reports~\cite{google_use_pre_launch_reports}. TBC.
\section{Selecting Mobile Analytics}

\begin{itemize}
    \item Establish the selection criteria \emph{e.g.} the intended goals and purposes of the data collection, compare with non-functional qualities, flexibility of the API, price, privacy, licensing, legal, and other selection criteria.
    \item Establish the acceptance criteria, including any design and implementation aspects.
    \item TBC...
\end{itemize}

\section{Evaluation criteria for Analytics Tools}
One of the considerations in terms of using analytics tools is to decide on evaluation criteria. These criteria may range from informal and implicit evaluations to more rigorous and formal approaches. Considerations also include a mix of technical and non-technical aspects such as popularity, brand, perceived ease of initial use, and so on.

This section includes four types of criteria and a rubric for evaluating analytics tools.

\subsection{Evidence-based criteria}

\subsubsection{Auditability}
The reliability of software where the outcomes of failure are material has been a subject of discussion and research for decades. As (\cite{dobbing1998reliability}) notes, where the reliability requirements are modest black box testing techniques may be sufficient, however \emph{``When reliability claims cannot be justified from test results alone, safety standards accept evidence from the design process"}. This paper focuses on smart instrumentation for the UK nuclear industry, nonetheless given the widespread use and implicit trust of analytics software, similar approaches to assess the reliability of this software could help in terms of auditing the behaviours of the analytics tools. Indeed two of the authors of (\cite{dobbing1998reliability}) collaborated with a third author and published a paper on the relevance and importance of software in measuring systems, where \emph{``Both users and suppliers of such systems must be aware of the risks involved and take appropriate precautions."} (~\cite{wichmann2007software}).

\subsubsection{Functional-aspects}

\subsubsection{Transparency}

\subsubsection{Veracity}

\subsubsection{Faults and failures}


\subsection{Verification and Validation criteria}
These two terms, verification and validation, are often used in tandem, particularly in software testing standards including the retired~\cite{BS_7925_1_1998} and the standard that superseded it~\cite{iso29119-1-2013}. The definitions from the ISO standard are:
\begin{itemize}
    \item ``Verification is confirmation, through the provision of objective evidence, that specified requirements have been fulfilled in a given work item."~\cite{iso29119-1-2013}
    \item ``Validation demonstrates that the work item can be used by the users for their specific tasks."~\cite{iso29119-1-2013}
\end{itemize}

In terms of analytics tools, verification would focus on evaluating whether the tool has been implemented correctly. Validation considers human aspects such as whether users can perform intended tasks using the analytics tool(s). (In this research context software developers of mobile apps are the main users).

As the requirements for analytics tools are often proprietary, verification using the product specified requirements may be impractical to assess rigorously unless and until one has access to these requirements. Nonetheless common-sense requirements can be established based on heuristics and experience, \emph{etc}. this is covered in the section titled: \href{rubric-for-evaluating-analytics-tools}{\nameref{rubric-for-evaluating-analytics-tools}}.

\subsection{Perceptions-based criteria}

\subsection{Qualitative/quality criteria}

\subsubsection{Functional correctness}

\subsubsection{Performance}

\subsubsection{Safety}
Freedom from harm or danger, safety in other words, may be an unlikely consideration initially especially in terms of using analytics tools. 

Safety in terms of reputation, ability to try something out, and so on, considers human aspects of using (or not-using) various analytics tools. Safety became an emerging consideration in terms of assessing various analytics tools. Safety in relationship to the researcher, the health of apps and projects related to the research, and in terms of protecting the safety of end users privacy, \emph{etc}.

\subsubsection{Security}

\subsubsection{Time-aspects}

\subsection{A rubric for evaluating analytics tools}~\label{rubric-for-evaluating-analytics-tools}
Bugs can be exposed with various qualities, a heuristic the author learned in many years of evaluating the performance of systems is zero, one, several, and many, where:
\begin{itemize}
    \item Zero: can represent a system before it is actively used and/or the quiescent state with no active users, where there were users previously.
    \item One: the first user, session, account, and so on. Unless there are stated reasons to the contrary, as the first activity starts the analytics should be able to correctly indicate and report on the activity.
    \item Several: As several activities occur in parallel and concurrently race conditions, queuing, latency, and reuse of dirty memory values can all emerge.
    \item Many: As volumes increase from several to many issues of scaling may emerge, and some of the issues that appeared to be minor with several users may increase nonlinearly. 
\end{itemize}

Hysteresis loops are used to represent forces in magnetism, elasticity, and so on. They may also be relevant in representing the effects of growth (loading) and decline (unloading) of analytics systems. Figure ~\ref{fig:elastic-hysteresis} indicates elastic hysteresis as force increases and decreases the extension of rubber also varies, but nonlinearly. For an analytics system Force may represent actual concurrent use and extension the reported use.

\begin{figure}[!htbp]
    \centering
    \copyrightbox[r]{
        \includesvg[scale = 0.8]{images/wikipedia/Elastic_Hysteresis.svg}}
    {\textcopyright Bedenbender et Tiger66 \href{{https://creativecommons.org/licenses/by/2.5}}{CreativeCommons: CC by 2.5}\\source: \href{https://commons.wikimedia.org/wiki/File:Elastic_Hysteresis.svg}{Wikpedia}}
    \caption{Elastic Hysteresis}
    \label{fig:elastic-hysteresis}
\end{figure}

Economic effects of whether individuals swear an oath were assessed in two countries, China and Sweden (\cite{carlsson2013truth}). 


\section{Validating Analytics}


\section{Summary of applying analytics to development practices}

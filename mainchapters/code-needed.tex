\chapter{Key software developed for this research}
\label{chapter-code-needed}
Seven software projects were co-developed as part of this research together with contributions to other software and documentation projects. The complete list of these projects are in the~\href{app:software-contributions}{\textit{software contributions appendix}}, this chapter provides more details of the most relevant of these projects, including the needs they were intended to address, their design, use, and their evaluation.

These software projects are:~\href{section-vitals-scraper}{\emph{Vitals Scraper}} that preserves reports and data from Google Play Console and Android Vitals, and two Android apps: Crash Dummy, and Zipternet.

Tools to DO analytics research. 



Editorial note: The following need to be included for each piece of software mentioned here:
\begin{itemize}
    \item Problem: the reason to develop the software.
    \item Description: of the software.
    \item Evidence and Evaluation: of the software~\emph{e.g.}
    \begin{itemize}
        \item Adoption by others.
    \end{itemize}
    \item My evidence and assessment of the software utility to the overall problem.
\end{itemize}

In other words: explain the problem that needed to be addressed, why creating the software was necessary, details of the software project and results of using it. Then discuss the work in each case.

\section{Vital Scraper}\label{section-vitals-scraper}
An earlier section,~\href{section-drilling-down-into-analytics}{\emph{\MakeLowercase{\nameref{section-drilling-down-into-analytics}}}}, %The MakeLowercase has no effect :( 
introduced several constraints regarding the access to and availability of more detailed information. 
%
Also, many of the reports are updated on a daily basis, and some of these~\emph{and the underlying details} are only available for finite periods. Furthermore, limitations in some of the reports~\emph{e.g.} in the clustering of crashes and ANRs, made comparisons and prioritisation of problems more challenging. Another objective was to be able to persist the reports and the failure clusters. Both development teams and researchers would then be able to analyse these artifacts.

In summary there were three main drivers for this software, to:
\begin{enumerate}
    \item preserve the reports and data,
    \item enable further analysis and corrections to failure groupings, and to
    \item enable sharing and further research.
\end{enumerate}

\textbf{Design}:
Users of Google Play Console need to login and to have the necessary permission before they can use it or see any information about a particular app, and permission is granular and controlled by registered owners of a developer account. The contents are rich web contents and require a modern, fully-featured web browser such as Google Chrome, Firefox,~\emph{etc.}. Therefore, a similarly fully-featured browser and API would be appropriate to automate efficacious retrieval of reports and other contents. We selected \href{https://developers.google.com/web/tools/puppeteer}{\emph{puppeteer}} as it is a popular and well respected browser automation API that incorporates an embedded version of the Chromium web browser. It is also developed and maintained by Google developers which may help it work efficiently and effectively with Google software, including Google Play Console.

\textbf{Software license}: The software was jointly developed with Joseph Reeve as an opensource project released under the MIT software license~\citep{mitlicense2020_ongithub}. The MIT license is a simple, permissive license which provides great freedom to others who wish to reuse the materials~\citep{chooseanopensourcelicense2020}, which was developed in 1984 - the history is described in~\citep{saltzer2020_the_origin_of_the_mit_license}. As research in 2008 identified, there are contradictory forces that influence the choice of opensource license~\citep{sen2008_determinants_for_foss_license}. We consciously chose to minimise the limitations on anyone who wished to adopt and adapt our work, even if it's for proprietary and/or commercial purposes. Proprietary and/or commercial derivatives would need to develop something useful and saleable which would be of value to others, which in turn helps validate our contributions.  

\subsection{Outline challenges, don't need to go into detail}.
This is not core to my topic. 
\begin{itemize}
    \item Some of the types of challenges we faced are described in \citep{upadhyay2017_articulating_the_construction_of_a_web_scraper_for_massive_data_extraction}. Additional challenges included the risk of access being removed and the account being banned (TODO x-ref to developer's stories and self-imposed restrictions).
    \item A detailed tutorial on web scraping, including the legal aspects, was published in 2020 \emph{``Tutorial: Legality and Ethics of Web Scraping"}~\citep{krotov2020_tutorial_legality_and_ethics_of_web_scraping}. This publication helps provide context for some of the design and implementation choices that were made while we developed and used Vitals Scraper (note the publication post-dates the creation and use of Vitals Scraper). An observation on this publication, the authors state web scraping is a \emph{``relatively new, emerging practice"}~\citep[p.556]{krotov2020_tutorial_legality_and_ethics_of_web_scraping}, in the author's experience web scraping has been used at scale for over twenty years and the publication cites examples from 2000, twenty-one years ago. 
    \item Adapting the code as the web site's underlying code changes is a key challenge both in terms of the operations and maintenance of software that interacts with the web site. \emph{``Classification-Based Adaptive Web Scraper"}~\citep{ujwal2017_classification_based_adaptive_web_scraper} presents an approach designed to be highly adaptive to changes in a particular web site's structure. Their approach could be considered for future versions of Vitals Scraper, however the client-side code for Google Play Console and Android Vitals was highly complex and in an entirely different domain and usage context (for instance having access controls and requiring a valid developer account with access to the content) and we chose to hand-craft the locators for the various information that was to be extracted which was relatively effective and efficient in terms of the effort needed to create and maintain Vitals Scraper.
\end{itemize}

\textbf{Typescript}:

\textbf{Modular Design}:

\textbf{Revisions and maintenance}:

Coping with changes to the implementation, the GUI, errors, timing issues, data volumes. Adapting to previously unknown characteristics and requirements. 

Adding new capabilities as new needs emerged.
\begin{itemize}
    \item Caching credentials. 
\end{itemize}

Revamping the codebase to support the revamp of Google Play Console.

\textbf{Method}:


\textbf{Validation}:
- ACM reproduction qualification on one of the papers: MUST-DO add details here. 

\section{Crash Dummy}


\section{Zipternet}


\section{Summary of the software chapter}